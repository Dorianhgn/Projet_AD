{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/spotify_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)\n",
    "display(data.describe().T.style.background_gradient(cmap='YlGnBu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "display(missing_values)\n",
    "\n",
    "# display the lines with missing values\n",
    "missing_data = data[data.isnull().any(axis=1)]\n",
    "display(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id columns\n",
    "data = data.drop(columns=['track_id', 'track_album_id', \"playlist_id\"], axis=1)\n",
    "# drop the missing values\n",
    "data = data.dropna()\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform track_album_release_date into datetime\n",
    "data['track_album_release_date'] = pd.to_datetime(data['track_album_release_date'], format='mixed')\n",
    "\n",
    "# transform categorical columns into categorical data type\n",
    "categorical_cols = ['playlist_genre', 'playlist_subgenre', 'track_artist', 'playlist_name', 'track_album_name']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# transform the duration_ms into minutes\n",
    "data['duration_s'] = data['duration_ms'] / 1000\n",
    "data.drop(columns=['duration_ms'], inplace=True)\n",
    "\n",
    "# For numeric columns that represent discrete values (like key and mode), convert to categorical\n",
    "key_mapping = {\n",
    "    0: 'C', 1: 'C♯/D♭', 2: 'D', 3: 'D♯/E♭', 4: 'E', 5: 'F',\n",
    "    6: 'F♯/G♭', 7: 'G', 8: 'G♯/A♭', 9: 'A', 10: 'A♯/B♭', 11: 'B'\n",
    "}\n",
    "data['key'] = data['key'].map(key_mapping).astype('category')\n",
    "\n",
    "data['mode'] = data['mode'].map({0: 'Minor', 1: 'Major'}).astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "display(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data.select_dtypes(include='number')\n",
    "cat = data.select_dtypes(include='category')\n",
    "print('Data quantitative :', round(100*num.shape[1]/data.shape[1], 2), '%')\n",
    "print('Data qualitative :', round(100*cat.shape[1]/data.shape[1], 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copier data dans data_songs\n",
    "data_songs = data.copy()\n",
    "\n",
    "# observer les données dupliquées sur toutes les colonnes\n",
    "duplicates = data_songs.duplicated().sum()\n",
    "print(f'Number of duplicates: {duplicates}')\n",
    "\n",
    "# Nombre de valeurs dupliquées avant suppression\n",
    "initial_duplicates = data_songs.duplicated(subset=['track_artist', 'track_name']).sum()\n",
    "print(f'Initial number of duplicates: {initial_duplicates}')\n",
    "\n",
    "# Supprimer les colonnes 'playlist'\n",
    "data_songs = data_songs.drop(columns=['playlist_genre', 'playlist_subgenre', 'playlist_name'])\n",
    "\n",
    "# Regarder le nombre de doublons après suppression\n",
    "duplicates = data_songs.duplicated().sum()\n",
    "print(f'Number of duplicates - après suppression des playlists : {duplicates}')\n",
    "\n",
    "# Supprimer les doublons\n",
    "data_songs = data_songs.drop_duplicates()\n",
    "\n",
    "# regarder le nombre de doublons en fonction de 'track_artist' et 'track_name'\n",
    "duplicates = data_songs.duplicated(subset=['track_artist', 'track_name']).sum()\n",
    "print(f'Number of duplicates - en se basant sur le nom d artiste de la track et : {duplicates}')\n",
    "\n",
    "# garder dans data_songs les lignes dupliquées ayant la popularité la plus élevée\n",
    "data_songs = data_songs.sort_values('track_popularity', ascending=False).drop_duplicates(subset=['track_artist', 'track_name'])\n",
    "# regarder le nombre de doublons en fonction de 'track_artist' et 'track_name'\n",
    "duplicates = data_songs.duplicated().sum()\n",
    "print(f'Number of duplicates - après suppression des supposés doublons : {duplicates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Réduction de dimension par ACP (Analyse en Composantes Principales)\n",
    "Dans cette partie, nous allons effectuer une analyse en composantes principales (ACP) sur les données prétraitées. L'ACP est une technique de réduction de dimension qui permet de projeter les données d'origine dans un espace de dimension inférieure.\n",
    "Nous avons gardé 20 variables et nous allons étudier s'il est possible de réduire la dimensionnalité de ces données tout en préservant un maximum d'information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Format des données\n",
    "Ici on ne sélectionne que les variables quantitatives, en y ajoutant une variable qualitative (`playlist_genre`) pour voir si elle a un impact sur la projection des données. On garde au final 11 variables quantitatives et 1 variable qualitative.\n",
    "\n",
    "On décide de normaliser les données pour que chaque variable ait une moyenne de 0 et un écart-type de 1. Cela est important car l'ACP est sensible à l'échelle des variables. On utilise la méthode `StandardScaler` de `sklearn` pour normaliser les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the quantitative columns\n",
    "\n",
    "qualisup = 'playlist_genre'\n",
    "\n",
    "data_quanti = data.select_dtypes(include=['int64', 'float64'])\n",
    "data_quanti[qualisup] = data[qualisup]\n",
    "data_quanti = data_quanti.set_index(qualisup)\n",
    "\n",
    "data_quanti.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quanti[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import prince \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalize_bool = True\n",
    "\n",
    "if normalize_bool:\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data_quanti)\n",
    "else:\n",
    "    data_scaled = data_quanti.values\n",
    "\n",
    "pca = PCA(\n",
    "    n_components=10,  # Number of components to keep\n",
    "    random_state=1  # For reproducibility\n",
    ")\n",
    "\n",
    "projected = pca.fit_transform(data_scaled)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "eig = pd.DataFrame(\n",
    "    {\n",
    "        \"Dimension\" : [f\"PC{i+1}\" for i in range(len(explained_variance))],\n",
    "        \"Variance\" : np.round(pca.explained_variance_, 2),\n",
    "        \"% explained variance\" : np.round(explained_variance*100, 1),\n",
    "        \"% cumulative variance\" : np.round(np.cumsum(explained_variance)*100, 1)\n",
    "    }\n",
    ")\n",
    "eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.bar(range(10), pca.explained_variance_ratio_[:10]*100, align='center',\n",
    "        color='coral', ecolor='black')\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_ylabel(\"Variance\")\n",
    "ax.set_title(\"\", fontsize=35)\n",
    "ax.set_title(u\"Pourcentage de variance expliqué\", fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.plot(np.cumsum(pca.explained_variance_ratio_), color='coral', marker='o')\n",
    "ax.hlines(0.80, 0, 10, colors='grey', linestyles='dashed', alpha=0.5)\n",
    "ax.set_title(u'Pourcentage de variance expliqué cumulé', fontsize=20)\n",
    "\n",
    "fig.suptitle(u\"Résultat ACP\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :** \n",
    "\n",
    "L’analyse de la variance expliquée montre que les **7 premières composantes principales** permettent de **représenter 80,1 % de la variance totale** du jeu de données. Cela signifie que l’essentiel de l’information contenue dans les **11 variables numériques initiales** (comme *danceability*, *energy*, *speechiness*, *tempo*, etc.) peut être résumé avec seulement 7 dimensions, ce qui représente une **réduction significative de la complexité** du dataset tout en conservant une bonne qualité descriptive.\n",
    "\n",
    "Dans cette optique de réduction de dimension, il serait **pertinent de conserver ces 7 composantes principales** pour la suite des analyses (clustering, visualisation, classification), car elles capturent la structure principale des données tout en éliminant le \"bruit\".\n",
    "\n",
    "Dans l’analyse factorielle, nous avons choisi d’**interpréter les trois premières composantes principales**, qui à elles seules expliquent 45 % de la variance totale. Elles offrent un bon compromis entre lisibilité et pertinence pour une visualisation ou une première analyse des relations entre les variables et les genres musicaux (*playlist_genre*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "box=plt.boxplot(projected[:,0:3],whis=100)\n",
    "plt.title(u\"Distribution des premières composantes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "- Le graphique ci-dessus montre la distribution des premières composantes principales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_prince = prince.PCA(\n",
    "    n_components=3,\n",
    "    n_iter=3,\n",
    "    rescale_with_mean=normalize_bool,\n",
    "    rescale_with_std=normalize_bool,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=1\n",
    ")\n",
    "pca_prince = pca_prince.fit(\n",
    "    data_quanti,\n",
    "    sample_weight=None,\n",
    "    column_weight=None,\n",
    "    supplementary_columns=None\n",
    ")\n",
    "\n",
    "# Create a correlation matrix of the PCA compnenets\n",
    "correlations = pca_prince.column_correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlations, annot=True, cmap='RdBu', center=0)\n",
    "plt.title('Corrélations entre les variables et les composantes principales')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des coordonnées des variables (correlations avec les composantes principales)\n",
    "coords = pca_prince.column_correlations\n",
    "\n",
    "# Création de la figure et des sous-graphiques\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "# Boucle pour créer les trois graphiques\n",
    "for idx, (ax, (x_comp, y_comp)) in enumerate(zip(axes, [(0, 1), (1, 2), (0, 2)])):\n",
    "    ax.grid(False)\n",
    "    for i in range(coords.shape[0]):\n",
    "        ax.arrow(0, 0, coords.iloc[i, x_comp], coords.iloc[i, y_comp], \n",
    "                 color='black', alpha=0.7, head_width=0.02, head_length=0.03)\n",
    "        ax.text(coords.iloc[i, x_comp] * 1.1, coords.iloc[i, y_comp] * 1.1, \n",
    "                coords.index[i], color='black', ha='center', va='center')\n",
    "\n",
    "    # Ajout du cercle de rayon 1\n",
    "    ax.add_artist(plt.Circle((0, 0), radius=1, color='cornflowerblue', fill=False))\n",
    "\n",
    "    # Ajout des axes\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    ax.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Paramètres du graphique\n",
    "    ax.set_xlim(-1.1, 1.1)\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.set_xlabel(f'Composante principale {x_comp + 1}')\n",
    "    ax.set_ylabel(f'Composante principale {y_comp + 1}')\n",
    "    ax.set_title(f'Projection des variables: CP{x_comp + 1} vs CP{y_comp + 1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table des correlations et les trois graphiques ci-dessus représentent les projections des features sur les trois premières composantes principales nous donne des informations sur la structure des données réduites.\n",
    "\n",
    "- **Composante principale 1** : \n",
    "    - Les variables `energy (-0.91)`, `loudness (-0.80)` et `acousticness (+0.72)` sont linéairement corrélées avec la première composante principale, en soulignant que `energy` et `loudness` sont inversément corrélées avec `acousticness`. Cela indique que la CP1 oppose les morceaux **énergiques, forts en volume et peu acoustiques** (ex : rock, électro) aux morceaux **calmes, acoustiques et peu énergétiques** (ex : folk, classique).\n",
    "- **Composante principale 2** : Sur le graphique de gauche, on remarque une opposition des variables `instrumentalness (+0.45)`, `duration_s (+0.38)` contre `danceability (-0.68)`, `valence (-0.62)`, `track_popularity (-0.37)`, `speechiness (-0.39)`. Cette composante principale oppose deux profils de morceaux :\n",
    "    - D’un côté, les morceaux **instrumentaux, longs et peu populaires** (forte contribution de `instrumentalness` et `duration_s`), souvent associés à des genres comme le classique ou le jazz.\n",
    "    - De l’autre, les chansons **courtes, dansantes, joyeuses et populaires** (forte contribution de `danceability`, `valence` et `track_popularity`), typiques de la pop ou de la musique de club. \n",
    "    - Enfin, cette opposition suggère que les morceaux avec des paroles marquées (`speechiness`) et une structure rythmique engageante (`danceability`) sont plus susceptibles de générer de la popularité.\n",
    "- **Composantes principales 2 et 3** : Sur le graphique au centre, on peut extraire plusieurs informations :\n",
    "    - Les morceaux dansants et joyeux (haute valence) s'opposent dans une moindre mesure aux morceaux de faible tempo. De plus, ces morceaux semblent avoir peu de versions live.\n",
    "    - On observe aussi que les morceaux instrumentaux et longs ont généralement une faible popularité, tandis que les morceaux courts et peu instrumentaux sont souvent plus populaires, ce qui est typique de la musique pop, qui est souvent plus accessible et commerciale.\n",
    "- **Composante principale 3** : La troisième composante (CP3) révèle un paradoxe : elle regroupe des morceaux à fort potentiel dansant (`danceability`) et mood positif (`valence`), mais qui restent peu populaires (`track_popularity`). Ces morceaux sont souvent instrumentaux (`instrumentalness`), longs (`duration_s`) et à tempo faible (`tempo`), ce qui les éloigne des standards des charts. Cette composante pourrait représenter des créations artistiques équilibrant danse et complexité, mais peinant à atteindre un large public.\n",
    "\n",
    "Pour mieux comprendre à quoi correspond les type morceaux extraits par ces composantes principales, nous allons regarder les morceaux (individus) contribuant le plus à chacune des composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display la mediane de notre dataset quantitatif à fins de comparaison\n",
    "median_values = data_quanti.median()\n",
    "median_values = median_values.to_frame(name='median')\n",
    "median_values = median_values.reset_index()\n",
    "median_values.columns = ['feature', 'median']\n",
    "median_values['feature'] = median_values['feature'].astype('category')\n",
    "median_values = median_values.set_index('feature')\n",
    "median_values = median_values.sort_index()\n",
    "median_values = median_values.T\n",
    "median_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composante principale 1\n",
    "\n",
    "Afin de mieux comprendre les profils musicaux mis en évidence par la première composante principale, nous allons examiner les morceaux qui y contribuent le plus fortement, positivement et négativement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contributions of individuals to the first principal component\n",
    "contributions = projected[:, 0]\n",
    "\n",
    "# Get the indices of the top 5 positive contributors\n",
    "top_5_positive_indices = np.argsort(contributions)[-5:]\n",
    "\n",
    "# Get the indices of the top 5 negative contributors\n",
    "top_5_negative_indices = np.argsort(contributions)[:5]\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for positive contributions\n",
    "top_5_positive_tracks = data_quanti.iloc[top_5_positive_indices].copy()\n",
    "top_5_positive_tracks['track_name'] = data.iloc[top_5_positive_indices]['track_name'].values\n",
    "top_5_positive_tracks['track_artist'] = data.iloc[top_5_positive_indices]['track_artist'].values\n",
    "top_5_positive_tracks['contribution'] = contributions[top_5_positive_indices]\n",
    "top_5_positive_tracks['playlist_subgenre'] = data.iloc[top_5_positive_indices]['playlist_subgenre'].values\n",
    "# sort by contribution\n",
    "top_5_positive_tracks = top_5_positive_tracks.sort_values(by='contribution', ascending=False)\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for negative contributions\n",
    "top_5_negative_tracks = data_quanti.iloc[top_5_negative_indices].copy()\n",
    "top_5_negative_tracks['track_name'] = data.iloc[top_5_negative_indices]['track_name'].values\n",
    "top_5_negative_tracks['track_artist'] = data.iloc[top_5_negative_indices]['track_artist'].values\n",
    "top_5_negative_tracks['contribution'] = contributions[top_5_negative_indices]\n",
    "top_5_negative_tracks['playlist_subgenre'] = data.iloc[top_5_negative_indices]['playlist_subgenre'].values\n",
    "\n",
    "# Display the top 5 positive and negative tracks with additional information\n",
    "print(\"Top 5 Positive Contributions (PC1):\")\n",
    "display(top_5_positive_tracks)\n",
    "\n",
    "print(\"Top 5 Negative Contributions (PC1) :\")\n",
    "display(top_5_negative_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux cerner les types de morceaux représentés aux extrémités de la **première composante principale (PC1)**, nous avons identifié les individus (chansons) ayant les **contributions les plus élevées**, positives comme négatives.\n",
    "\n",
    "- **Du côté des contributions positives**, on retrouve majoritairement des morceaux **rock, hard rock ou pop rock** très énergiques et puissants tels que *American Idiot* (Green Day), *Beauty Queen* (BLVK SWVN) ou *ATTENTION ATTENTION* (Shinedown). Ces morceaux sont caractérisés par une **énergie élevée**, une **forte intensité sonore (loudness)** et une **faible acoustique**, ce qui confirme bien la structure mise en évidence par la CP1. Notons aussi *This Is How We Do It* (Montell Jordan), un morceau R&B énergique, qui se distingue des autres par son genre mais partage les mêmes caractéristiques acoustiques.\n",
    "\n",
    "- **À l’opposé**, les morceaux à contribution très négative sur PC1 sont des titres à **forte acoustique**, **peu énergiques** et **très faibles en loudness**. Il s'agit notamment de sons **ambiants, relaxants ou naturels**, comme *Peaceful Forest* ou *Tropical Rainforest at Dawn*, mais aussi de titres R&B ou indie très doux (*Small* de chloe moriondo). Ces morceaux incarnent l'autre extrémité de la CP1 : **des chansons calmes, acoustiques et à faible énergie**, souvent issues de sous-genres comme *tropical*, *indie poptimism* ou *new jack swing*.\n",
    "\n",
    "Cette opposition renforce l’interprétation de la **CP1 comme un axe énergie / intensité sonore vs. calme / acoustique**, pertinent pour distinguer deux grandes familles de styles musicaux dans le dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composante principale 2\n",
    "\n",
    "Pour approfondir l’interprétation de la **deuxième composante principale**, nous allons analyser les morceaux qui y contribuent le plus fortement — positivement comme négativement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contributions of individuals to the second principal component\n",
    "contributions_pc2 = projected[:, 1]\n",
    "\n",
    "# Get the indices of the top 5 positive contributors for PC2\n",
    "top_5_positive_indices_pc2 = np.argsort(contributions_pc2)[-5:]\n",
    "\n",
    "# Get the indices of the top 5 negative contributors for PC2\n",
    "top_5_negative_indices_pc2 = np.argsort(contributions_pc2)[:5]\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for positive contributions (PC2)\n",
    "top_5_positive_tracks_pc2 = data_quanti.iloc[top_5_positive_indices_pc2].copy()\n",
    "top_5_positive_tracks_pc2['track_name'] = data.iloc[top_5_positive_indices_pc2]['track_name'].values\n",
    "top_5_positive_tracks_pc2['track_artist'] = data.iloc[top_5_positive_indices_pc2]['track_artist'].values\n",
    "top_5_positive_tracks_pc2['contribution'] = contributions_pc2[top_5_positive_indices_pc2]\n",
    "top_5_positive_tracks_pc2['playlist_subgenre'] = data.iloc[top_5_positive_indices_pc2]['playlist_subgenre'].values\n",
    "# Sort by contribution\n",
    "top_5_positive_tracks_pc2 = top_5_positive_tracks_pc2.sort_values(by='contribution', ascending=False)\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for negative contributions (PC2)\n",
    "top_5_negative_tracks_pc2 = data_quanti.iloc[top_5_negative_indices_pc2].copy()\n",
    "top_5_negative_tracks_pc2['track_name'] = data.iloc[top_5_negative_indices_pc2]['track_name'].values\n",
    "top_5_negative_tracks_pc2['track_artist'] = data.iloc[top_5_negative_indices_pc2]['track_artist'].values\n",
    "top_5_negative_tracks_pc2['contribution'] = contributions_pc2[top_5_negative_indices_pc2]\n",
    "top_5_negative_tracks_pc2['playlist_subgenre'] = data.iloc[top_5_negative_indices_pc2]['playlist_subgenre'].values\n",
    "\n",
    "# Display the top 5 positive and negative tracks with additional information for PC2\n",
    "print(\"Top 5 Positive Contributions (PC2):\")\n",
    "display(top_5_positive_tracks_pc2)\n",
    "\n",
    "print(\"Top 5 Negative Contributions (PC2):\")\n",
    "display(top_5_negative_tracks_pc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Côté contributions positives**, on retrouve des titres principalement **rap et latino**, tels que *Suge* de DaBaby ou *LAX* de B0nds. Ces morceaux sont :\n",
    "- **courts**,\n",
    "- **dansants** (haute `danceability`),\n",
    "- avec une **valence élevée** (émotion positive),\n",
    "- mais également avec un certain niveau de **speechiness**, notamment pour les titres rap.\n",
    "\n",
    "Ces morceaux partagent donc des caractéristiques propres aux chansons **énergétiques, rythmées et populaires**, souvent taillées pour le streaming, avec des formats courts, accrocheurs et directs.\n",
    "\n",
    "**À l’opposé**, les morceaux ayant une **forte contribution négative à PC2** sont très différents : on retrouve des **paysages sonores naturels, ambiants ou instrumentaux** comme *Rain Forest and Tropical Beach Sound*, *Caribbean Thunderstorm*, ou encore *Battlement*. Ces titres sont :\n",
    "- **longs**,\n",
    "- **instrumentaux** (forte `instrumentalness`),\n",
    "- avec une **faible valence** et **peu de parole**,\n",
    "- et souvent issus de sous-genres comme *tropical*, *album rock*, ou *ambient*.\n",
    "\n",
    "Cela confirme l’interprétation initiale de la PC2 comme un **axe opposant la musique instrumentale, longue et contemplative** à une musique **populaire, dansante et rythmée**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composante principale 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contributions of individuals to the third principal component\n",
    "contributions_pc3 = projected[:, 2]\n",
    "\n",
    "# Get the indices of the top 5 positive contributors for PC3\n",
    "top_5_positive_indices_pc3 = np.argsort(contributions_pc3)[-5:]\n",
    "\n",
    "# Get the indices of the top 5 negative contributors for PC3\n",
    "top_5_negative_indices_pc3 = np.argsort(contributions_pc3)[:5]\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for positive contributions (PC3)\n",
    "top_5_positive_tracks_pc3 = data_quanti.iloc[top_5_positive_indices_pc3].copy()\n",
    "top_5_positive_tracks_pc3['track_name'] = data.iloc[top_5_positive_indices_pc3]['track_name'].values\n",
    "top_5_positive_tracks_pc3['track_artist'] = data.iloc[top_5_positive_indices_pc3]['track_artist'].values\n",
    "top_5_positive_tracks_pc3['contribution'] = contributions_pc3[top_5_positive_indices_pc3]\n",
    "top_5_positive_tracks_pc3['playlist_subgenre'] = data.iloc[top_5_positive_indices_pc3]['playlist_subgenre'].values\n",
    "# Sort by contribution\n",
    "top_5_positive_tracks_pc3 = top_5_positive_tracks_pc3.sort_values(by='contribution', ascending=False)\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for negative contributions (PC3)\n",
    "top_5_negative_tracks_pc3 = data_quanti.iloc[top_5_negative_indices_pc3].copy()\n",
    "top_5_negative_tracks_pc3['track_name'] = data.iloc[top_5_negative_indices_pc3]['track_name'].values\n",
    "top_5_negative_tracks_pc3['track_artist'] = data.iloc[top_5_negative_indices_pc3]['track_artist'].values\n",
    "top_5_negative_tracks_pc3['contribution'] = contributions_pc3[top_5_negative_indices_pc3]\n",
    "top_5_negative_tracks_pc3['playlist_subgenre'] = data.iloc[top_5_negative_indices_pc3]['playlist_subgenre'].values\n",
    "\n",
    "# Display the top 5 positive and negative tracks with additional information for PC3\n",
    "print(\"Top 5 Positive Contributions (PC3):\")\n",
    "display(top_5_positive_tracks_pc3)\n",
    "\n",
    "print(\"Top 5 Negative Contributions (PC3):\")\n",
    "display(top_5_negative_tracks_pc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **troisième composante principale** met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "**Du côté des contributions positives**, on retrouve des titres de **pop et R&B calmes et acoustiques** comme *raindrops (an angel cried)* (Ariana Grande) ou *You Are The Reason* (Calum Scott). Ces chansons ont :\n",
    "- une **acousticness élevée** (acapela, guitare acoustique, piano),\n",
    "- un **tempo légèrement plus rapide que la médiane des morceaux**,\n",
    "- une **faible énergie**, mais un **potentiel émotionnel fort** (`valence` variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "**Les contributions négatives**, quant à elles, sont largement dominées par des morceaux **EDM ou latino instrumentaux**, comme *I Feel Love* ou *Chase*. Ces morceaux sont :\n",
    "- **longs**,\n",
    "- très **instrumentaux**,\n",
    "- **énergiques** mais souvent **moins \"accessibles\" émotionnellement** (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la **PC3 oppose des créations acoustiques à forte charge émotionnelle** à des morceaux **instrumentaux, électroniques, longs**, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque que le signe des contribution est inversé par rapport à la PCA réalisé en R uniquement pour cette dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Factorial Analysis (MCA)\n",
    "\n",
    "**1. Variables catégorielles à utiliser dans la MCA**\n",
    "Voici les variables qualitatives que l'on pourrait envisager d'utiliser pour la MCA sur le dataset Spotify :  \n",
    "- `track_artist`  \n",
    "- `track_album_name` (attention à trop de modalités rares, peut-être garder que les plus fréquentes ou ne pas inclure à cause du grand nombre d’artistes)  \n",
    "- `playlist_name`  \n",
    "- `playlist_genre`  \n",
    "- `playlist_subgenre`  \n",
    "- `key`  \n",
    "- `mode`  \n",
    "\n",
    "---\n",
    "\n",
    "**2. Questions que la MCA peut aider à explorer**\n",
    "\n",
    "**a) Quels sont les groupes/cluster de modalités similaires ?**\n",
    "- Est-ce que certains genres et sous-genres de playlists s’associent fréquemment ?  \n",
    "- Certains \"modes\" (majeur/minor) sont-ils plus fréquents dans certains genres ?  \n",
    "- Y a-t-il des clés (`key`) musicales qui sont typiques de certains genres ou playlists ?  \n",
    "\n",
    "La MCA permettra de représenter graphiquement (biplot) ces modalités et d’identifier des associations fortes.\n",
    "\n",
    "**b) Est-ce que certains artistes ou playlists ont un profil qualitatif particulier ?**\n",
    "- Par exemple, certains artistes seraient-ils associés à un genre et sous-genre spécifiques, ou à un mode particulier ?  \n",
    "- Y a-t-il des clusters d’artistes / playlists qui partagent des caractéristiques particulières (clé, mode, genre) ?\n",
    "\n",
    "**3. Comment interpréter la MCA ici**\n",
    "\n",
    "- **Axes factoriels** : Chaque axe correspond à une dimension qui résume des associations fortes entre modalités. Par exemple, un axe peut opposer les genres \"Rock\" à \"Pop\", ou des clés majeures à mineures.\n",
    "- **Modalités proches dans l’espace** : Modalités proches signifient qu’elles co-apparaissent souvent dans les observations (ex. certains genres + mode majeur).\n",
    "- **Observation** : Si tu represents les observations (chansons) dans l’espace MCA, celles proches partagent des profils catégoriels similaires.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Utilisations concrètes/academic use cases**\n",
    "\n",
    "- **Profil des genres musicaux** : Comprendre quels modes/clés/sous-genres caractérisent les genres populaires sur Spotify.  \n",
    "- **Segmentation qualitative des playlists** : Y a-t-il des types de playlists/musiques qui partagent des caractéristiques qualitatives communes ?  \n",
    "- **Analyse de diversité** : Mesurer dans quelle mesure certains artistes/genres sont hétérogènes ou homogènes quant à leurs caractéristiques catégorielles.  \n",
    "- **Préparation à une classification** : Par exemple, combiner le résultat de la PCA (variables numériques) avec la MCA (variables qualitatives) dans une analyse factorielle mixte ou pour enrichir un modèle prédictif.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Exemple de questions précises à poser**\n",
    "\n",
    "- Les genres musicaux sont-ils liés à certaines tonalités ou modes ?  \n",
    "- Les sous-genres présents dans la même playlist sont-ils proches ou éloignés dans l’espace MCA ?  \n",
    "- Y a-t-il des clés rares ou des modes minoritaires associés à certains genres uniquement ?  \n",
    "- Peut-on détecter des groupes de playlists ou artistes avec des profils qualitatifs similaires ?  \n",
    "\n",
    "---\n",
    "\n",
    "**En conclusion**\n",
    "La MCA t’aide surtout à **explorer et visualiser les relations entre variables qualitatives** et leurs modalités sur ton dataset Spotify, ce qui complète bien la PCA sur les variables numériques. C’est une étape utile pour comprendre la structure qualitative de tes données avant d’envisager une modélisation supervisée ou une analyse plus approfondie.\n",
    "\n",
    "---\n",
    "\n",
    "Si tu veux, je peux aussi te fournir un exemple de code Python pour réaliser une MCA avec `prince` ou en R avec `FactoMineR` sur ton dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import prince \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Subset for MCA\n",
    "df_cat = data[['playlist_genre', 'mode', 'key']].copy()\n",
    "\n",
    "# Run MCA\n",
    "mca = prince.MCA(n_components=2, n_iter=100, copy=True, check_input=True, engine='sklearn', random_state=1)\n",
    "mca = mca.fit(df_cat)\n",
    "\n",
    "# Get coordinates for the plot\n",
    "coords = mca.column_coordinates(df_cat)\n",
    "\n",
    "# Calculate cosine similarities for sizing\n",
    "cosine_similarities = mca.column_cosine_similarities(df_cat)\n",
    "# Use the sum of cosine similarities as size parameter (for clearer visualization)\n",
    "sizes = cosine_similarities[0]**2 + cosine_similarities[1]**2\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'x': coords[0],\n",
    "    'y': coords[1],\n",
    "    'variable': [x.split('__')[0] for x in coords.index],\n",
    "    'value': [x.split('__')[1] for x in coords.index],\n",
    "    'size': sizes * 500  # Scale sizes for better visualization\n",
    "})\n",
    "\n",
    "# Create a color mapping for variables\n",
    "colors = {'playlist_genre': 'blue', 'mode': 'red', 'key': 'green'}\n",
    "plot_data['color'] = plot_data['variable'].map(colors)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = sns.scatterplot(\n",
    "    data=plot_data,\n",
    "    x='x', \n",
    "    y='y',\n",
    "    hue='variable',\n",
    "    size='size',\n",
    "    sizes=(50, 500),\n",
    "    palette=colors,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add annotations\n",
    "for i, row in plot_data.iterrows():\n",
    "    plt.text(\n",
    "        row['x'] + 0.02, \n",
    "        row['y'] + 0.02, \n",
    "        row['value'], \n",
    "        fontsize=9,\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "# Add styling\n",
    "plt.title('MCA: Relationship between Genre, Mode and Key', fontsize=16)\n",
    "plt.xlabel(f'Dimension 1 ({mca.eigenvalues_summary.iloc[0, 1]})', fontsize=12)\n",
    "plt.ylabel(f'Dimension 2 ({mca.eigenvalues_summary.iloc[1, 1]})', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.legend(title='Variable Type')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print quick interpretation of coordinates\n",
    "print(\"\\nCoordinates Summary by Variable Type:\")\n",
    "for var in ['playlist_genre', 'mode', 'key']:\n",
    "    var_coords = coords.filter(like=var)\n",
    "    print(f\"\\n{var.upper()} coordinates:\")\n",
    "    print(var_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables utilisées\n",
    "Les variables qualitatives sélectionnées pour cette analyse sont :\n",
    "- `playlist_genre` : Genre de la playlist (ex. rock, pop, rap, etc.).\n",
    "- `key` : Tonalité musicale (ex. C, D, E♭, etc.).\n",
    "- `mode` : Mode musical (majeur ou mineur).\n",
    "\n",
    "### Résultats\n",
    "\n",
    "#### 1. Axes factoriels\n",
    "- **Dim1 (8%)** : Cet axe semble opposer des genres musicaux et des tonalités spécifiques :\n",
    "  - À gauche, des genres comme `rap` et des tonalités comme `A♯/B♭` sont associés à des morceaux modernes ou spécifiques.\n",
    "  - À droite, des tonalités comme `C` et `G` sont associées à des genres comme `rock`, suggérant une relation avec des styles plus classiques.\n",
    "- **Dim2 (6.6%)** : Cet axe reflète une distinction entre les modes (`major` et `minor`) et leur association avec certains genres :\n",
    "  - En bas, le mode `major` est associé à des genres comme `rock`.\n",
    "  - En haut, le mode `minor` est plus proche de genres comme `rap` et `edm`.\n",
    "\n",
    "On remarque ici que nous avons les même resultats qu'en R à l'exception de la projection des individus qui est inversée.\n",
    "\n",
    "#### 2. Proximité des modalités\n",
    "- Les modalités proches sur le graphique sont souvent associées dans les données :\n",
    "  - `pop`, `latin`, `r&b` et `edm` sont centrés par rapport aux modes `minor`et `major`, indiquant qu'ils n'appartiennent pas clairement à un mode spécifique, mais partagent des caractéristiques communes.\n",
    "  - `rap` est également centré par rapport à ces modes, ce qui suggère que l'utilisation des modes majeurs et mineurs est assez équilibrée dans la composition des morceaux de rap. Toutefois, il reste distinct des groupes `pop`, `latin`, `r&b` et `edm`.\n",
    "  - `rock` est plus proche de `major`, ce qui suggère que les musiques de ce genre sont souvent associées à des tonalités majeures.\n",
    "  - Les tonalités comme `B`,`D♯/E♭`,`A♯/B♭`,`F♯/G♭`et `F` sont proches de `minor`, indiquant qu'elles sont souvent utilisées dans des morceaux en mode mineur.\n",
    "  - Les tonalités comme `C`, `G`,`D` sont proches de `major`, ce qui suggère qu'elles sont souvent utilisées dans des morceaux en mode majeur.\n",
    "\n",
    "#### 3. Cos² (Qualité de représentation)\n",
    "- La taille des bulles indiquent la qualité de représentation des modalités sur les deux premières dimensions :\n",
    "  - Les modalités avec des grosses bulles comme `major`, `minor`, `C♯/D♭` ou `rock` sont bien représentées sur ces axes.\n",
    "  - Les modalités avec des bulles plus petites comme certaines tonalités, ou certains genres (`pop`, `latin`, `r&b` et `edm`) sont moins bien représentées, ce qui signifie qu'elles pourraient être mieux expliquées par d'autres dimensions.\n",
    "\n",
    "### Conclusion\n",
    "Cette MCA met en évidence des associations claires entre les genres musicaux, les tonalités (`key`), et les modes (`major`/`minor`). Elle permet de visualiser les relations qualitatives dans les données et d'identifier des clusters ou des oppositions significatives. Par exemple :\n",
    "- `rock` est distinct des autres genres, avec des tonalités et un mode spécifiques.\n",
    "- `pop`, `latin`, `r&b` et `edm` partagent des caractéristiques similaires, mais ne sont pas clairement associés à un mode particulier.\n",
    "- `rap` est centré par rapport aux modes, mais reste distinct des autres genres.\n",
    "\n",
    "Ces résultats offrent une meilleure compréhension des structures qualitatives des données et peuvent être utilisés pour des analyses complémentaires, comme la segmentation ou la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir 4 artistes fréquents\n",
    "top_artists = ['David Guetta', 'Ed Sheeran', 'Green Day', 'Billie Eilish', 'Eminem']\n",
    "\n",
    "# Remplacer les autres artistes par 'Autre'\n",
    "data['artist_subset'] = data['track_artist'].apply(lambda x: x if x in top_artists else 'Autre')\n",
    "\n",
    "# Refaire le sous-ensemble avec artiste\n",
    "df_cat = data[['playlist_genre', 'mode', 'key', 'artist_subset']].copy()\n",
    "\n",
    "# Run MCA\n",
    "mca = prince.MCA(n_components=2, n_iter=100, copy=True, check_input=True, engine='sklearn', random_state=1)\n",
    "mca = mca.fit(df_cat)\n",
    "\n",
    "# Get coordinates for the plot\n",
    "coords = mca.column_coordinates(df_cat)\n",
    "\n",
    "# Calculate cosine similarities for sizing\n",
    "cosine_similarities = mca.column_cosine_similarities(df_cat)\n",
    "# Use the sum of cosine similarities as size parameter (for clearer visualization)\n",
    "sizes = cosine_similarities[0]**2 + cosine_similarities[1]**2\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'x': coords[0],\n",
    "    'y': coords[1],\n",
    "    'variable': [x.split('__')[0] for x in coords.index],\n",
    "    'value': [x.split('__')[1] for x in coords.index],\n",
    "    'size': sizes * 500  # Scale sizes for better visualization\n",
    "})\n",
    "\n",
    "# Create a color mapping for variables\n",
    "colors = {'playlist_genre': 'blue', 'mode': 'red', 'key': 'green', 'artist_subset': 'purple'}\n",
    "plot_data['color'] = plot_data['variable'].map(colors)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = sns.scatterplot(\n",
    "    data=plot_data,\n",
    "    x='x', \n",
    "    y='y',\n",
    "    hue='variable',\n",
    "    size='size',\n",
    "    sizes=(50, 500),\n",
    "    palette=colors,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add annotations\n",
    "for i, row in plot_data.iterrows():\n",
    "    plt.text(\n",
    "        row['x'] + 0.02, \n",
    "        row['y'] + 0.02, \n",
    "        row['value'], \n",
    "        fontsize=9,\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "# Add styling\n",
    "plt.title('MCA: Relationship between Genre, Mode and Key', fontsize=16)\n",
    "plt.xlabel(f'Dimension 1 ({mca.eigenvalues_summary.iloc[0, 1]})', fontsize=12)\n",
    "plt.ylabel(f'Dimension 2 ({mca.eigenvalues_summary.iloc[1, 1]})', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.legend(title='Variable Type')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print quick interpretation of coordinates\n",
    "print(\"\\nCoordinates Summary by Variable Type:\")\n",
    "for var in ['playlist_genre', 'mode', 'key', 'artist_subset']:\n",
    "    var_coords = coords.filter(like=var)\n",
    "    print(f\"\\n{var.upper()} coordinates:\")\n",
    "    print(var_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les genres et les artistes\n",
    "genres = [i for i in coords.index if i.startswith(\"playlist_genre__\")]\n",
    "artists = [i for i in coords.index if i.startswith(\"artist_subset__\")]\n",
    "\n",
    "# Initialiser un nouveau DataFrame pour stocker les distances\n",
    "distances = pd.DataFrame(index=artists, columns=genres)\n",
    "\n",
    "# Calculer les distances euclidiennes au carré\n",
    "for artist in artists:\n",
    "    for genre in genres:\n",
    "        vec_artist = coords.loc[artist].values\n",
    "        vec_genre = coords.loc[genre].values\n",
    "        dist_sq = np.sum((vec_artist - vec_genre) ** 2)\n",
    "        distances.loc[artist, genre] = dist_sq\n",
    "\n",
    "# Convertir les distances en float (au cas où)\n",
    "distances = distances.astype(float)\n",
    "\n",
    "# Afficher les résultats\n",
    "distances.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances artistes-genres (MCA)\n",
    "Nous avons décidé d'affiner notre MCA en y intégrant certains artistes pour mieux comprendre leurs relations avec les genres musicaux. Nous avons sélectionné 6 artistes : **David Guetta**, **Ed Sheeran**, **Green Day**, **Billie Eilish**, **Eminem** et un groupe d'artistes diversifié nommé **Autre**. Afin d'analyser la proximité entre ces artistes et les genres musicaux, nous avons calculé les distances euclidiennes au carré entre chaque artiste et les genres issus de l'Analyse des Correspondances Multiples (MCA).\n",
    "\n",
    "#### Interprétations individuelles\n",
    "\n",
    "- **David Guetta** est très proche du genre **EDM**, ce qui est cohérent avec son positionnement d’artiste électro. Il est aussi relativement proche du genre `pop` et `rock`, ce qui peut s’expliquer par ses nombreuses collaborations avec des chanteurs populaires.\n",
    "\n",
    "- **Ed Sheeran** est modérément proche des genres **pop** et **edm**, ce qui reflète sa diversité musicale et ses morceaux mêlant acoustique et sons plus produits.\n",
    "\n",
    "- **Green Day** est relativement proche du genre **rock**, ce qui confirme son ancrage dans ce style. Il est plus éloigné des autres genres, ce qui le distingue nettement stylistiquement dans cette analyse.\n",
    "\n",
    "- **Billie Eilish** est située à mi-distance de plusieurs genres (`pop`, `edm`, `rock`), ce qui traduit une position hybride. Elle n’est pas fortement associée à un genre unique, ce qui est cohérent avec son style singulier et difficile à catégoriser.\n",
    "\n",
    "- **Eminem** montre une **affinité forte avec le genre Rap**, avec une distance minimale comparée aux autres genres. Il est largement séparé des genres comme rock ou pop, ce qui reflète bien son style musical distinct.\n",
    "\n",
    "- **Autre** est, comme attendu, proche du centre, ce qui traduit une position moyenne, résultant de l’agrégation d’artistes divers aux profils variés.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "L’analyse des distances artistes-genres via la MCA confirme plusieurs intuitions sur les positionnements stylistiques des artistes. Elle permet également de détecter des cas hybrides (comme Billie Eilish)\n",
    "Elle enrichit l’interprétation visuelle de l’ACM en objectivant la notion de \"proximité\" par une mesure quantitative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = [\n",
    "    'danceability', 'energy', 'loudness', 'speechiness',\n",
    "    'acousticness', 'instrumentalness', 'liveness',\n",
    "    'valence', 'tempo', 'duration_s'\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1. Sélection des features audio\n",
    "X = data_songs[audio_features].copy()\n",
    "\n",
    "# 2. Normalisation min-max (important pour la NMF)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. Tester plusieurs valeurs de r (nombre de composants)\n",
    "errors = []\n",
    "r_values = range(2,11, 2)\n",
    "\n",
    "for r in r_values:\n",
    "    model = NMF(n_components=int(r), init='nndsvda', random_state=42, max_iter=500)\n",
    "    W = model.fit_transform(X_scaled)\n",
    "    H = model.components_\n",
    "    reconstruction = np.dot(W, H)\n",
    "    error = np.linalg.norm(X_scaled - reconstruction, 'fro')  # norme de Frobenius\n",
    "    errors.append(error)\n",
    "\n",
    "# 4. Tracer la courbe de l’erreur de reconstruction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(r_values, errors, marker='o')\n",
    "plt.title(\"Erreur de reconstruction vs nombre de composants (r)\")\n",
    "plt.xlabel(\"Nombre de composants (r)\")\n",
    "plt.ylabel(\"Erreur de reconstruction (norme de Frobenius)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde 6 profils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Application de la NMF\n",
    "nmf_model = NMF(n_components=6, init='nndsvda', random_state=42, max_iter=500)\n",
    "W = nmf_model.fit_transform(X_scaled)\n",
    "H = nmf_model.components_\n",
    "\n",
    "# 4. Créer un DataFrame pour la matrice H\n",
    "H_df = pd.DataFrame(H, columns=audio_features)\n",
    "H_df.index = [f'Profil {i+1}' for i in range(H.shape[0])]\n",
    "\n",
    "# 5. Affichage de la matrice H\n",
    "print(\"Matrice H (profils latents définis par les variables audio) :\")\n",
    "display(H_df)\n",
    "\n",
    "# 6. Visualisation : contribution des variables à chaque profil\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(H_df, annot=True, cmap='YlGnBu', fmt=\".2f\")\n",
    "plt.title(\"Profils latents musicaux détectés par NMF (matrice H)\")\n",
    "plt.xlabel(\"Caractéristiques audio\")\n",
    "plt.ylabel(\"Profils NMF\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset utilisé\n",
    "Nous avons décidé d'utiliser le dataframe `data_songs` ne contenant que les morceaux une seule fois dans le dataset, pour éviter de biaiser les résultats. \n",
    "\n",
    "### Variables utilisées\n",
    "\n",
    "Les variables sélectionnées pour cette NMF sont les caractéristiques audio continues suivantes :\n",
    "\n",
    "* `danceability`, `energy`, `loudness`, `speechiness`, `acousticness`, `instrumentalness`, `liveness`, `valence`, `tempo`, `duration_s`.\n",
    "\n",
    "Nous avons exclu la variable `track_popularity` car la NMF est très sensible aux valeurs extrêmes et cette variable a une distribution très héterogène. De plus, nous avons exclu les variables catégorielles et les variables de texte, car la NMF est conçue pour fonctionner sur des données numériques continues.\n",
    "\n",
    "### Résultats\n",
    "\n",
    "#### 1. Profils latents détectés\n",
    "\n",
    "L’analyse a révélé **6 profils musicaux latents** à partir des données. Chaque profil est défini par une combinaison unique de caractéristiques audio. Voici leur interprétation :\n",
    "\n",
    "* **Profil 1 : Profil Énergique-Intense**\n",
    "\n",
    "  * Caractérisé par de **très fortes valeurs en `energy`, `loudness` et `tempo` et `duration`**.\n",
    "  * Faible en composantes émotionnelles (`valence`), vocales et instrumentales.\n",
    "  * Ce profil pourrait correspondre à des morceaux **très dynamiques et bruyants**, typiques de l’**EDM** (house, electro, techno) ou du **hard-rock**/**metal**.\n",
    "\n",
    "* **Profil 2 : Profil Acoustique-Chant**\n",
    "\n",
    "  * Dominé par une forte **`acousticness`**.\n",
    "  * Ce profil, presente **`instrumentalness`=0**, et un faible **`speechiness`** mais différent de zero.\n",
    "  * Ce profil regroupe possiblement des morceaux **acoustiques et chantés**.\n",
    "\n",
    "* **Profil 3 : Profil Instrumental**\n",
    "\n",
    "  * Très forte **`instrumentalness`** avec très peu d'autres caractéristiques.\n",
    "  * Correspond clairement à des morceaux **purement instrumentaux**, probablement **ambient**, **classique** ou **bande-son**.\n",
    "\n",
    "* **Profil 4 : Profil Émotionnel-Valence**\n",
    "\n",
    "  * Faible en toutes dimensions sauf une très forte **`valence`**.\n",
    "  * Ce profil regroupe des morceaux **émotionnellement très positifs**, avec une ambiance **joyeuse ou euphorique**, indépendamment du tempo ou de l’énergie.\n",
    "\n",
    "* **Profil 5 : Profil Vocal-Live**\n",
    "\n",
    "  * Faibles valeurs générales sauf une **forte `liveness`** et une **`speechiness`** marquée.\n",
    "  * Peut représenter des morceaux **live**, **rap**, ou des chansons **parlées/spoken word**.\n",
    "\n",
    "* **Profil 6 : Profil Rap-Rythmé**\n",
    "\n",
    "  * Forte `danceability`, `speechiness` et modérée `energy`.\n",
    "  * Ce profil semble capturer des morceaux **rythmés et très vocaux**, typiques du **rap**, **hip-hop**, voire certains morceaux **R\\&B urbains**. Ils pourraient aussi correspondre à des morceaux **pop** et **latino** dans une certaine mesure.\n",
    "\n",
    "---\n",
    "\n",
    "Pour chaque profil, nous allons desormais regarder les morceaux qui y contribuent le plus fortement, pour confirmer ces resultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 tracks for each NMF profile\n",
    "n_profiles = 6  # Number of profiles from our NMF model\n",
    "top_n = 2      # Number of top tracks to display per profile\n",
    "\n",
    "# Create a dataframe with track information and profile weights\n",
    "profile_weights = pd.DataFrame(W, index=data_songs.index)\n",
    "profile_weights.columns = [f'Profile_{i+1}' for i in range(n_profiles)]\n",
    "\n",
    "# For each profile, find the tracks with the highest weights\n",
    "results = []\n",
    "\n",
    "for profile_idx in range(n_profiles):\n",
    "    profile_name = f'Profile_{profile_idx+1}'\n",
    "    \n",
    "    # Get top tracks for this profile\n",
    "    top_indices = profile_weights[profile_name].nlargest(top_n).index\n",
    "    \n",
    "    # Extract relevant information for these tracks\n",
    "    for idx in top_indices:\n",
    "        track_info = {\n",
    "            'Profile': profile_name,\n",
    "            'Track Name': data.loc[idx, 'track_name'],\n",
    "            'Artist': data.loc[idx, 'track_artist'],\n",
    "            'Genre': data.loc[idx, 'playlist_genre'],\n",
    "            'Subgenre': data.loc[idx, 'playlist_subgenre'],\n",
    "            'Weight': profile_weights.loc[idx, profile_name]\n",
    "        }\n",
    "        \n",
    "        # Add audio features for context\n",
    "        for feature in audio_features:\n",
    "            track_info[feature] = data.loc[idx, feature]\n",
    "            \n",
    "        results.append(track_info)\n",
    "\n",
    "# Create a dataframe with the results and display it\n",
    "top_tracks_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by profile and weight\n",
    "top_tracks_df = top_tracks_df.sort_values(['Profile', 'Weight'], ascending=[True, False])\n",
    "display(top_tracks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve des resultats cohérents avec les profils identifiés précédemment. Seul `Sandstorm` de Darude qui est censé être un morceau EDM est classé dans le profil 2, ce qui est surprenant. Mais en regardant la caractéristique `instrumentalness`, on remarque qu'il est très proche de 1, ce qui signifie que le morceau est classé comme très intrumental. Il est donc normal qu'il soit classé dans le profil 2.\n",
    "\n",
    "---\n",
    "\n",
    "On peut desormais regarder pour certains artistes quels sont les profils musicaux qui leur correspondent le mieux. On va regarder les tracks des artistes suivants : **David Guetta**, **Ed Sheeran**, **Green Day**, **Billie Eilish** et **Eminem**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with profile weights for each track\n",
    "profile_weights = pd.DataFrame(W, index=data_songs.index)\n",
    "profile_weights.columns = [f'Profile_{i+1}' for i in range(n_profiles)]\n",
    "\n",
    "# Merge with original data to get artist info\n",
    "artist_profiles = pd.concat([data_songs[['track_artist', 'track_name']], profile_weights], axis=1)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "artist_distribution = {}\n",
    "\n",
    "# For each artist, analyze their tracks\n",
    "for artist in top_artists:\n",
    "    # Filter tracks by this artist\n",
    "    artist_tracks = artist_profiles[artist_profiles['track_artist'] == artist]\n",
    "    \n",
    "    if len(artist_tracks) == 0:\n",
    "        print(f\"No tracks found for {artist}\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate average profile weight for this artist\n",
    "    avg_profile_weights = artist_tracks[[f'Profile_{i+1}' for i in range(n_profiles)]].mean()\n",
    "    \n",
    "    # Find dominant profile for each track\n",
    "    dominant_profiles = artist_tracks[[f'Profile_{i+1}' for i in range(n_profiles)]].idxmax(axis=1).value_counts()\n",
    "    \n",
    "    # Store results\n",
    "    artist_distribution[artist] = {\n",
    "        'track_count': len(artist_tracks),\n",
    "        'avg_weights': avg_profile_weights,\n",
    "        'dominant_profiles': dominant_profiles\n",
    "    }\n",
    "\n",
    "# Visualize the results\n",
    "fig, axes = plt.subplots(len(top_artists), 2, figsize=(18, 4*len(top_artists)))\n",
    "\n",
    "for i, artist in enumerate(top_artists):\n",
    "    if artist not in artist_distribution:\n",
    "        continue\n",
    "    \n",
    "    # Average profile weights\n",
    "    artist_distribution[artist]['avg_weights'].plot(\n",
    "        kind='bar', \n",
    "        ax=axes[i, 0], \n",
    "        color='skyblue',\n",
    "        title=f\"{artist}: Average Profile Weights (n={artist_distribution[artist]['track_count']} tracks)\"\n",
    "    )\n",
    "    axes[i, 0].set_ylabel(\"Weight\")\n",
    "    axes[i, 0].set_xlabel(\"NMF Profile\")\n",
    "    \n",
    "    # Distribution of dominant profiles\n",
    "    if len(artist_distribution[artist]['dominant_profiles']) > 0:\n",
    "        artist_distribution[artist]['dominant_profiles'].plot(\n",
    "            kind='bar', \n",
    "            ax=axes[i, 1], \n",
    "            color='coral',\n",
    "            title=f\"{artist}: Dominant Profile Distribution\"\n",
    "        )\n",
    "        axes[i, 1].set_ylabel(\"Number of Tracks\")\n",
    "        axes[i, 1].set_xlabel(\"Dominant NMF Profile\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print a summary\n",
    "print(\"\\nArtist Profile Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for artist in top_artists:\n",
    "    if artist not in artist_distribution:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{artist} ({artist_distribution[artist]['track_count']} tracks)\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Get the dominant profile(s)\n",
    "    if len(artist_distribution[artist]['dominant_profiles']) > 0:\n",
    "        top_profile = artist_distribution[artist]['dominant_profiles'].index[0]\n",
    "        top_count = artist_distribution[artist]['dominant_profiles'].iloc[0]\n",
    "        top_percent = (top_count / artist_distribution[artist]['track_count']) * 100\n",
    "        \n",
    "        print(f\"Primary Profile: {top_profile} ({top_percent:.1f}% of tracks)\")\n",
    "    \n",
    "    # Get the highest weight profile on average\n",
    "    top_avg_profile = artist_distribution[artist]['avg_weights'].idxmax()\n",
    "    top_avg_weight = artist_distribution[artist]['avg_weights'].max()\n",
    "    \n",
    "    print(f\"Highest Average Weight: {top_avg_profile} (weight: {top_avg_weight:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all tracks by Green Day\n",
    "green_day_tracks = data_songs[data_songs['track_artist'] == 'Green Day']\n",
    "\n",
    "# Create a dataframe with profile weights for each Green Day track\n",
    "profile_weights = pd.DataFrame(W, index=data_songs.index)\n",
    "profile_weights.columns = [f'Profile_{i+1}' for i in range(n_profiles)]\n",
    "\n",
    "# Merge track information with profile weights\n",
    "green_day_profiles = pd.concat([green_day_tracks[['track_name']], \n",
    "                               profile_weights.loc[green_day_tracks.index]], axis=1)\n",
    "\n",
    "# Add the dominant profile column\n",
    "green_day_profiles['Dominant_Profile'] = green_day_profiles[[f'Profile_{i+1}' for i in range(n_profiles)]].idxmax(axis=1)\n",
    "\n",
    "# Sort by dominant profile and then by the weight of that profile (descending)\n",
    "green_day_profiles = green_day_profiles.sort_values(['Dominant_Profile', 'track_name'])\n",
    "\n",
    "# Display the tracks with their profile information\n",
    "display(green_day_profiles[['track_name', 'Dominant_Profile'] + \n",
    "                          [f'Profile_{i+1}' for i in range(n_profiles)]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats\n",
    "\n",
    "En dehors de **Green Day** a des morceaux partagés entre les profiles 4, 5 et 6, les autres artistes appartiennent tous au profil 6. \n",
    "\n",
    "On peut conclure sur le fait que ce profil 6 regroupe..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
