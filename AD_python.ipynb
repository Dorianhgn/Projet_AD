{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Contexte et objectifs\n",
    "\n",
    "Ce projet analyse un dataset Spotify contenant des caractéristiques audio de milliers de chansons provenant de différents genres musicaux. L'objectif principal est d'explorer la structure des données musicales à travers diverses techniques d'analyse multivariée et de réduction de dimension.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Le dataset comprend des variables quantitatives (danceability, energy, valence, tempo, etc.) et qualitatives (genre, artiste, tonalité, mode) permettant une analyse complète des profils musicaux. Après prétraitement, nous disposons de données sur les caractéristiques audio objectives et les métadonnées descriptives des morceaux.\n",
    "\n",
    "## Approche méthodologique\n",
    "\n",
    "Cette analyse combine plusieurs techniques complémentaires :\n",
    "- **Analyse en Composantes Principales (ACP)** pour explorer les relations entre variables quantitatives et réduire la dimensionnalité\n",
    "- **Analyse des Correspondances Multiples (MCA)** pour étudier les associations entre variables qualitatives (genres, tonalités, modes)\n",
    "- **Analyse Factorielle Multiple (MFA)** pour intégrer simultanément données quantitatives et qualitatives dans une analyse unifiée\n",
    "- **Techniques de réduction non-linéaire** (MDS, t-SNE) pour visualiser la structure complexe des données musicales\n",
    "- **Factorisation Matricielle Non-négative (NMF)** pour identifier des profils musicaux latents et développer un système de recommandation\n",
    "- **Algorithmes de clustering** pour segmenter les morceaux en groupes homogènes selon leurs caractéristiques audio\n",
    "\n",
    "L'objectif est de comprendre comment les caractéristiques musicales s'organisent, identifier des patterns et profils musicaux distincts, et développer des applications pratiques comme un système de recommandation personnalisé basé sur les profils latents découverts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "\n",
    "## Préparation et nettoyage des données\n",
    "\n",
    "Le préprocessing est une étape cruciale qui conditionne la qualité des analyses statistiques ultérieures. Pour ce dataset Spotify, plusieurs transformations sont nécessaires :\n",
    "\n",
    "### Objectifs du préprocessing\n",
    "\n",
    "- **Élimination des variables non pertinentes** : Suppression des identifiants techniques (`track_id`, `album_id`, `playlist_id`) qui n'apportent pas d'information analytique\n",
    "- **Gestion des valeurs manquantes** : Identification et traitement des données incomplètes pour éviter les biais dans les analyses\n",
    "- **Standardisation des types de données** : Conversion des variables catégorielles et temporelles dans les formats appropriés\n",
    "- **Déduplication intelligente** : Conservation des versions les plus populaires des morceaux dupliqués\n",
    "- **Harmonisation des unités** : Conversion de la durée en secondes pour une meilleure interprétabilité\n",
    "\n",
    "### Impact sur les analyses multivariées\n",
    "\n",
    "Un preprocessing rigoureux garantit :\n",
    "- Des résultats d'ACP non biaisés par des échelles de variables hétérogènes\n",
    "- Une MCA cohérente avec des modalités catégorielles bien définies\n",
    "- Des algorithmes de clustering et de réduction de dimension plus performants\n",
    "- Une meilleure généralisation des modèles de recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/spotify_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)\n",
    "display(data.describe().T.style.background_gradient(cmap='YlGnBu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "display(missing_values)\n",
    "\n",
    "# display the lines with missing values\n",
    "missing_data = data[data.isnull().any(axis=1)]\n",
    "display(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id columns\n",
    "data = data.drop(columns=['track_id', 'track_album_id', \"playlist_id\"], axis=1)\n",
    "# drop the missing values\n",
    "data = data.dropna()\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform track_album_release_date into datetime\n",
    "data['track_album_release_date'] = pd.to_datetime(data['track_album_release_date'], format='mixed')\n",
    "\n",
    "# transform categorical columns into categorical data type\n",
    "categorical_cols = ['playlist_genre', 'playlist_subgenre', 'track_artist', 'playlist_name', 'track_album_name']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# transform the duration_ms into minutes\n",
    "data['duration_s'] = data['duration_ms'] / 1000\n",
    "data.drop(columns=['duration_ms'], inplace=True)\n",
    "\n",
    "# For numeric columns that represent discrete values (like key and mode), convert to categorical\n",
    "key_mapping = {\n",
    "    0: 'C', 1: 'C♯/D♭', 2: 'D', 3: 'D♯/E♭', 4: 'E', 5: 'F',\n",
    "    6: 'F♯/G♭', 7: 'G', 8: 'G♯/A♭', 9: 'A', 10: 'A♯/B♭', 11: 'B'\n",
    "}\n",
    "data['key'] = data['key'].map(key_mapping).astype('category')\n",
    "\n",
    "data['mode'] = data['mode'].map({0: 'Minor', 1: 'Major'}).astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "display(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data.select_dtypes(include='number')\n",
    "cat = data.select_dtypes(include='category')\n",
    "print('Data quantitative :', round(100*num.shape[1]/data.shape[1], 2), '%')\n",
    "print('Data qualitative :', round(100*cat.shape[1]/data.shape[1], 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copier data dans data_songs\n",
    "data_songs = data.copy()\n",
    "\n",
    "# observer les données dupliquées sur toutes les colonnes\n",
    "duplicates = data_songs.duplicated().sum()\n",
    "print(f'Number of duplicates: {duplicates}')\n",
    "\n",
    "# Nombre de valeurs dupliquées avant suppression\n",
    "initial_duplicates = data_songs.duplicated(subset=['track_artist', 'track_name']).sum()\n",
    "print(f'Initial number of duplicates: {initial_duplicates}')\n",
    "\n",
    "# Supprimer les colonnes 'playlist'\n",
    "data_songs = data_songs.drop(columns=['playlist_genre', 'playlist_subgenre', 'playlist_name'])\n",
    "\n",
    "# Regarder le nombre de doublons après suppression\n",
    "duplicates = data_songs.duplicated().sum()\n",
    "print(f'Number of duplicates - après suppression des playlists : {duplicates}')\n",
    "\n",
    "# Supprimer les doublons\n",
    "data_songs = data_songs.drop_duplicates()\n",
    "\n",
    "# regarder le nombre de doublons en fonction de 'track_artist' et 'track_name'\n",
    "duplicates = data_songs.duplicated(subset=['track_artist', 'track_name']).sum()\n",
    "print(f'Number of duplicates - en se basant sur le nom d artiste de la track et : {duplicates}')\n",
    "\n",
    "# garder dans data_songs les lignes dupliquées ayant la popularité la plus élevée\n",
    "data_songs = data_songs.sort_values('track_popularity', ascending=False).drop_duplicates(subset=['track_artist', 'track_name'])\n",
    "# regarder le nombre de doublons en fonction de 'track_artist' et 'track_name'\n",
    "duplicates = data_songs.duplicated().sum()\n",
    "print(f'Number of duplicates - après suppression des supposés doublons : {duplicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier data_songs par l'index 'idx'\n",
    "data_songs.sort_index(inplace=True)\n",
    "\n",
    "display(data_songs[-5:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce pré-processing de nos données, nous avons fait différents choix pour traiter nos données qui sont les suivantes :\n",
    "* Nous avons supprimé les lignes du jeu avec des valeurs manquantes (nom d'artiste, de morceau...), et nous avons constaté qu'uniquement **5 lignes** avaient des données non spécifiées. Nous avons donc fait le choix de les supprimer en supposant que cela n'aurait pas d'impact, étant donné la taille du jeu de données initial.\n",
    "* Nous avons également supprimé les colonnes qui représentaient les identifiants des artistes, playlists et morceaux car nous avons décidé de ne pas nous baser dessus dans notre étude car c'est une suite de lettres et de chiffres. \n",
    "* Nous avons effectué quelques modifications sur les variables, en transformant certaines variables numériques en variables catégoriques et certains format d'affichage. \n",
    "\n",
    "Nous avons finalement souhaité étudier notre jeu de données initial en considérant deux jeux. Ce sont les suivants :\n",
    "* Dans certains cas nous utilisons le **jeu de données initialement fourni** (avec les modification effectuées dessus).\n",
    "* Dans d'autres cas nous utilisons un **jeu de données qui ne se base pas sur les playlists** auxquels les morceaux sont associés. Cela a permis de ne pas considérer les morceaux présents dans plusieurs playlists (identiques ou différentes) afin de pouvoir considérer uniquement leurs caractéristiques. De plus, afin de supprimer les éventuels *doublons* présents, nous avons fait le choix de conserver le morceau ayant la plus haute popularité. En effet, certains artistes sortent des EP et ces mêmes EPs sont également présents dans des albums, mais n'ont pas la même popularité. Donc pour ne pas biaiser d'éventuelles analyses, ce choix a été fait. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse exploratoire "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse univariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour tracer les variables en fonction du type d'affichage voulu\n",
    "def plot_specific_variables(data, variable_plot_map):\n",
    "    num_plots = len(variable_plot_map)\n",
    "    fig, axes = plt.subplots(nrows=(num_plots + 1) // 2, ncols=4, figsize=(18, 6 * ((num_plots + 3) // 4)))#, constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    plot_index = 0\n",
    "\n",
    "    for var, plot_type in variable_plot_map.items():\n",
    "        if plot_type == 'histogram':\n",
    "            sns.histplot(data[var], kde=True, ax=axes[plot_index])\n",
    "            axes[plot_index].set_title(f'Distribution of {var}')\n",
    "            axes[plot_index].set_xlabel(var)\n",
    "            axes[plot_index].set_ylabel('Frequency')\n",
    "        elif plot_type == 'countplot':\n",
    "            sns.countplot(x=var, data=data, order=data[var].value_counts().index, ax=axes[plot_index])\n",
    "            axes[plot_index].set_title(f'Count of {var}')\n",
    "            axes[plot_index].set_xlabel(var)\n",
    "            axes[plot_index].set_ylabel('Frequency')\n",
    "        elif plot_type == 'boxplot':\n",
    "            sns.boxplot(x=data[var], ax=axes[plot_index])\n",
    "            axes[plot_index].set_title(f'Boxplot of {var}')\n",
    "            axes[plot_index].set_xlabel(var)\n",
    "            axes[plot_index].set_ylabel('Frequency')\n",
    "        elif plot_type == 'kde':\n",
    "            sns.kdeplot(data[var], ax=axes[plot_index])\n",
    "            axes[plot_index].set_title(f'KDE of {var}')\n",
    "            axes[plot_index].set_xlabel(var)\n",
    "            axes[plot_index].set_ylabel('Density')\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown plot type: {plot_type}\")\n",
    "\n",
    "        plot_index += 1\n",
    "\n",
    "    # Masquer les sous-graphiques non utilisés\n",
    "    for i in range(plot_index, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappage des variables aux types de graphiques\n",
    "variable_plot_map = {\n",
    "    'track_popularity': 'histogram',\n",
    "    'danceability': 'histogram',\n",
    "    'energy': 'histogram',\n",
    "    'loudness': 'histogram',\n",
    "    'acousticness': 'histogram',\n",
    "    'valence': 'histogram',\n",
    "    'tempo': 'histogram',\n",
    "    'duration_s': 'histogram'\n",
    "}\n",
    "\n",
    "plot_specific_variables(data_songs, variable_plot_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater que la majorité des caractéristiques représentées suivent une distribution qui semble normale.  \n",
    "\n",
    "Concernant la distribution de la **popularité**, il y a une grande fréquence de morceaux dont la popularité est nulle. Cela s'explique par les critères de notations de *Spotify*, qui note la popularité d'un morceaux en fonction de ses écoutes, si elles ont étés nombreuses ou encore récentes.  \n",
    "\n",
    "L'**acoustique** d'un morceau est noté entre 0.0 et 1.0. \n",
    "* 0.0 représente un morceau perçu comme non acoustique.\n",
    "* 1.0 représente à l'inverse un morceau acoustique.  \n",
    "  \n",
    "Grâce à la  distribution, nous pouvons constater qu'une grande fréquence des morceaux présents dans ce jeu possèdent une acoustique nulle, cela peut déjà donner une première analyse sur le fait que le jeu de données est principalement composé de musiques de type *électronique* ou *synthétique*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé ensuite de créer des intervalles pour certaines variables afin qu'elles soient plus facilement interprétables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_speechiness = [-float('inf'), 0.33, 0.66, float('inf')]\n",
    "labels_speechiness = ['<0.33', '[0.33;0.66]', '>0.66']\n",
    "data_songs['speechiness_interval'] = pd.cut(data_songs['speechiness'], bins=bins_speechiness, labels=labels_speechiness)\n",
    "\n",
    "bins_instrumentalness = [-float('inf'), 0.5, float('inf')]\n",
    "labels_instrumentalness = ['<=0.5', '>0.5']\n",
    "data_songs['instrumentalness_interval'] = pd.cut(data_songs['instrumentalness'], bins=bins_instrumentalness, labels=labels_instrumentalness)\n",
    "\n",
    "bins_liveness = [-float('inf'), 0.8, float('inf')]\n",
    "labels_liveness = ['<=0.8', '>0.8']\n",
    "data_songs['liveness_interval'] = pd.cut(data_songs['liveness'], bins=bins_liveness, labels=labels_liveness)\n",
    "\n",
    "speechiness_counts = data_songs['speechiness_interval'].value_counts().sort_index()\n",
    "instrumentalness_counts = data_songs['instrumentalness_interval'].value_counts().sort_index()\n",
    "liveness_counts = data_songs['liveness_interval'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "# Créer une figure avec 3 sous-graphiques sur une même ligne\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Premier graphique : speechiness_interval\n",
    "axes[0].bar(range(len(speechiness_counts)), speechiness_counts.values, color='skyblue')\n",
    "axes[0].set_xticks(range(len(speechiness_counts)))\n",
    "axes[0].set_xticklabels(speechiness_counts.index, rotation=45)\n",
    "axes[0].set_title('Distribution des intervalles de paroles')\n",
    "axes[0].set_xlabel('Intervalle de paroles')\n",
    "axes[0].set_ylabel('Fréquence')\n",
    "\n",
    "# Deuxième graphique : instrumentalness_interval\n",
    "axes[1].bar(range(len(instrumentalness_counts)), instrumentalness_counts.values, color='lightcoral')\n",
    "axes[1].set_xticks(range(len(instrumentalness_counts)))\n",
    "axes[1].set_xticklabels(instrumentalness_counts.index, rotation=45)\n",
    "axes[1].set_title('Distribution des intervalles d\\'instrumentalité')\n",
    "axes[1].set_xlabel('Intervalle d\\'instrumentalité')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "\n",
    "# Troisième graphique : liveness_interval\n",
    "axes[2].bar(range(len(liveness_counts)), liveness_counts.values, color='lightgreen')\n",
    "axes[2].set_xticks(range(len(liveness_counts)))\n",
    "axes[2].set_xticklabels(liveness_counts.index, rotation=45)\n",
    "axes[2].set_title('Distribution des intervalles de présence live')\n",
    "axes[2].set_xlabel('Intervalle de présence live')\n",
    "axes[2].set_ylabel('Fréquence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables speechiness, instrumentalness et liveness, les intervalles dans lesquels les morceaux ont été classés, s'interprètent de la manière suivante : \n",
    "* **speechiness :** \n",
    "  * $<0.33$ : faible présence de paroles\n",
    "  * $[0.33,0.66]$ : présence modérée de paroles\n",
    "  * $>0.66$ : forte présence de paroles \n",
    "* **instrumentalness :** \n",
    "  * $\\le 0.5$ : peu ou pas instrumental\n",
    "  * $>0.5$ : très instrumental\n",
    "* **liveness :** \n",
    "  * $\\le 0.8$ : morceau probablement produit en studio\n",
    "  * $>0.8$ : morceau probablement produit en live (concert, public)\n",
    "\n",
    "D'après les distributions obtenues, la majorité des morceaux sont considérés comme possédant peu de paroles et qui n'ont pas été produits en live. Concernant l'instrumentalité des morceaux, nous pouvons difficilement conclure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Années de sortie des albums**\n",
    "\n",
    "Nous avons fait le choix de regrouper les albums par la décennie de leur sortie. Cela permet d'avoir une analyse plus pertinente que si l'on regardait par années de sortie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On extrait l'année de la date de sortie de l'album\n",
    "data_songs['release_year'] = data_songs['track_album_release_date'].dt.year # type: ignore\n",
    "\n",
    "# Création d'une nouvelle colonne pour les décennies\n",
    "data_songs['decade'] = (data_songs['release_year'] // 10) * 10 # type: ignore\n",
    "\n",
    "decade_counts = data_songs['decade'].value_counts().sort_index()\n",
    "\n",
    "# Tracer la distribution des décennies\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=decade_counts.index, y=decade_counts.values, palette='viridis')\n",
    "plt.title('Distribution des décennies de sortie des albums')\n",
    "plt.xlabel('Décennie')\n",
    "plt.ylabel('Nombre de chansons')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La majorité des morceaux inclus dans le jeu de données sont des morceaux parus pendant les années 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse multivariée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes numériques\n",
    "numeric_columns = data_songs.select_dtypes(include=['int64', 'float64'])\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables semblent très peu corrélées entre-elles pour la plupart, mais nous pouvons néanmoins constater les corrélations qui suivent.  \n",
    "- **Corrélation positive :** \n",
    "    - *loudness* et *energy* : corrélation forte (0.69). Cela semble cohérent, on lie le dynamisme d'un morceau au bruit ressenti.\n",
    "    - *valence* et *danceability* : légère corrélation (0.33). La valence mesure la positivité d'un morceau. Donc si celui-ci fait ressentir de la positivité, il y aura une tendance à donner l'envie de danser dessus.\n",
    "\n",
    "- **Corrélation négative :**\n",
    "    - *acousticness* et *energy* : corrélation négative modérée (-0.55). Plus une musique est perçue comme acoustique, moins elle est perçue comme énergique. Cela permet d'opposer des morceaux calmes à des morceaux dynamiques. \n",
    "    - *acousticness* et *loudness* : corrélation négative modérée (-0.38). Cela met en avant l'opposition entre un morceau bruyant et un morceau calme (acoustique).\n",
    "\n",
    "Pour le reste on a des corrélations assez faibles, qu'elles soient positives ou négatives. Cela ne nous permet pas de mettre en avant d'autres liens entre les variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "sns.scatterplot(x='loudness', y='energy', hue='track_popularity', data=data_songs, palette='viridis', alpha=0.7, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Loudness vs Energy')\n",
    "axes[0, 0].set_xlabel('Loudness')\n",
    "axes[0, 0].set_ylabel('Energy')\n",
    "\n",
    "sns.scatterplot(x='danceability', y='valence', hue='track_popularity', data=data_songs, palette='viridis', alpha=0.7, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Danceability vs Valence')\n",
    "axes[0, 1].set_xlabel('Danceability')\n",
    "axes[0, 1].set_ylabel('Valence')\n",
    "\n",
    "sns.scatterplot(x='acousticness', y='energy', hue='track_popularity', data=data_songs, palette='viridis', alpha=0.7, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Acousticness vs Energy')\n",
    "axes[1, 0].set_xlabel('Acousticness')\n",
    "axes[1, 0].set_ylabel('Energy')\n",
    "\n",
    "sns.scatterplot(x='acousticness', y='loudness', hue='track_popularity', data=data_songs, palette='viridis', alpha=0.7, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Acousticness vs Loudness')\n",
    "axes[1, 1].set_xlabel('Acousticness')\n",
    "axes[1, 1].set_ylabel('Loudness')\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.get_legend().remove() \n",
    "    \n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title='Popularity', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.suptitle('Scatterplots des corrélations entre les variables quantitatives (colorés par popularité)',\n",
    "             fontsize=22)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96], w_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de vérifier ces corrélations, nous avons affiché les scatterplots les représentant.  \n",
    "Les deux premiers graphiques (première ligne) représentent bien des **corrélations positives**, en effet à mesure qu'une des deux variables augmente, la seconde aussi.   \n",
    "Pour les deux autres graphiques (seconde ligne), à l'inverse nous remarquons bien la **corrélation négative**. En effet lorsqu'une des deux variables évolue, la seconde diminue.   \n",
    "\n",
    "Nous avons décidé d'effectuer l'affichage en fonction de la popularité, mais comme nous pouvous le voir, il y a des morceaux de différentes popularités qui sont placés aux mêmes endroits, nous pouvons donc penser que la popularité n'a aucune influence sur les variables représentées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des variables quantitatives et qualitatives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étude de la popularité des morceaux par années**  \n",
    "Comme cela a été présenté dans le pré-processing, nous étudions le jeu de données dans lequel nous avons extrait les morceaux uniques en gardant celui qui avait la popularité la plus haute, si ce même morceau était présent plusieurs fois.   \n",
    "Cette popularité est calculée en fonction du nombre d'écoutes et si ces mêmes écoutes ont été récentes ou non. \n",
    "\n",
    "Nous allons ici étudier la date de sortie des morceaux en fonction de leur popularité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la moyenne de popularité par année\n",
    "popularity_by_year = data_songs.groupby('release_year')['track_popularity'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='release_year', y='track_popularity', data=popularity_by_year, marker='o')\n",
    "plt.title('Popularité moyennes des morceaux par années')\n",
    "plt.xlabel('Année')\n",
    "plt.ylabel('Popularité moyenne')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_by_decade = data_songs.groupby('decade')['track_popularity'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x='decade', y='track_popularity', data=popularity_by_decade, marker='o')\n",
    "plt.title('Popularité moyenne des morceaux par décénnies')\n",
    "plt.xlabel('décénnie')\n",
    "plt.ylabel('Popularité moyenne')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre total de morceaux par décennie\n",
    "count_by_decade = data_songs['decade'].value_counts().sort_index()\n",
    "std_by_decade = data_songs.groupby('decade')['track_popularity'].std()\n",
    "\n",
    "# Nombre de morceaux non notés (popularité = 0) par décennie\n",
    "count_zero_popularity_by_decade = data_songs[data_songs['track_popularity'] == 0].groupby('decade').size()\n",
    "proportion_zero_popularity = (count_zero_popularity_by_decade / count_by_decade * 100).fillna(0)\n",
    "\n",
    "proportion_df = pd.DataFrame({\n",
    "    'Nb total de morceaux': count_by_decade,\n",
    "    '% de morceaux non notés': proportion_zero_popularity.round(2),\n",
    "    '% de morceaux notés' : 100-proportion_zero_popularity.round(2),\n",
    "    'Ecart-type': std_by_decade.round(2)\n",
    "}).fillna(0)\n",
    "\n",
    "print(\"\\nProportion de morceaux non notés par décennie :\")\n",
    "print(proportion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Par années :**\n",
    "- Sur le premier graphe on peut lire la popularité moyenne des morceaux par année. Cela reste difficilement interprétable car il y a beaucoup de variations. \n",
    "- Nous pouvons néanmoins constater qu'avant 1960 il y a une tendance de popularité haute, mais qu'après ça oscille entre 30 et 50/60. \n",
    "- La moyenne de popularité totale est de 40.45.  \n",
    "\n",
    "Pour une interprétation plus globale nous avons regardé la popularité des morceaux en les regroupant par décennie de parution.\n",
    "\n",
    "**Par décennies :**\n",
    "  - On a une tendance de popularité très haute pour les musiques sorties entre 1950-1980. Cela peut s'expliquer notamment pour les musiques sorties entre 1950-60 : \n",
    "      - Peu de musiques sorties pendant ces années sont présentes dans le jeu de données.\n",
    "      - Il y a une moins grande diversité dans les notes comme il y a moins de musiques. Donc si celles-ci sont très bien notées alors ces années auront nécessairement une moyenne de popularité élevée.\n",
    "      - Si nous croisons ces résultats à l'écart-type associé qui est élevé, nous pouvons conclure que par le faible nombre de morceaux, cette décennie n'est pas représentative. Les décennies suivantes sont plus stables. \n",
    "  - Le minimum des moyennes de popularité par décennie est atteint pour les musiques des années 2000 :\n",
    "      - Cela peut s'expliquer par le nombre de morceaux qui n'ont pas de note de popularité, avec presque 19% des morceaux qui ont une note de 0. \n",
    "      - Donc soit ces morceaux n'ont été que très peu écoutés, soit les morceaux n'ont pas connu de succès, augmentant l'écart-type par rapport aux années précédentes. \n",
    "  - À l'inverse, dès 2020, la dispersion est plus faible avec peu de morceaux non notés, mais un nombre de morceaux assez faible, donc les morceaux ont une popularité en moyenne assez similaire avec moins de morceaux à succès et non succès extrêmes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse multivariée en incluant le genre des playlists\n",
    "**Analyse univariée sur les genres des playlists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du nombre de musiques par genre/sous-genre\n",
    "genre_counts = data['playlist_genre'].value_counts()\n",
    "subgenre_counts = data['playlist_subgenre'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "genre_counts.plot(kind='bar', color='skyblue', ax=axes[0])\n",
    "axes[0].set_title('Nombre de musiques par genre')\n",
    "axes[0].set_xlabel('Genre')\n",
    "axes[0].set_ylabel('Fréquence')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "subgenre_counts.plot(kind='barh', color='lightcoral', ax=axes[1])\n",
    "axes[1].set_title('Nombre de musiques par sous-genre')\n",
    "axes[1].set_xlabel('Fréquence')\n",
    "axes[1].set_ylabel('Sous-genre')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['playlist_genre'], data['playlist_subgenre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On compte le nombre de playlists différentes par genre\n",
    "playlists_per_genre = data.groupby('playlist_genre', observed=False)['playlist_name'].nunique()\n",
    "\n",
    "print(\"Nombre de playlists différentes par genre :\")\n",
    "print(playlists_per_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons effectué une rapide analyse univariée sur les genres et les sous-genres des playlists, donc sur le jeu de donné fourni initialement.   \n",
    "\n",
    "Nous pouvons remarquer que le nombre de playlists par genre est plutôt équilibré avec en moyenne 76 playlists par genres. Néanmoins, on peut constater que le genre **EDM** est majoritairement présent dans le jeu de données, et que le genre **rock** est celui qui est minoritaire. Le reste des genres se différencie uniquement de quelques centaines de morceaux.  \n",
    "De plus, chaque sous-genre est associé à un unique genre, dont la répartition a été affichée. \n",
    "\n",
    "Nous allons maintenant croiser ces données avec nos autres variables afin de voir si nous pouvons trouver des relations ou non. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des statistiques descriptives par genre\n",
    "columns_to_analyze = ['danceability', 'energy', 'tempo', 'loudness']\n",
    "stats_by_genre = data.groupby('playlist_genre', observed=False)[columns_to_analyze].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "\n",
    "stats_by_genre.columns = ['_'.join(col).strip() for col in stats_by_genre.columns.values]\n",
    "\n",
    "print(\"Statistiques descriptives par genre :\")\n",
    "display(stats_by_genre)\n",
    "\n",
    "# Affichage des moyennes\n",
    "mean_by_genre = stats_by_genre.filter(like='_mean')\n",
    "mean_by_genre.columns = ['danceability_mean', 'energy_mean', 'tempo_mean', 'loudness_mean']\n",
    "display(mean_by_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'valence', 'tempo', 'track_popularity', 'duration_s'\n",
    "]\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = (len(variables) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "handles, labels = None, None\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    ax = axes[i]\n",
    "    for genre in data['playlist_genre'].cat.categories:\n",
    "        subset = data[data['playlist_genre'] == genre]\n",
    "        sns.kdeplot(subset[var], ax=ax, label=genre, fill=False, linewidth=1.5)\n",
    "    ax.set_title(f'Distribution de {var} par genre')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('Densité')\n",
    "    ax.grid(True)\n",
    "    if handles is None and ax.get_legend_handles_labels()[0]:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "\n",
    "for j in range(len(variables), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if handles and labels:\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc='lower left',\n",
    "        bbox_to_anchor=(0.75, 0.08),\n",
    "        ncol=2,  \n",
    "        fontsize=16,\n",
    "        frameon=False,\n",
    "    )\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'essayer de comprendre les spécificités des morceaux présents dans le jeu de données, nous avons analysé les différentes **distributions des variables quantitatives** selon le genre des playlists. L'objectif est d'identifier ici les différences pouvant caractériser les genres musicaux. Ces courbes de densité permettent de visualiser où se concentrent la majorité des morceaux.  \n",
    "\n",
    "<u>*Analyse des distributions et des genres :*</u>\n",
    "\n",
    "* **Danceability :**\n",
    "  * Le genre **latin** et le **rap** se distinguent particulièrement avec des valeurs de danceability proche de 0.8, indiquant des morceaux très dansants pour ces genres. \n",
    "  * À l'inverse, le genre **rock** est plus dispersé, indiquant que certains morceaux sont très dansants, d'autres pas du tout.\n",
    "  \n",
    "* **EDM**\n",
    "  * Ce genre semble se distinguer sur plusieurs points, en effet d'après les distributions, les morceaux du type EDM auront tendance à donner un ressenti **dynamique (energy)** (densité autour de 0.9), **bruyant** et se dinstingue par son **tempo** se trouvant autour de 130 BPM, valeur caractérisant généralement les morceaux d'EDM, techno...\n",
    "  * Néanmoins, les musiques de ce genre musical ne semblent pas être ressenties comme positives ou joyeuses d'après leur valence.\n",
    "  * Et on retrouve bien la corrélation négative avec l'**acousticness**.\n",
    "  \n",
    "* **Popularity :**\n",
    "  * Si l'on ne prend en compte le pic à 0 (qui concerne les morceaux non notés), mais seulement au second pic, on peut remarquer :\n",
    "    * **EDM** semble être le genre le moins populaire, mais la présence de la queue de distribution vers les valeurs élevées peut traduire la présence de morceaux à succès. \n",
    "    * Le **rap** possède une popularité plutôt moyenne par rapport aux autres genres, et ne semble pas avoir beaucoup de morceaux ayant connu un grand succès, mais l'inverse est aussi vrai, il ne semble pas y avoir beaucoup de morceaux à faible audience.\n",
    "    * La **pop** et **latin** sont les genres les plus populaires.\n",
    "\n",
    "* **Energy :**\n",
    "  * L'**EDM** est le genre le plus dynamique. \n",
    "  * La distribution plus large pour les genres comme **r&b**, **rap** ou encore **latin** aura plutôt tendance à indiquer que ces genres regroupent à la fois des morceaux calmes et énergiques.\n",
    "\n",
    "* **Valence :**\n",
    "  * Le genre **latin** se distingue particulièrement par sa valence élevée, traduisant des musiques plutôt joyeuses.\n",
    "  * La distribution globale de la valence est large (tous genres confondus) traduisant une grande diversité émotionnelle produite par les morceaux des différents genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = (len(variables) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "handles, labels = None, None\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    ax = axes[i]\n",
    "    for genre in data['playlist_subgenre'].cat.categories:\n",
    "        subset = data[data['playlist_subgenre'] == genre]\n",
    "        sns.kdeplot(subset[var], ax=ax, label=genre, fill=False, linewidth=1.5)\n",
    "    ax.set_title(f'Distribution de {var} par genre')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('Densité')\n",
    "    ax.grid(True)\n",
    "    if handles is None and ax.get_legend_handles_labels()[0]:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "for j in range(len(variables), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if handles and labels:\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc='lower left',\n",
    "        bbox_to_anchor=(0.7, 0.03),\n",
    "        ncol=2,  \n",
    "        fontsize=12,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons effectué le même affichage pour les sous-genres, qui sont un petit moins lisibles. Néanmoins, pour les analyses que nous avons fait précédemment, nous retrouvons les mêmes principales caractéristiques pour les sous-genres associés. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réduction de dimension\n",
    "Dans cette partie, nous allons effectuer une analyse en composantes principales (ACP) sur les données prétraitées. L'ACP est une technique de réduction de dimension qui permet de projeter les données d'origine dans un espace de dimension inférieure.\n",
    "Nous avons gardé 20 variables et nous allons étudier s'il est possible de réduire la dimensionnalité de ces données tout en préservant un maximum d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on ne sélectionne que les variables quantitatives, en y ajoutant une variable qualitative (`playlist_genre`) pour voir si elle a un impact sur la projection des données. On garde au final 11 variables quantitatives et 1 variable qualitative.\n",
    "\n",
    "On décide de normaliser les données pour que chaque variable ait une moyenne de 0 et un écart-type de 1. Cela est important car l'ACP est sensible à l'échelle des variables. On utilise la méthode `StandardScaler` de `sklearn` pour normaliser les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the quantitative columns\n",
    "\n",
    "qualisup = 'playlist_genre'\n",
    "\n",
    "data_quanti = data.select_dtypes(include=['int64', 'float64'])\n",
    "data_quanti[qualisup] = data[qualisup]\n",
    "data_quanti = data_quanti.set_index(qualisup)\n",
    "\n",
    "data_quanti.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quanti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en Composantes Principales (ACP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import prince \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalize_bool = True\n",
    "\n",
    "if normalize_bool:\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data_quanti)\n",
    "else:\n",
    "    data_scaled = data_quanti.values\n",
    "\n",
    "pca = PCA(\n",
    "    n_components=10,  # Number of components to keep\n",
    "    random_state=1  # For reproducibility\n",
    ")\n",
    "\n",
    "projected = pca.fit_transform(data_scaled)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "eig = pd.DataFrame(\n",
    "    {\n",
    "        \"Dimension\" : [f\"PC{i+1}\" for i in range(len(explained_variance))],\n",
    "        \"Variance\" : np.round(pca.explained_variance_, 2),\n",
    "        \"% explained variance\" : np.round(explained_variance*100, 1),\n",
    "        \"% cumulative variance\" : np.round(np.cumsum(explained_variance)*100, 1)\n",
    "    }\n",
    ")\n",
    "eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22,8))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.bar(range(10), pca.explained_variance_ratio_[:10]*100, align='center',\n",
    "        color='#F69F1D', ecolor='black')\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_ylabel(\"Variance\")\n",
    "ax.set_title(\"\", fontsize=35)\n",
    "ax.set_title(u\"Pourcentage de variance expliqué\", fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.plot(np.cumsum(pca.explained_variance_ratio_), color='#F69F1D', marker='o')\n",
    "ax.hlines(0.80, 0, 10, colors='grey', linestyles='dashed', alpha=0.5)\n",
    "ax.set_title(u'Pourcentage de variance expliqué cumulé', fontsize=20)\n",
    "\n",
    "fig.suptitle(u\"Résultat ACP\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :** \n",
    "\n",
    "L’analyse de la variance expliquée montre que les **7 premières composantes principales** permettent de **représenter 80,1 % de la variance totale** du jeu de données. Cela signifie que l’essentiel de l’information contenue dans les **11 variables numériques initiales** (comme *danceability*, *energy*, *speechiness*, *tempo*, etc.) peut être résumé avec seulement 7 dimensions, ce qui représente une **réduction significative de la complexité** du dataset tout en conservant une bonne qualité descriptive.\n",
    "\n",
    "Dans cette optique de réduction de dimension, il serait **pertinent de conserver ces 7 composantes principales** pour la suite des analyses (clustering, visualisation, classification), car elles capturent la structure principale des données tout en éliminant le \"bruit\".\n",
    "\n",
    "Dans l’analyse factorielle, nous avons choisi d’**interpréter les trois premières composantes principales**, qui à elles seules expliquent 45 % de la variance totale. Elles offrent un bon compromis entre lisibilité et pertinence pour une visualisation ou une première analyse des relations entre les variables et les genres musicaux (*playlist_genre*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "box=plt.boxplot(projected[:,0:3],whis=100)\n",
    "plt.title(u\"Distribution des premières composantes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "- Le graphique ci-dessus montre la distribution des premières composantes principales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_prince = prince.PCA(\n",
    "    n_components=3,\n",
    "    n_iter=3,\n",
    "    rescale_with_mean=normalize_bool,\n",
    "    rescale_with_std=normalize_bool,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=1\n",
    ")\n",
    "pca_prince = pca_prince.fit(\n",
    "    data_quanti,\n",
    "    sample_weight=None,\n",
    "    column_weight=None,\n",
    "    supplementary_columns=None\n",
    ")\n",
    "\n",
    "# Create a correlation matrix of the PCA compnenets\n",
    "correlations = pca_prince.column_correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlations, annot=True, cmap='RdBu', center=0)\n",
    "plt.title('Corrélations entre les variables et les composantes principales')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des coordonnées des variables (correlations avec les composantes principales)\n",
    "coords = pca_prince.column_correlations\n",
    "\n",
    "# Création de la figure et des sous-graphiques\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "# Boucle pour créer les trois graphiques\n",
    "for idx, (ax, (x_comp, y_comp)) in enumerate(zip(axes, [(0, 1), (1, 2), (0, 2)])):\n",
    "    ax.grid(False)\n",
    "    for i in range(coords.shape[0]):\n",
    "        ax.arrow(0, 0, coords.iloc[i, x_comp], coords.iloc[i, y_comp], \n",
    "                 color='black', alpha=0.7, head_width=0.02, head_length=0.03)\n",
    "        ax.text(coords.iloc[i, x_comp] * 1.1, coords.iloc[i, y_comp] * 1.1, \n",
    "                coords.index[i], color='black', ha='center', va='center')\n",
    "\n",
    "    # Ajout du cercle de rayon 1\n",
    "    ax.add_artist(plt.Circle((0, 0), radius=1, color='cornflowerblue', fill=False))\n",
    "\n",
    "    # Ajout des axes\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    ax.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Paramètres du graphique\n",
    "    ax.set_xlim(-1.1, 1.1)\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.set_xlabel(f'Composante principale {x_comp + 1}')\n",
    "    ax.set_ylabel(f'Composante principale {y_comp + 1}')\n",
    "    ax.set_title(f'Projection des variables: CP{x_comp + 1} vs CP{y_comp + 1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table des correlations et les trois graphiques ci-dessus représentent les projections des features sur les trois premières composantes principales nous donne des informations sur la structure des données réduites.\n",
    "\n",
    "- **Composante principale 1** : \n",
    "    - Les variables `energy (-0.91)`, `loudness (-0.80)` et `acousticness (+0.72)` sont linéairement corrélées avec la première composante principale, en soulignant que `energy` et `loudness` sont inversément corrélées avec `acousticness`. Cela indique que la CP1 oppose les morceaux **énergiques, forts en volume et peu acoustiques** (ex : rock, électro) aux morceaux **calmes, acoustiques et peu énergétiques** (ex : folk, classique).\n",
    "- **Composante principale 2** : Sur le graphique de gauche, on remarque une opposition des variables `instrumentalness (+0.45)`, `duration_s (+0.38)` contre `danceability (-0.68)`, `valence (-0.62)`, `track_popularity (-0.37)`, `speechiness (-0.39)`. Cette composante principale oppose deux profils de morceaux :\n",
    "    - D’un côté, les morceaux **instrumentaux, longs et peu populaires** (forte contribution de `instrumentalness` et `duration_s`), souvent associés à des genres comme le classique ou le jazz.\n",
    "    - De l’autre, les chansons **courtes, dansantes, joyeuses et populaires** (forte contribution de `danceability`, `valence` et `track_popularity`), typiques de la pop ou de la musique de club. \n",
    "    - Enfin, cette opposition suggère que les morceaux avec des paroles marquées (`speechiness`) et une structure rythmique engageante (`danceability`) sont plus susceptibles de générer de la popularité.\n",
    "- **Composantes principales 2 et 3** : Sur le graphique au centre, on peut extraire plusieurs informations :\n",
    "    - Les morceaux dansants et joyeux (haute valence) s'opposent dans une moindre mesure aux morceaux de faible tempo. De plus, ces morceaux semblent avoir peu de versions live.\n",
    "    - On observe aussi que les morceaux instrumentaux et longs ont généralement une faible popularité, tandis que les morceaux courts et peu instrumentaux sont souvent plus populaires, ce qui est typique de la musique pop, qui est souvent plus accessible et commerciale.\n",
    "- **Composante principale 3** : La troisième composante (CP3) révèle un paradoxe : elle regroupe des morceaux à fort potentiel dansant (`danceability`) et mood positif (`valence`), mais qui restent peu populaires (`track_popularity`). Ces morceaux sont souvent instrumentaux (`instrumentalness`), longs (`duration_s`) et à tempo faible (`tempo`), ce qui les éloigne des standards des charts. Cette composante pourrait représenter des créations artistiques équilibrant danse et complexité, mais peinant à atteindre un large public.\n",
    "\n",
    "Pour mieux comprendre à quoi correspond les type morceaux extraits par ces composantes principales, nous allons regarder les morceaux (individus) contribuant le plus à chacune des composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display la mediane de notre dataset quantitatif à fins de comparaison\n",
    "median_values = data_quanti.median()\n",
    "median_values = median_values.to_frame(name='median')\n",
    "median_values = median_values.reset_index()\n",
    "median_values.columns = ['feature', 'median']\n",
    "median_values['feature'] = median_values['feature'].astype('category')\n",
    "median_values = median_values.set_index('feature')\n",
    "median_values = median_values.sort_index()\n",
    "median_values = median_values.T\n",
    "median_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composante principale 1\n",
    "\n",
    "Afin de mieux comprendre les profils musicaux mis en évidence par la première composante principale, nous allons examiner les morceaux qui y contribuent le plus fortement, positivement et négativement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contributions of individuals to the first principal component\n",
    "contributions = projected[:, 0]\n",
    "\n",
    "# Get the indices of the top 5 positive contributors\n",
    "top_5_positive_indices = np.argsort(contributions)[-5:]\n",
    "\n",
    "# Get the indices of the top 5 negative contributors\n",
    "top_5_negative_indices = np.argsort(contributions)[:5]\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for positive contributions\n",
    "top_5_positive_tracks = data_quanti.iloc[top_5_positive_indices].copy()\n",
    "top_5_positive_tracks['track_name'] = data.iloc[top_5_positive_indices]['track_name'].values\n",
    "top_5_positive_tracks['track_artist'] = data.iloc[top_5_positive_indices]['track_artist'].values\n",
    "top_5_positive_tracks['contribution'] = contributions[top_5_positive_indices]\n",
    "top_5_positive_tracks['playlist_subgenre'] = data.iloc[top_5_positive_indices]['playlist_subgenre'].values\n",
    "# sort by contribution\n",
    "top_5_positive_tracks = top_5_positive_tracks.sort_values(by='contribution', ascending=False)\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for negative contributions\n",
    "top_5_negative_tracks = data_quanti.iloc[top_5_negative_indices].copy()\n",
    "top_5_negative_tracks['track_name'] = data.iloc[top_5_negative_indices]['track_name'].values\n",
    "top_5_negative_tracks['track_artist'] = data.iloc[top_5_negative_indices]['track_artist'].values\n",
    "top_5_negative_tracks['contribution'] = contributions[top_5_negative_indices]\n",
    "top_5_negative_tracks['playlist_subgenre'] = data.iloc[top_5_negative_indices]['playlist_subgenre'].values\n",
    "\n",
    "# Display the top 5 positive and negative tracks with additional information\n",
    "print(\"Top 5 Positive Contributions (PC1):\")\n",
    "display(top_5_positive_tracks)\n",
    "\n",
    "print(\"Top 5 Negative Contributions (PC1) :\")\n",
    "display(top_5_negative_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux cerner les types de morceaux représentés aux extrémités de la **première composante principale (PC1)**, nous avons identifié les individus (chansons) ayant les **contributions les plus élevées**, positives comme négatives.\n",
    "\n",
    "- **Du côté des contributions positives**, on retrouve majoritairement des morceaux **rock, hard rock ou pop rock** très énergiques et puissants tels que *American Idiot* (Green Day), *Beauty Queen* (BLVK SWVN) ou *ATTENTION ATTENTION* (Shinedown). Ces morceaux sont caractérisés par une **énergie élevée**, une **forte intensité sonore (loudness)** et une **faible acoustique**, ce qui confirme bien la structure mise en évidence par la CP1. Notons aussi *This Is How We Do It* (Montell Jordan), un morceau R&B énergique, qui se distingue des autres par son genre mais partage les mêmes caractéristiques acoustiques.\n",
    "\n",
    "- **À l’opposé**, les morceaux à contribution très négative sur PC1 sont des titres à **forte acoustique**, **peu énergiques** et **très faibles en loudness**. Il s'agit notamment de sons **ambiants, relaxants ou naturels**, comme *Peaceful Forest* ou *Tropical Rainforest at Dawn*, mais aussi de titres R&B ou indie très doux (*Small* de chloe moriondo). Ces morceaux incarnent l'autre extrémité de la CP1 : **des chansons calmes, acoustiques et à faible énergie**, souvent issues de sous-genres comme *tropical*, *indie poptimism* ou *new jack swing*.\n",
    "\n",
    "Cette opposition renforce l’interprétation de la **CP1 comme un axe énergie / intensité sonore vs. calme / acoustique**, pertinent pour distinguer deux grandes familles de styles musicaux dans le dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composante principale 2\n",
    "\n",
    "Pour approfondir l’interprétation de la **deuxième composante principale**, nous allons analyser les morceaux qui y contribuent le plus fortement — positivement comme négativement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contributions of individuals to the second principal component\n",
    "contributions_pc2 = projected[:, 1]\n",
    "\n",
    "# Get the indices of the top 5 positive contributors for PC2\n",
    "top_5_positive_indices_pc2 = np.argsort(contributions_pc2)[-5:]\n",
    "\n",
    "# Get the indices of the top 5 negative contributors for PC2\n",
    "top_5_negative_indices_pc2 = np.argsort(contributions_pc2)[:5]\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for positive contributions (PC2)\n",
    "top_5_positive_tracks_pc2 = data_quanti.iloc[top_5_positive_indices_pc2].copy()\n",
    "top_5_positive_tracks_pc2['track_name'] = data.iloc[top_5_positive_indices_pc2]['track_name'].values\n",
    "top_5_positive_tracks_pc2['track_artist'] = data.iloc[top_5_positive_indices_pc2]['track_artist'].values\n",
    "top_5_positive_tracks_pc2['contribution'] = contributions_pc2[top_5_positive_indices_pc2]\n",
    "top_5_positive_tracks_pc2['playlist_subgenre'] = data.iloc[top_5_positive_indices_pc2]['playlist_subgenre'].values\n",
    "# Sort by contribution\n",
    "top_5_positive_tracks_pc2 = top_5_positive_tracks_pc2.sort_values(by='contribution', ascending=False)\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for negative contributions (PC2)\n",
    "top_5_negative_tracks_pc2 = data_quanti.iloc[top_5_negative_indices_pc2].copy()\n",
    "top_5_negative_tracks_pc2['track_name'] = data.iloc[top_5_negative_indices_pc2]['track_name'].values\n",
    "top_5_negative_tracks_pc2['track_artist'] = data.iloc[top_5_negative_indices_pc2]['track_artist'].values\n",
    "top_5_negative_tracks_pc2['contribution'] = contributions_pc2[top_5_negative_indices_pc2]\n",
    "top_5_negative_tracks_pc2['playlist_subgenre'] = data.iloc[top_5_negative_indices_pc2]['playlist_subgenre'].values\n",
    "\n",
    "# Display the top 5 positive and negative tracks with additional information for PC2\n",
    "print(\"Top 5 Positive Contributions (PC2):\")\n",
    "display(top_5_positive_tracks_pc2)\n",
    "\n",
    "print(\"Top 5 Negative Contributions (PC2):\")\n",
    "display(top_5_negative_tracks_pc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Côté contributions positives**, on retrouve des titres principalement **rap et latino**, tels que *Suge* de DaBaby ou *LAX* de B0nds. Ces morceaux sont :\n",
    "- **courts**,\n",
    "- **dansants** (haute `danceability`),\n",
    "- avec une **valence élevée** (émotion positive),\n",
    "- mais également avec un certain niveau de **speechiness**, notamment pour les titres rap.\n",
    "\n",
    "Ces morceaux partagent donc des caractéristiques propres aux chansons **énergétiques, rythmées et populaires**, souvent taillées pour le streaming, avec des formats courts, accrocheurs et directs.\n",
    "\n",
    "**À l’opposé**, les morceaux ayant une **forte contribution négative à PC2** sont très différents : on retrouve des **paysages sonores naturels, ambiants ou instrumentaux** comme *Rain Forest and Tropical Beach Sound*, *Caribbean Thunderstorm*, ou encore *Battlement*. Ces titres sont :\n",
    "- **longs**,\n",
    "- **instrumentaux** (forte `instrumentalness`),\n",
    "- avec une **faible valence** et **peu de parole**,\n",
    "- et souvent issus de sous-genres comme *tropical*, *album rock*, ou *ambient*.\n",
    "\n",
    "Cela confirme l’interprétation initiale de la PC2 comme un **axe opposant la musique instrumentale, longue et contemplative** à une musique **populaire, dansante et rythmée**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composante principale 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contributions of individuals to the third principal component\n",
    "contributions_pc3 = projected[:, 2]\n",
    "\n",
    "# Get the indices of the top 5 positive contributors for PC3\n",
    "top_5_positive_indices_pc3 = np.argsort(contributions_pc3)[-5:]\n",
    "\n",
    "# Get the indices of the top 5 negative contributors for PC3\n",
    "top_5_negative_indices_pc3 = np.argsort(contributions_pc3)[:5]\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for positive contributions (PC3)\n",
    "top_5_positive_tracks_pc3 = data_quanti.iloc[top_5_positive_indices_pc3].copy()\n",
    "top_5_positive_tracks_pc3['track_name'] = data.iloc[top_5_positive_indices_pc3]['track_name'].values\n",
    "top_5_positive_tracks_pc3['track_artist'] = data.iloc[top_5_positive_indices_pc3]['track_artist'].values\n",
    "top_5_positive_tracks_pc3['contribution'] = contributions_pc3[top_5_positive_indices_pc3]\n",
    "top_5_positive_tracks_pc3['playlist_subgenre'] = data.iloc[top_5_positive_indices_pc3]['playlist_subgenre'].values\n",
    "# Sort by contribution\n",
    "top_5_positive_tracks_pc3 = top_5_positive_tracks_pc3.sort_values(by='contribution', ascending=False)\n",
    "\n",
    "# Extract the corresponding rows from the original dataset for negative contributions (PC3)\n",
    "top_5_negative_tracks_pc3 = data_quanti.iloc[top_5_negative_indices_pc3].copy()\n",
    "top_5_negative_tracks_pc3['track_name'] = data.iloc[top_5_negative_indices_pc3]['track_name'].values\n",
    "top_5_negative_tracks_pc3['track_artist'] = data.iloc[top_5_negative_indices_pc3]['track_artist'].values\n",
    "top_5_negative_tracks_pc3['contribution'] = contributions_pc3[top_5_negative_indices_pc3]\n",
    "top_5_negative_tracks_pc3['playlist_subgenre'] = data.iloc[top_5_negative_indices_pc3]['playlist_subgenre'].values\n",
    "\n",
    "# Display the top 5 positive and negative tracks with additional information for PC3\n",
    "print(\"Top 5 Positive Contributions (PC3):\")\n",
    "display(top_5_positive_tracks_pc3)\n",
    "\n",
    "print(\"Top 5 Negative Contributions (PC3):\")\n",
    "display(top_5_negative_tracks_pc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **troisième composante principale** met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "**Du côté des contributions positives**, on retrouve des titres de **pop et R&B calmes et acoustiques** comme *raindrops (an angel cried)* (Ariana Grande) ou *You Are The Reason* (Calum Scott). Ces chansons ont :\n",
    "- une **acousticness élevée** (acapela, guitare acoustique, piano),\n",
    "- un **tempo légèrement plus rapide que la médiane des morceaux**,\n",
    "- une **faible énergie**, mais un **potentiel émotionnel fort** (`valence` variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "**Les contributions négatives**, quant à elles, sont largement dominées par des morceaux **EDM ou latino instrumentaux**, comme *I Feel Love* ou *Chase*. Ces morceaux sont :\n",
    "- **longs**,\n",
    "- très **instrumentaux**,\n",
    "- **énergiques** mais souvent **moins \"accessibles\" émotionnellement** (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la **PC3 oppose des créations acoustiques à forte charge émotionnelle** à des morceaux **instrumentaux, électroniques, longs**, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque que le signe des contribution est inversé par rapport à la PCA réalisé en R uniquement pour cette dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDS\n",
    "\n",
    "Le **MDS (Multidimensional Scaling)** est une technique de réduction de dimension non linéaire qui permet de visualiser des données en préservant les distances entre les points. Dans notre cas, nous allons l'appliquer sur les données prétraitées pour obtenir une représentation en 2D des morceaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "\n",
    "df_data_scaled = pd.DataFrame(data_scaled, columns=data_quanti.columns)\n",
    "# set the same index as data_quanti\n",
    "df_data_scaled.index = data_quanti.index\n",
    "\n",
    "# Limit to 500 songs randomly selected to avoid memory crash\n",
    "data_scaled_sample = df_data_scaled.sample(n=500, random_state=1)\n",
    "\n",
    "# Calculate the Manhattan distance matrix\n",
    "manhattan_dist_matrix = manhattan_distances(data_scaled_sample)\n",
    "# Calculate the Euclidean distance matrix\n",
    "euclidean_dist_matrix = euclidean_distances(data_scaled_sample)\n",
    "\n",
    "# Perform MDS using Manhattan distance\n",
    "mds_manhattan = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "mds_manhattan_results = mds_manhattan.fit_transform(manhattan_dist_matrix)\n",
    "# Perform MDS using Euclidean distance\n",
    "mds_euclidean = MDS(n_components=2, dissimilarity='precomputed', random_state=1)\n",
    "mds_euclidean_results = mds_euclidean.fit_transform(euclidean_dist_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MDS results for Manhattan and Euclidean distance in one figure with two subplots and a shared legend\n",
    "\n",
    "# Prepare color palette for playlist_genre\n",
    "palette = sns.color_palette('Set2', n_colors=data_scaled_sample.index.nunique())\n",
    "genre_labels = data_scaled_sample.index.astype(str).values\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharex=False, sharey=False)\n",
    "\n",
    "# Manhattan distance subplot\n",
    "sns.scatterplot(\n",
    "    x=mds_manhattan_results[:, 0],\n",
    "    y=mds_manhattan_results[:, 1],\n",
    "    hue=data_scaled_sample.index,\n",
    "    palette=palette,\n",
    "    alpha=0.7,\n",
    "    ax=axes[0],\n",
    "    legend=False  # Hide legend for now\n",
    ")\n",
    "axes[0].set_title('MDS Manhattan', fontsize=16)\n",
    "axes[0].set_xlabel('MDS Dimension 1', fontsize=12)\n",
    "axes[0].set_ylabel('MDS Dimension 2', fontsize=12)\n",
    "axes[0].grid()\n",
    "\n",
    "# Euclidean distance subplot\n",
    "scatter = sns.scatterplot(\n",
    "    x=mds_euclidean_results[:, 0],\n",
    "    y=mds_euclidean_results[:, 1],\n",
    "    hue=data_scaled_sample.index,\n",
    "    palette=palette,\n",
    "    alpha=0.7,\n",
    "    ax=axes[1],\n",
    "    legend='brief'  # Show legend only on this subplot\n",
    ")\n",
    "axes[1].set_title('MDS Euclidean', fontsize=16)\n",
    "axes[1].set_xlabel('MDS Dimension 1', fontsize=12)\n",
    "axes[1].set_ylabel('MDS Dimension 2', fontsize=12)\n",
    "axes[1].grid()\n",
    "\n",
    "# Place the legend outside the plot\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title=qualisup, bbox_to_anchor=(1.02, 0.5), loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform several MDS sns.scatterplot with different hues, for the 11 quantitative variables in data_scaled\n",
    "quantitative_vars = data_scaled_sample.columns\n",
    "\n",
    "# Create a list of colors for the scatterplots\n",
    "colors = sns.color_palette(\"Set2\", len(quantitative_vars), as_cmap=True)\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20, 20))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easy iteration\n",
    "# Loop through each quantitative variable and create a scatterplot\n",
    "for i, var in enumerate(quantitative_vars):\n",
    "    sns.scatterplot(\n",
    "        x=mds_euclidean_results[:, 0],\n",
    "        y=mds_euclidean_results[:, 1],\n",
    "        hue=data_scaled_sample[var],\n",
    "        ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f'MDS with {var}', fontsize=16)\n",
    "    axes[i].set_xlabel('MDS Dimension 1', fontsize=14)\n",
    "    axes[i].set_ylabel('MDS Dimension 2', fontsize=14)\n",
    "    axes[i].legend(title=var, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[i].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "\n",
    "L’analyse en **MDS (Multidimensional Scaling)** appliquée aux données quantitatives donne des résultats contrastés.\n",
    "\n",
    "* Lorsqu’on projette les points selon une **distance euclidienne ou manhattan**, et qu’on colore les morceaux selon le **genre de playlist**, **aucune structure claire n’émerge** : les genres sont **entièrement mélangés**. Cela montre que, globalement, **les variables quantitatives ne permettent pas de séparer les genres musicaux** dans une représentation MDS. La MDS **ne capture donc pas d'information utile liée au genre musical global** dans cet espace.\n",
    "\n",
    "* Cependant, certaines **variables quantitatives spécifiques sont bien séparées** dans l’espace MDS :\n",
    "\n",
    "  * C’est le cas de **`energy`**, **`loudness`**, **`speechiness`**, **`acousticness`**, **`instrumentalness`**, et dans une moindre mesure **`valence`**.\n",
    "\n",
    "    * Pour **`valence`**, bien que l’on observe deux groupes principaux (valence haute vs. basse), **certains morceaux très joyeux se retrouvent mélangés avec des morceaux tristes**, ce qui rend la séparation moins nette que pour les autres variables.\n",
    "  * On observe des **relations fortes et interprétables** entre certaines variables :\n",
    "\n",
    "    * Sur la **dimension 1 de la MDS**, **`energy` et `loudness` sont corrélées positivement**, et **`acousticness` leur est exactement opposée**. Cela signifie que **les morceaux énergétiques et forts sont peu acoustiques**, ce qui est **parfaitement cohérent avec l’intuition musicale**.\n",
    "    * Sur la **dimension 2**, on retrouve une opposition logique entre **`instrumentalness` et `speechiness`** : **les morceaux très instrumentaux sont peu parlés**, ce qui reflète bien la réalité musicale (ex : classique vs. rap).\n",
    "\n",
    "* En revanche, pour **`track_popularity`**, **`danceability`**, **`tempo`** et **`duration_s`**, **aucune séparation nette n’apparaît** dans l’espace MDS. Ces variables semblent **ne pas être linéairement séparables** par la MDS. On peut donc conclure que **la MDS ne permet pas d’identifier de structure claire** pour ces dimensions — possiblement en raison de leur **relation non linéaire** ou d’un **bruit trop important**.\n",
    "\n",
    "---\n",
    "\n",
    "**Lien avec l’analyse PCA** :\n",
    "\n",
    "On retrouve ici des observations **cohérentes avec l’analyse des composantes principales**. Par exemple :\n",
    "\n",
    "* La **CP1** opposait déjà **`energy` et `loudness`** à **`acousticness`**, exactement comme la **dimension 1 de la MDS**.\n",
    "* La **CP2** révélait une tension entre **`instrumentalness`** et **`speechiness`**, que la **MDS dimension 2** reflète également.\n",
    "* Enfin, comme en PCA, **`track_popularity`**, **`tempo`** et **`duration_s`** ne permettent pas de bien structurer l’espace : ces variables n’étaient déjà que faiblement corrélées avec les premières composantes principales, et la MDS confirme leur faible capacité à structurer les données dans un espace réduit.\n",
    "\n",
    "---\n",
    "\n",
    "Nous allons désormais réaliser un **t-SNE** (t-distributed Stochastic Neighbor Embedding) pour visualiser en 2D la proximité (ou la similarité) entre les chansons Spotify selon leurs caractéristiques audio (danceability, energy, loudness, etc.), pour voir **si des genres musicaux distincts émergent sous forme de groupes**. A l'inverse de la PCA et de la MDS, le **t-SNE est une méthode non linéaire** qui pourrait capturer des relations différentes entre les données que celles révélées par les méthodes linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "tsne_results = tsne.fit_transform(data_scaled_sample)\n",
    "\n",
    "# plot the t-SNE results with sns\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(\n",
    "    x=tsne_results[:, 0],\n",
    "    y=tsne_results[:, 1],\n",
    "    hue=data_scaled_sample.index,\n",
    "    palette='Set2',\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('t-SNE', fontsize=20)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=16)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=16)\n",
    "plt.legend(title=qualisup, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout du t-SNE dans la même figure (3 sous-graphiques sur une ligne)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 8), sharex=False, sharey=False)\n",
    "\n",
    "# Manhattan distance subplot\n",
    "sns.scatterplot(\n",
    "    x=mds_manhattan_results[:, 0],\n",
    "    y=mds_manhattan_results[:, 1],\n",
    "    hue=data_scaled_sample.index,\n",
    "    palette=palette,\n",
    "    alpha=0.7,\n",
    "    ax=axes[0],\n",
    "    legend=False\n",
    ")\n",
    "axes[0].set_title('MDS Manhattan', fontsize=16)\n",
    "axes[0].set_xlabel('MDS Dimension 1', fontsize=12)\n",
    "axes[0].set_ylabel('MDS Dimension 2', fontsize=12)\n",
    "axes[0].grid()\n",
    "\n",
    "# Euclidean distance subplot\n",
    "scatter = sns.scatterplot(\n",
    "    x=mds_euclidean_results[:, 0],\n",
    "    y=mds_euclidean_results[:, 1],\n",
    "    hue=data_scaled_sample.index,\n",
    "    palette=palette,\n",
    "    alpha=0.7,\n",
    "    ax=axes[1],\n",
    "    legend=False\n",
    ")\n",
    "axes[1].set_title('MDS Euclidean', fontsize=16)\n",
    "axes[1].set_xlabel('MDS Dimension 1', fontsize=12)\n",
    "axes[1].set_ylabel('MDS Dimension 2', fontsize=12)\n",
    "axes[1].grid()\n",
    "\n",
    "# t-SNE subplot\n",
    "sns.scatterplot(\n",
    "    x=tsne_results[:, 0],\n",
    "    y=tsne_results[:, 1],\n",
    "    hue=data_scaled_sample.index,\n",
    "    palette=palette,\n",
    "    alpha=0.7,\n",
    "    ax=axes[2],\n",
    "    legend='brief'\n",
    ")\n",
    "axes[2].set_title('t-SNE', fontsize=16)\n",
    "axes[2].set_xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "axes[2].set_ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "axes[2].grid()\n",
    "\n",
    "# Place the legend outside the plot (from the t-SNE plot)\n",
    "handles, labels = axes[2].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title=qualisup, bbox_to_anchor=(1.02, 0.5), loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform t-SNE with different hues, for the 11 quantitative variables in data_scaled\n",
    "# Create a list of colors for the scatterplots\n",
    "colors = sns.color_palette(\"Set2\", len(quantitative_vars), as_cmap=True)\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20, 20))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easy iteration\n",
    "# Loop through each quantitative variable and create a scatterplot\n",
    "for i, var in enumerate(quantitative_vars):\n",
    "    sns.scatterplot(\n",
    "        x=tsne_results[:, 0],\n",
    "        y=tsne_results[:, 1],\n",
    "        hue=data_scaled_sample[var],\n",
    "        ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f't-SNE with {var}', fontsize=16)\n",
    "    axes[i].set_xlabel('t-SNE Dimension 1', fontsize=14)\n",
    "    axes[i].set_ylabel('t-SNE Dimension 2', fontsize=14)\n",
    "    axes[i].legend(title=var, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[i].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "\n",
    "Malgré l’application du **t-SNE**, on observe **toujours aussi peu de séparation nette entre les genres musicaux** : les morceaux restent largement **mélangés indépendamment de leur genre**, ce qui confirme les limites des caractéristiques audio pour discriminer les styles musicaux au sens large.\n",
    "\n",
    "Cependant, le **t-SNE révèle une structure beaucoup plus claire que la MDS**, avec l’émergence de **groupes de morceaux** qui semblent s’organiser selon leurs **propriétés audio internes**.\n",
    "\n",
    "* Les variables **`energy`** et **`loudness`** sont **clairement séparées**, avec une **distribution similaire**, ce qui rejoint parfaitement les résultats observés en **PCA (CP1)** et en **MDS (dim 1)**. De même, **`acousticness`** est **opposée** à ces deux variables, avec un groupe bien distinct de **musiques très acoustiques**, caractérisées par **une faible énergie et un faible volume sonore**.\n",
    "\n",
    "* Concernant **`instrumentalness`**, le t-SNE apporte une **information nouvelle importante** : on distingue **deux groupes de morceaux instrumentaux** très différents :\n",
    "\n",
    "  * Un groupe de morceaux **instrumentaux, calmes, acoustiques et peu louds**.\n",
    "  * Un autre groupe **instrumental mais très énergétique, fort en loudness**, donc probablement plus proche de l’expérimental, du post-rock ou de l’électro instrumental.\n",
    "    Cette séparation fine n’apparaissait **ni en PCA, ni en MDS**, et montre que le **t-SNE capture mieux les structures non linéaires** des données.\n",
    "\n",
    "* Pour **`valence`**, on observe **plusieurs sous-groupes assez distincts**, mais **difficiles à interpréter directement**. Toutefois, en croisant avec **`acousticness`**, on remarque que **les morceaux acoustiques et calmes ont généralement une valence très faible**, ce qui correspond à des ambiances tristes ou introspectives.\n",
    "\n",
    "* En revanche, pour des variables comme **`track_popularity`**, **`danceability`**, **`tempo`** ou **`duration_s`**, la séparation reste **floue et peu informative**, ce qui suggère que ces caractéristiques sont **moins déterminantes** pour structurer l’espace audio selon t-SNE.\n",
    "\n",
    "---\n",
    "\n",
    "**Bilan sur les méthodes de réduction de dimension quantitatives :**\n",
    "\n",
    "* La **PCA** fournit une **lecture linéaire et interprétable** des relations entre variables, et met en évidence des axes clairs comme l’opposition **énergie vs. acoustique** ou **instrumental vs. populaire**.\n",
    "* La **MDS**, malgré son approche plus flexible sur les distances, **n’apporte pas d’information supplémentaire significative** par rapport à la PCA, sauf sur des dimensions très spécifiques.\n",
    "* Le **t-SNE**, quant à lui, **révèle des regroupements non linéaires** que les autres méthodes ne captent pas, et permet de **mieux explorer des structures complexes**, notamment pour des variables comme **`instrumentalness`**, **`energy`**, et **`acousticness`**.\n",
    "\n",
    "En conclusion, chaque méthode a ses forces : **la PCA pour l’interprétation globale des variables**, **le t-SNE pour l'exploration fine des regroupements**, et **la MDS reste plus limitée** dans ce cas d’étude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse en Correspondances Multiples (MCA)\n",
    "\n",
    "### Objectif\n",
    "\n",
    "L'Analyse en Correspondances Multiples (MCA) va être utilisée afin de visualiser les associations entre les modalités des variables qualitatives et d'identifier des clusters ou des oppositions significatives.\n",
    "\n",
    "## Transformation des variables quantitatives en catégories\n",
    "\n",
    "Pour enrichir l'analyse des correspondances multiples (MCA), nous proposons de convertir les variables quantitatives en variables qualitatives ordinales. Cette transformation permet d'intégrer les caractéristiques audio numériques dans une analyse factorielle adaptée aux données catégorielles.\n",
    "\n",
    "### Critères de segmentation\n",
    "\n",
    "La catégorisation suit une logique **musicologique et perceptuelle**, en tenant compte des seuils naturels d'interprétation des caractéristiques audio :\n",
    "\n",
    "**Variables binaires (seuil à 0.5)** : \n",
    "- `danceability`, `energy`, `valence` : Séparation entre niveaux faible/élevé selon la médiane théorique\n",
    "- `instrumentalness` : Distinction claire entre morceaux vocaux et instrumentaux\n",
    "\n",
    "**Variables à seuils spécifiques** :\n",
    "- `speechiness` : Seuil à 0.3 pour différencier musique pure vs. contenu parlé (rap, podcast)\n",
    "- `liveness` : Seuil à 0.8 pour capturer les vraies performances live\n",
    "- `popularity` : Segmentation en tertiles (0-20, 20-75, 75-100) reflétant les distributions réelles de Spotify\n",
    "\n",
    "**Variables temporelles** :\n",
    "- `tempo` : Classification musicologique standard (lent <100, modéré 100-150, rapide >150 BPM)\n",
    "- `duration` : Segmentation basée sur les formats musicaux (courts <2min, moyens 2-4min, longs >4min)\n",
    "- `decade` : Regroupement par décennies avec fusion des années 1950s-1960s pour équilibrer les effectifs\n",
    "\n",
    "Cette approche préserve la signification musicale des variables tout en créant des catégories équilibrées pour l'analyse MCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un DataFrame catégorique selon les règles demandées\n",
    "\n",
    "df_cat_custom = pd.DataFrame(index=data.index)\n",
    "\n",
    "# Popularity\n",
    "df_cat_custom['popularity_cat'] = pd.cut(\n",
    "    data['track_popularity'],\n",
    "    bins=[-1, 20, 75, 100],\n",
    "    labels=['peu populaire', 'popularité moyenne', 'très populaire']\n",
    ")\n",
    "\n",
    "# Speechiness\n",
    "df_cat_custom['speechiness_cat'] = pd.cut(\n",
    "    data['speechiness'],\n",
    "    bins=[-0.01, 0.33, 1.0],\n",
    "    labels=['peu de paroles', 'paroles dominantes']\n",
    ")\n",
    "\n",
    "# Danceability\n",
    "df_cat_custom['danceability_cat'] = pd.cut(\n",
    "    data['danceability'],\n",
    "    bins=[-0.01, 0.5, 1.0],\n",
    "    labels=['peu dansant', 'dansant']\n",
    ")\n",
    "\n",
    "# Energy\n",
    "df_cat_custom['energy_cat'] = pd.cut(\n",
    "    data['energy'],\n",
    "    bins=[-0.01, 0.5, 1.0],\n",
    "    labels=['peu énergique', 'énergique']\n",
    ")\n",
    "\n",
    "# Instrumentalness\n",
    "df_cat_custom['instrumentalness_cat'] = pd.cut(\n",
    "    data['instrumentalness'],\n",
    "    bins=[-0.01, 0.5, 1.0],\n",
    "    labels=['peu instrumentale', 'instrumentale']\n",
    ")\n",
    "\n",
    "# Liveness\n",
    "df_cat_custom['liveness_cat'] = pd.cut(\n",
    "    data['liveness'],\n",
    "    bins=[-0.01, 0.8, 1.0],\n",
    "    labels=['pas live', 'live']\n",
    ")\n",
    "\n",
    "# Valence\n",
    "df_cat_custom['valence_cat'] = pd.cut(\n",
    "    data['valence'],\n",
    "    bins=[-0.01, 0.5, 1.0],\n",
    "    labels=['triste', 'joyeux']\n",
    ")\n",
    "\n",
    "# Tempo\n",
    "df_cat_custom['tempo_cat'] = pd.cut(\n",
    "    data['tempo'],\n",
    "    bins=[-float('inf'), 100, 150, float('inf')],\n",
    "    labels=['Lent', 'Modéré', 'Rapide']\n",
    ")\n",
    "\n",
    "# Duration (en secondes)\n",
    "df_cat_custom['duration_cat'] = pd.cut(\n",
    "    data['duration_s'],\n",
    "    bins=[-0.01, 120, 240, float('inf')],\n",
    "    labels=['court', 'moyen', 'long']\n",
    ")\n",
    "# Décennie de sortie de l'album\n",
    "df_cat_custom['decade'] = (\n",
    "    pd.to_datetime(data['track_album_release_date'], errors='coerce')\n",
    "    .dt.year\n",
    "    .dropna()\n",
    "    .astype(int)\n",
    "    .apply(lambda y: f\"{(y // 10) * 10}s\" if pd.notnull(y) else 'unknown')\n",
    ")\n",
    "\n",
    "# Fusionner les décennies 1950s et 1960s en une seule catégorie '1950s-1960s'\n",
    "df_cat_custom['decade'] = df_cat_custom['decade'].replace({'1950s': '1950s-1960s', '1960s': '1950s-1960s'})\n",
    "\n",
    "# Ajout des variables qualitatives existantes\n",
    "df_cat_custom['mode'] = data['mode']\n",
    "df_cat_custom['key'] = data['key']\n",
    "df_cat_custom['playlist_genre'] = data['playlist_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for MCA with the new categorical variables\n",
    "df_cat = df_cat_custom[\n",
    "    [\n",
    "        'popularity_cat', 'speechiness_cat', 'danceability_cat', 'energy_cat',\n",
    "        'instrumentalness_cat', 'liveness_cat', 'valence_cat', 'tempo_cat',\n",
    "        'duration_cat', 'decade', 'mode', 'playlist_genre'\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Run MCA\n",
    "mca = prince.MCA(n_components=2, n_iter=100, copy=True, check_input=True, engine='sklearn', random_state=1)\n",
    "mca = mca.fit(df_cat)\n",
    "\n",
    "# Get coordinates for the plot\n",
    "coords = mca.column_coordinates(df_cat)\n",
    "\n",
    "# Calculate cosine similarities for sizing\n",
    "cosine_similarities = mca.column_cosine_similarities(df_cat)\n",
    "sizes = cosine_similarities[0]**2 + cosine_similarities[1]**2\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'x': coords[0],\n",
    "    'y': coords[1],\n",
    "    'variable': [x.split('__')[0] for x in coords.index],\n",
    "    'value': [x.split('__')[1] for x in coords.index],\n",
    "    'size': sizes * 500  # Scale sizes for better visualization\n",
    "})\n",
    "\n",
    "# Create a color mapping for variables\n",
    "color_list = sns.color_palette('tab20', n_colors=12)\n",
    "variables = [\n",
    "    'popularity_cat', 'speechiness_cat', 'danceability_cat', 'energy_cat',\n",
    "    'instrumentalness_cat', 'liveness_cat', 'valence_cat', 'tempo_cat',\n",
    "    'duration_cat', 'decade', 'mode', 'playlist_genre'\n",
    "]\n",
    "colors = dict(zip(variables, color_list))\n",
    "plot_data['color'] = plot_data['variable'].map(colors)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 9))\n",
    "scatter = sns.scatterplot(\n",
    "    data=plot_data,\n",
    "    x='x', \n",
    "    y='y',\n",
    "    hue='variable',\n",
    "    size='size',\n",
    "    sizes=(50, 500),\n",
    "    palette=colors,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add annotations\n",
    "for i, row in plot_data.iterrows():\n",
    "    plt.text(\n",
    "        row['x'] + 0.02, \n",
    "        row['y'] + 0.02, \n",
    "        row['value'], \n",
    "        fontsize=9,\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "plt.title('MCA: Relations entre variables qualitatives audio', fontsize=16)\n",
    "plt.xlabel(f'Dimension 1 ({mca.eigenvalues_summary.iloc[0, 1]})', fontsize=12)\n",
    "plt.ylabel(f'Dimension 2 ({mca.eigenvalues_summary.iloc[1, 1]})', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.legend(title='Variable')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation de l'Analyse des Correspondances Multiples (MCA)\n",
    "\n",
    "#### Variables utilisées\n",
    "\n",
    "Les variables qualitatives sélectionnées pour cette analyse sont :\n",
    "\n",
    "* `playlist_genre` : Genre de la playlist (pop, rock, edm, rap, etc.)\n",
    "* `mode` : Mode musical (majeur / mineur)\n",
    "* `tempo_cat` : Catégorie de tempo (lent / rapide / modéré)\n",
    "* `valence_cat` : Valence émotionnelle (joyeux / triste / neutre)\n",
    "* `energy_cat`, `danceability_cat`, `instrumentalness_cat`, `speechiness_cat`, `liveness_cat`\n",
    "* `duration_cat` : Longueur du morceau (court / moyen / long)\n",
    "* `decade` : Décennie de sortie\n",
    "* `popularity_cat` : Niveau de popularité (peu / moyen / très)\n",
    "* `size` : Fréquence d'apparition (représentée par la taille des bulles)\n",
    "\n",
    "---\n",
    "\n",
    "### Résultats\n",
    "\n",
    "#### 1. **Axes factoriels**\n",
    "\n",
    "##### **Dimension 1 (8.15%)** :\n",
    "\n",
    "Cet axe semble opposer :\n",
    "\n",
    "* **À droite** : des genres et époques associés à une musique plus **live**, **peu dansante**, **rock** et **années 1970–1980**, souvent en **mode majeur**, avec une tendance à la **longueur**.\n",
    "* **À gauche** : des genres comme **EDM**, **rap**, ou **pop des années 2010–2020**, associés à des morceaux plus **courts**, **instrumentaux**, **très populaires**, avec **paroles dominantes**, souvent **joyeux** et **mineur**.\n",
    "\n",
    "##### **Dimension 2 (7.14%)** :\n",
    "\n",
    "Cet axe reflète plutôt une opposition d’ambiance :\n",
    "\n",
    "* **En haut** : Musiques plus **live**, **peu dansantes**, parfois **instrumentales**, associées à des décennies anciennes (1950s–1980s).\n",
    "* **En bas** : Musiques plus **rapides**, **énergétiques**, **avec paroles dominantes**, parfois **r\\&b** ou **pop**.\n",
    "\n",
    "> La projection est inversée selon la dim 1 par rapport aux résultats sous R. Cela n'affecte pas l'interprétation, seule l’orientation spatiale est différente.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Proximité des modalités**\n",
    "\n",
    "* Les genres **rap**, **latin**, **court**, **très populaire** et **paroles dominantes** sont regroupés → musique courte, populaire, axée sur le texte.\n",
    "* Le **rock** est fortement associé au **mode majeur**, à la **décennie 1980**, à un **caractère live** et **peu dansant**.\n",
    "* **EDM** est très proche de **instrumentale**, indiquant des morceaux sans paroles.\n",
    "* Les catégories **\"paroles dominantes\"**, **\"peu instrumental\"**, et **\"énergique\"** sont toutes proches, suggérant que beaucoup de morceaux énergiques contiennent beaucoup de texte.\n",
    "* **Pop des années 2010s et 2020s**, **dansants**, morceaux **moyennement long** se positionne plutôt au centre, ce qui reflète une certaine **polyvalence**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Cos² (qualité de représentation)**\n",
    "\n",
    "* Les modalités bien représentées par les deux axes (grosses bulles) incluent :\n",
    "\n",
    "  * `rock`, `live`, `très populaire`, `joyeux`, `paroles dominantes`, `peu dansant`\n",
    "* Les modalités avec des bulles plus petites comme `minor`, `pop`, `latin`, `r&b` sont moins bien représentées → elles nécessiteraient plus de dimensions pour être bien décrites.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Cette MCA met en évidence des **clusters sémantiques clairs** entre les genres, l’époque, les caractéristiques émotionnelles et musicales :\n",
    "\n",
    "* **Le rock des années 70–80** est clairement identifiable : live, peu dansant, majeur, long.\n",
    "* **Le EDM et l’instrumental** vont de pair, souvent peu dansants, modernes, peu de texte.\n",
    "* **Le rap** est court, populaire, avec des paroles dominantes, souvent dans un registre énergique mais pas exclusivement mineur ou majeur.\n",
    "* **La pop des années 2010s–2020s** est très mixte : ni clairement joyeuse ni triste, ni très rapide ni lente → un profil \"standard\" qui touche un large public.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir 4 artistes fréquents\n",
    "top_artists = ['David Guetta', 'Ed Sheeran', 'Green Day', 'Billie Eilish', 'Eminem']\n",
    "\n",
    "# Remplacer les autres artistes par 'Autre'\n",
    "data['artist_subset'] = data['track_artist'].apply(lambda x: x if x in top_artists else 'Autre')\n",
    "\n",
    "# Refaire le sous-ensemble avec artiste\n",
    "df_cat1 = data[['playlist_genre', 'mode', 'key', 'artist_subset']].copy()\n",
    "\n",
    "# Run MCA\n",
    "mca = prince.MCA(n_components=2, n_iter=100, copy=True, check_input=True, engine='sklearn', random_state=1)\n",
    "mca = mca.fit(df_cat1)\n",
    "\n",
    "# Get coordinates for the plot\n",
    "coords = mca.column_coordinates(df_cat1)\n",
    "\n",
    "# Calculate cosine similarities for sizing\n",
    "cosine_similarities = mca.column_cosine_similarities(df_cat1)\n",
    "# Use the sum of cosine similarities as size parameter (for clearer visualization)\n",
    "sizes = cosine_similarities[0]**2 + cosine_similarities[1]**2\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'x': coords[0],\n",
    "    'y': coords[1],\n",
    "    'variable': [x.split('__')[0] for x in coords.index],\n",
    "    'value': [x.split('__')[1] for x in coords.index],\n",
    "    'size': sizes * 500  # Scale sizes for better visualization\n",
    "})\n",
    "\n",
    "# Create a color mapping for variables\n",
    "colors = {'playlist_genre': 'blue', 'mode': 'red', 'key': 'green', 'artist_subset': 'purple'}\n",
    "plot_data['color'] = plot_data['variable'].map(colors)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = sns.scatterplot(\n",
    "    data=plot_data,\n",
    "    x='x', \n",
    "    y='y',\n",
    "    hue='variable',\n",
    "    size='size',\n",
    "    sizes=(50, 500),\n",
    "    palette=colors,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add annotations\n",
    "for i, row in plot_data.iterrows():\n",
    "    plt.text(\n",
    "        row['x'] + 0.02, \n",
    "        row['y'] + 0.02, \n",
    "        row['value'], \n",
    "        fontsize=9,\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "# Add styling\n",
    "plt.title('MCA: Relationship between Genre, Mode and Key', fontsize=16)\n",
    "plt.xlabel(f'Dimension 1 ({mca.eigenvalues_summary.iloc[0, 1]})', fontsize=12)\n",
    "plt.ylabel(f'Dimension 2 ({mca.eigenvalues_summary.iloc[1, 1]})', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.legend(title='Variable Type')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances artistes-genres (MCA)\n",
    "Nous avons décidé d'affiner notre MCA en y intégrant certains artistes pour mieux comprendre leurs relations avec les genres musicaux. Nous avons sélectionné 6 artistes : **David Guetta**, **Ed Sheeran**, **Green Day**, **Billie Eilish**, **Eminem** et un groupe d'artistes diversifié nommé **Autre**. Afin d'analyser la proximité entre ces artistes et les genres musicaux, nous avons calculé les distances euclidiennes au carré entre chaque artiste et les genres issus de l'Analyse des Correspondances Multiples (MCA).\n",
    "\n",
    "#### Interprétations individuelles\n",
    "\n",
    "- **David Guetta** est très proche du genre **EDM**, ce qui est cohérent avec son positionnement d’artiste électro. Il est aussi relativement proche du genre `pop` et `rock`, ce qui peut s’expliquer par ses nombreuses collaborations avec des chanteurs populaires.\n",
    "\n",
    "- **Ed Sheeran** est modérément proche des genres **pop** et **edm**, ce qui reflète sa diversité musicale et ses morceaux mêlant acoustique et sons plus produits.\n",
    "\n",
    "- **Green Day** est relativement proche du genre **rock**, ce qui confirme son ancrage dans ce style. Il est plus éloigné des autres genres, ce qui le distingue nettement stylistiquement dans cette analyse.\n",
    "\n",
    "- **Billie Eilish** est située à mi-distance de plusieurs genres (`pop`, `edm`, `rock`), ce qui traduit une position hybride. Elle n’est pas fortement associée à un genre unique, ce qui est cohérent avec son style singulier et difficile à catégoriser.\n",
    "\n",
    "- **Eminem** montre une **affinité forte avec le genre Rap**, avec une distance minimale comparée aux autres genres. Il est largement séparé des genres comme rock ou pop, ce qui reflète bien son style musical distinct.\n",
    "\n",
    "- **Autre** est, comme attendu, proche du centre, ce qui traduit une position moyenne, résultant de l’agrégation d’artistes divers aux profils variés.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "L’analyse des distances artistes-genres via la MCA confirme plusieurs intuitions sur les positionnements stylistiques des artistes. Elle permet également de détecter des cas hybrides (comme Billie Eilish)\n",
    "Elle enrichit l’interprétation visuelle de l’ACM en objectivant la notion de \"proximité\" par une mesure quantitative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF\n",
    "\n",
    "La Factorisation Matricielle Non-Négative (NMF) est une technique de réduction de dimension qui permet de décomposer une matrice en deux matrices de facteurs non négatifs. Dans le contexte de l'analyse des données musicales, NMF est particulièrement utile pour identifier des motifs latents ou des profils musicaux à partir des caractéristiques audio.\n",
    "\n",
    "### Objectif de la NMF\n",
    "L'objectif de la NMF dans ce projet est de découvrir des profils musicaux latents qui peuvent représenter des styles ou des genres musicaux spécifiques. En factorisant les données audio, nous espérons extraire des caractéristiques communes qui peuvent être utilisées pour la recommandation de musique ou pour mieux comprendre la structure des genres musicaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = [\n",
    "    'danceability', 'energy', 'loudness', 'speechiness',\n",
    "    'acousticness', 'instrumentalness', 'liveness',\n",
    "    'valence', 'tempo', 'duration_s'\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1. Sélection des features audio\n",
    "X = data_songs[audio_features].copy()\n",
    "\n",
    "# 2. Normalisation min-max (important pour la NMF)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. Tester plusieurs valeurs de r (nombre de composants)\n",
    "errors = []\n",
    "r_values = range(2,11, 2)\n",
    "\n",
    "for r in r_values:\n",
    "    model = NMF(n_components=int(r), init='nndsvda', random_state=42, max_iter=500)\n",
    "    W = model.fit_transform(X_scaled)\n",
    "    H = model.components_\n",
    "    reconstruction = np.dot(W, H)\n",
    "    error = np.linalg.norm(X_scaled - reconstruction, 'fro')  # norme de Frobenius\n",
    "    errors.append(error)\n",
    "\n",
    "# 4. Tracer la courbe de l’erreur de reconstruction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(r_values, errors, marker='o')\n",
    "plt.title(\"Erreur de reconstruction vs nombre de composants (r)\")\n",
    "plt.xlabel(\"Nombre de composants (r)\")\n",
    "plt.ylabel(\"Erreur de reconstruction (norme de Frobenius)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'erreur de reconstruction décroit jusqu'à notre nombre variables total, on choisit arbitrairement de prendre 6 facteurs pour la suite de l'analyse, ce qui va nous donner 6 profils musicaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Application de la NMF\n",
    "nmf_model = NMF(n_components=6, init='nndsvda', random_state=42, max_iter=500)\n",
    "W = nmf_model.fit_transform(X_scaled)\n",
    "H = nmf_model.components_\n",
    "\n",
    "# 4. Créer un DataFrame pour la matrice H\n",
    "H_df = pd.DataFrame(H, columns=audio_features)\n",
    "H_df.index = [f'Profil {i+1}' for i in range(H.shape[0])]\n",
    "\n",
    "# 5. Affichage de la matrice H\n",
    "print(\"Matrice H (profils latents définis par les variables audio) :\")\n",
    "display(H_df)\n",
    "\n",
    "# 6. Visualisation : contribution des variables à chaque profil\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(H_df, annot=True, cmap='YlGnBu', fmt=\".2f\")\n",
    "plt.title(\"Profils latents musicaux détectés par NMF (matrice H)\")\n",
    "plt.xlabel(\"Caractéristiques audio\")\n",
    "plt.ylabel(\"Profils NMF\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset utilisé\n",
    "Nous avons décidé d'utiliser le dataframe `data_songs` ne contenant que les morceaux une seule fois dans le dataset, pour éviter de biaiser les résultats. \n",
    "\n",
    "### Variables utilisées\n",
    "\n",
    "Les variables sélectionnées pour cette NMF sont les caractéristiques audio continues suivantes :\n",
    "\n",
    "* `danceability`, `energy`, `loudness`, `speechiness`, `acousticness`, `instrumentalness`, `liveness`, `valence`, `tempo`, `duration_s`.\n",
    "\n",
    "Nous avons exclu la variable `track_popularity` car la NMF est très sensible aux valeurs extrêmes et cette variable a une distribution très héterogène. De plus, nous avons exclu les variables catégorielles et les variables de texte, car la NMF est conçue pour fonctionner sur des données numériques continues.\n",
    "\n",
    "### Résultats\n",
    "\n",
    "#### 1. Profils latents détectés\n",
    "\n",
    "L’analyse a révélé **6 profils musicaux latents** à partir des données. Chaque profil est défini par une combinaison unique de caractéristiques audio. Voici leur interprétation :\n",
    "\n",
    "* **Profil 1 : Profil Énergique-Intense**\n",
    "\n",
    "  * Caractérisé par de **très fortes valeurs en `energy`, `loudness` et `tempo` et `duration`**.\n",
    "  * Faible en composantes émotionnelles (`valence`), vocales et instrumentales.\n",
    "  * Ce profil pourrait correspondre à des morceaux **très dynamiques et bruyants**, typiques de l’**EDM** (house, electro, techno) ou du **hard-rock**/**metal**.\n",
    "\n",
    "* **Profil 2 : Profil Acoustique-Chant**\n",
    "\n",
    "  * Dominé par une forte **`acousticness`**.\n",
    "  * Ce profil, presente **`instrumentalness`=0**, et un faible **`speechiness`** mais différent de zero.\n",
    "  * Ce profil regroupe possiblement des morceaux **acoustiques et chantés**.\n",
    "\n",
    "* **Profil 3 : Profil Instrumental**\n",
    "\n",
    "  * Très forte **`instrumentalness`** avec très peu d'autres caractéristiques.\n",
    "  * Correspond clairement à des morceaux **purement instrumentaux**, probablement **ambient**, **classique** ou **bande-son**.\n",
    "\n",
    "* **Profil 4 : Profil Émotionnel-Valence**\n",
    "\n",
    "  * Faible en toutes dimensions sauf une très forte **`valence`**.\n",
    "  * Ce profil regroupe des morceaux **émotionnellement très positifs**, avec une ambiance **joyeuse ou euphorique**, indépendamment du tempo ou de l’énergie.\n",
    "\n",
    "* **Profil 5 : Profil Vocal-Live**\n",
    "\n",
    "  * Faibles valeurs générales sauf une **forte `liveness`** et une **`speechiness`** marquée.\n",
    "  * Peut représenter des morceaux **live**, **rap**, ou des chansons **parlées/spoken word**.\n",
    "\n",
    "* **Profil 6 : Profil Rap-Rythmé**\n",
    "\n",
    "  * Forte `danceability`, `speechiness` et modérée `energy`.\n",
    "  * Ce profil semble capturer des morceaux **rythmés et très vocaux**, typiques du **rap**, **hip-hop**, voire certains morceaux **R\\&B urbains**. Ils pourraient aussi correspondre à des morceaux **pop** et **latino** dans une certaine mesure.\n",
    "\n",
    "---\n",
    "\n",
    "Pour chaque profil, nous allons desormais regarder les morceaux qui y contribuent le plus fortement, pour confirmer ces resultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 tracks for each NMF profile\n",
    "n_profiles = 6  # Number of profiles from our NMF model\n",
    "top_n = 2      # Number of top tracks to display per profile\n",
    "\n",
    "# Create a dataframe with track information and profile weights\n",
    "profile_weights = pd.DataFrame(W, index=data_songs.index)\n",
    "profile_weights.columns = [f'Profile_{i+1}' for i in range(n_profiles)]\n",
    "\n",
    "# For each profile, find the tracks with the highest weights\n",
    "results = []\n",
    "\n",
    "for profile_idx in range(n_profiles):\n",
    "    profile_name = f'Profile_{profile_idx+1}'\n",
    "    \n",
    "    # Get top tracks for this profile\n",
    "    top_indices = profile_weights[profile_name].nlargest(top_n).index\n",
    "    \n",
    "    # Extract relevant information for these tracks\n",
    "    for idx in top_indices:\n",
    "        track_info = {\n",
    "            'Profile': profile_name,\n",
    "            'Track Name': data.loc[idx, 'track_name'],\n",
    "            'Artist': data.loc[idx, 'track_artist'],\n",
    "            'Genre': data.loc[idx, 'playlist_genre'],\n",
    "            'Subgenre': data.loc[idx, 'playlist_subgenre'],\n",
    "            'Weight': profile_weights.loc[idx, profile_name]\n",
    "        }\n",
    "        \n",
    "        # Add audio features for context\n",
    "        for feature in audio_features:\n",
    "            track_info[feature] = data.loc[idx, feature]\n",
    "            \n",
    "        results.append(track_info)\n",
    "\n",
    "# Create a dataframe with the results and display it\n",
    "top_tracks_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by profile and weight\n",
    "top_tracks_df = top_tracks_df.sort_values(['Profile', 'Weight'], ascending=[True, False])\n",
    "display(top_tracks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "\n",
    "On retrouve des resultats cohérents avec les profils identifiés précédemment. Seul `Sandstorm` de Darude qui est censé être un morceau EDM est classé dans le profil 2, ce qui est surprenant. Mais en regardant la caractéristique `instrumentalness`, on remarque qu'il est très proche de 1, ce qui signifie que le morceau est classé comme très intrumental. Il est donc normal qu'il soit classé dans le profil 2.\n",
    "\n",
    "---\n",
    "\n",
    "On peut desormais regarder pour certains artistes quels sont les profils musicaux qui leur correspondent le mieux. On va regarder les tracks des artistes suivants : **David Guetta**, **Ed Sheeran**, **Green Day**, **Billie Eilish** et **Eminem**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir 4 artistes fréquents\n",
    "top_artists = ['David Guetta', 'Ed Sheeran', 'Green Day', 'Billie Eilish', 'Eminem']\n",
    "\n",
    "# Create a dataframe with profile weights for each track\n",
    "profile_weights = pd.DataFrame(W, index=data_songs.index)\n",
    "profile_weights.columns = [f'Profile_{i+1}' for i in range(n_profiles)]\n",
    "\n",
    "# Merge with original data to get artist info\n",
    "artist_profiles = pd.concat([data_songs[['track_artist', 'track_name']], profile_weights], axis=1)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "artist_distribution = {}\n",
    "\n",
    "# For each artist, analyze their tracks\n",
    "for artist in top_artists:\n",
    "    # Filter tracks by this artist\n",
    "    artist_tracks = artist_profiles[artist_profiles['track_artist'] == artist]\n",
    "    \n",
    "    if len(artist_tracks) == 0:\n",
    "        print(f\"No tracks found for {artist}\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate average profile weight for this artist\n",
    "    avg_profile_weights = artist_tracks[[f'Profile_{i+1}' for i in range(n_profiles)]].mean()\n",
    "    \n",
    "    # Find dominant profile for each track\n",
    "    dominant_profiles = artist_tracks[[f'Profile_{i+1}' for i in range(n_profiles)]].idxmax(axis=1).value_counts()\n",
    "    \n",
    "    # Store results\n",
    "    artist_distribution[artist] = {\n",
    "        'track_count': len(artist_tracks),\n",
    "        'avg_weights': avg_profile_weights,\n",
    "        'dominant_profiles': dominant_profiles\n",
    "    }\n",
    "\n",
    "# Visualize the results\n",
    "fig, axes = plt.subplots(len(top_artists), 2, figsize=(18, 4*len(top_artists)))\n",
    "\n",
    "for i, artist in enumerate(top_artists):\n",
    "    if artist not in artist_distribution:\n",
    "        continue\n",
    "    \n",
    "    # Average profile weights\n",
    "    artist_distribution[artist]['avg_weights'].plot(\n",
    "        kind='bar', \n",
    "        ax=axes[i, 0], \n",
    "        color='skyblue',\n",
    "        title=f\"{artist}: Average Profile Weights (n={artist_distribution[artist]['track_count']} tracks)\"\n",
    "    )\n",
    "    axes[i, 0].set_ylabel(\"Weight\")\n",
    "    axes[i, 0].set_xlabel(\"NMF Profile\")\n",
    "    \n",
    "    # Distribution of dominant profiles\n",
    "    if len(artist_distribution[artist]['dominant_profiles']) > 0:\n",
    "        artist_distribution[artist]['dominant_profiles'].plot(\n",
    "            kind='bar', \n",
    "            ax=axes[i, 1], \n",
    "            color='coral',\n",
    "            title=f\"{artist}: Dominant Profile Distribution\"\n",
    "        )\n",
    "        axes[i, 1].set_ylabel(\"Number of Tracks\")\n",
    "        axes[i, 1].set_xlabel(\"Dominant NMF Profile\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print a summary\n",
    "print(\"\\nArtist Profile Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for artist in top_artists:\n",
    "    if artist not in artist_distribution:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{artist} ({artist_distribution[artist]['track_count']} tracks)\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Get the dominant profile(s)\n",
    "    if len(artist_distribution[artist]['dominant_profiles']) > 0:\n",
    "        top_profile = artist_distribution[artist]['dominant_profiles'].index[0]\n",
    "        top_count = artist_distribution[artist]['dominant_profiles'].iloc[0]\n",
    "        top_percent = (top_count / artist_distribution[artist]['track_count']) * 100\n",
    "        \n",
    "        print(f\"Primary Profile: {top_profile} ({top_percent:.1f}% of tracks)\")\n",
    "    \n",
    "    # Get the highest weight profile on average\n",
    "    top_avg_profile = artist_distribution[artist]['avg_weights'].idxmax()\n",
    "    top_avg_weight = artist_distribution[artist]['avg_weights'].max()\n",
    "    \n",
    "    print(f\"Highest Average Weight: {top_avg_profile} (weight: {top_avg_weight:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all tracks by Green Day\n",
    "green_day_tracks = data_songs[data_songs['track_artist'] == 'Green Day']\n",
    "\n",
    "# Create a dataframe with profile weights for each Green Day track\n",
    "profile_weights = pd.DataFrame(W, index=data_songs.index)\n",
    "profile_weights.columns = [f'Profile_{i+1}' for i in range(n_profiles)]\n",
    "\n",
    "# Merge track information with profile weights\n",
    "green_day_profiles = pd.concat([green_day_tracks[['track_name']], \n",
    "                               profile_weights.loc[green_day_tracks.index]], axis=1)\n",
    "\n",
    "# Add the dominant profile column\n",
    "green_day_profiles['Dominant_Profile'] = green_day_profiles[[f'Profile_{i+1}' for i in range(n_profiles)]].idxmax(axis=1)\n",
    "\n",
    "# Sort by dominant profile and then by the weight of that profile (descending)\n",
    "green_day_profiles = green_day_profiles.sort_values(['Dominant_Profile', 'track_name'])\n",
    "\n",
    "# Display the tracks with their profile information\n",
    "display(green_day_profiles[['track_name', 'Dominant_Profile'] + \n",
    "                          [f'Profile_{i+1}' for i in range(n_profiles)]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artistes et profils musicaux\n",
    "\n",
    "En dehors de **Green Day**, ayant des morceaux partagés entre les profiles 4, 5 et 6, **les autres artistes appartiennent tous au profil 6**. Pour ce qui est de **Green Day**, les morceaux qui lui sont attribués dans le profil 4 sont en effet des morceaux joyeux et gais comme *American Idiot* ou *Basket Case* du moins dans la direction artistique.\n",
    "\n",
    "Les morceaux qui lui sont attribués dans le **profil 5** sont des morceaux **qui a priori ne sont pas des versions live** mais l'algorithme de Spotify en charge de detecter les versions live **a du se tromper**. Si cette variable présente des valeurs non représentatives, il serait intéressante de répéter l'analyse sans cette variable.\n",
    "\n",
    "Pour ce qui est des morceaux qui lui sont attribués dans le **profil 6**, ce sont des morceaux pop-rock **plutot équilibrés** comme *Boulevard of Broken Dreams* ou *Wake Me Up When September Ends*.\n",
    "\n",
    "---\n",
    "\n",
    "On peut conclure sur le fait que ce profil 6 regroupe plus de styles musicaux que les autres profils. Il semble être **le profil le plus généraliste**, et regroupe des morceaux de plusieurs genres musicaux.\n",
    "\n",
    "Il serait utile de faire un clustering sur les profils musicaux pour voir si on peut regrouper les morceaux en fonction de leurs caractéristiques audio, particulièrement sur le profil 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib import colors\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='k-means++', n_init='auto', random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans, k=(2, 12))\n",
    "visualizer.fit(W)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering on W with 3 clusters\n",
    "kmeans_w = KMeans(n_clusters=4, random_state=42, n_init='auto')\n",
    "cluster_labels = kmeans_w.fit_predict(W)\n",
    "\n",
    "# Add cluster labels to a DataFrame for easier handling\n",
    "clustered_data = data_songs.copy()\n",
    "clustered_data['kmeans_cluster'] = cluster_labels\n",
    "\n",
    "#Confusion Matrix: K-Means clusters vs. NMF profiles\n",
    "\n",
    "# Determine the dominant NMF profile for each track\n",
    "# profile_weights was calculated in CELL INDEX 50 and has data_songs.index\n",
    "dominant_nmf_profile = profile_weights.idxmax(axis=1)\n",
    "clustered_data['dominant_nmf_profile'] = dominant_nmf_profile\n",
    "\n",
    "# Create confusion matrix\n",
    "# Ensure the labels match the unique values in dominant_nmf_profile and kmeans_cluster\n",
    "nmf_labels = clustered_data['dominant_nmf_profile'].unique()\n",
    "kmeans_labels = sorted(clustered_data['kmeans_cluster'].unique())\n",
    "\n",
    "# Create a contingency matrix instead of a confusion matrix\n",
    "contingency_matrix = pd.crosstab(clustered_data['dominant_nmf_profile'], clustered_data['kmeans_cluster'])\n",
    "\n",
    "# Convert the contingency matrix to a DataFrame for visualization\n",
    "cm_nmf_df = contingency_matrix\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_nmf_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix: K-Means Clusters vs. Dominant NMF Profiles')\n",
    "plt.ylabel('Dominant NMF Profile')\n",
    "plt.xlabel('K-Means Cluster')\n",
    "plt.show()\n",
    "\n",
    "#Confusion Matrix: K-Means clusters vs. Playlist Genres\n",
    "\n",
    "# Get playlist genres for tracks in data_songs from the original 'data' DataFrame\n",
    "playlist_genres_for_W = data.loc[data_songs.index, 'playlist_genre'] # Usage of data.loc to ensure correct indexing\n",
    "clustered_data['playlist_genre'] = playlist_genres_for_W\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "\n",
    "L’analyse des clusters obtenus à partir de la **matrice W de la NMF** révèle des profils très contrastés :\n",
    "\n",
    "* Les **profils 1 à 4 sont clairement définis et homogènes** : ils se retrouvent **presque exclusivement dans un seul cluster (le cluster 3)**, ce qui indique une **cohérence interne forte** et une bonne séparation de ces profils par la NMF.\n",
    "\n",
    "* Le **profil 5** montre une **certaine diversité**, mais reste **partiellement concentré dans le cluster 1**, suggérant une structure intermédiaire : ni totalement homogène, ni complètement dispersé.\n",
    "\n",
    "* Le **profil 6** est **largement hétérogène**, avec des morceaux **répartis sur l’ensemble des 5 clusters**, ce qui confirme plusieurs points importants :\n",
    "\n",
    "  * Ce profil capture **un groupe de morceaux très variés**, sans dominante claire.\n",
    "  * Il reflète probablement **plusieurs sous-genres ou styles musicaux imbriqués**.\n",
    "  * Sa **taille très supérieure** à celle des autres profils suggère que la **NMF n’a pas réussi à découper efficacement cet ensemble**, ce qui peut être dû à une **grande diversité sonore** ou à une **structure non linéaire difficile à factoriser**.\n",
    "\n",
    "---\n",
    "\n",
    "**Bilan :**\n",
    "\n",
    "L’analyse met en évidence que **seul le profil 6 mérite une exploration plus approfondie**. On peut maintenant **zoomer sur ce profil**, et **interpréter les clusters qui le composent** en examinant :\n",
    "\n",
    "* La répartition des **genres** et **sous-genres musicaux**.\n",
    "* La structure des **caractéristiques audio** propres à chaque cluster.\n",
    "\n",
    "Cela permettra d’identifier si des **sous-groupes cohérents** émergent au sein de ce profil complexe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier le profil dominant pour chaque morceau\n",
    "dominant_profile = W.argmax(axis=1)  # Renvoie l'indice du profil dominant (0 à 5)\n",
    "\n",
    "# Filtrer uniquement ceux dont le profil dominant est le profil 6 (index 5)\n",
    "profile_6_indices = np.where(dominant_profile == 5)[0]\n",
    "W_profile_6 = W[profile_6_indices]\n",
    "\n",
    "kmeans = KMeans(init='k-means++', n_init='auto', random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans, k=(2, 12))\n",
    "visualizer.fit(W_profile_6)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer uniquement les données correspondant au profil 6\n",
    "profile_6_indices = np.where(dominant_profile == 5)[0]  # Indices des morceaux avec profil dominant 6\n",
    "W_profile_6 = W[profile_6_indices]  # Matrice W pour le profil 6\n",
    "data_songs_profile_6 = data_songs.iloc[profile_6_indices]  # Filtrer les morceaux correspondants\n",
    "\n",
    "# Effectuer le clustering K-Means sur W profil 6\n",
    "kmeans_profile_6 = KMeans(n_clusters=6, random_state=42, n_init='auto')\n",
    "cluster_labels_profile_6 = kmeans_profile_6.fit_predict(W_profile_6)\n",
    "\n",
    "# Ajouter les étiquettes de cluster au DataFrame filtré\n",
    "data_songs_profile_6['kmeans_cluster'] = cluster_labels_profile_6\n",
    "\n",
    "# Créer une matrice de contingence pour les genres de playlist\n",
    "playlist_genres_for_W_profile_6 = data.loc[data_songs_profile_6.index, 'playlist_genre']\n",
    "data_songs_profile_6['playlist_genre'] = playlist_genres_for_W_profile_6\n",
    "\n",
    "# Matrice de contingence : clusters K-Means vs genres de playlist\n",
    "cm_genre_df_profile_6 = pd.crosstab(data_songs_profile_6['playlist_genre'], data_songs_profile_6['kmeans_cluster'])\n",
    "\n",
    "# Visualisation de la matrice de contingence\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm_genre_df_profile_6, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Confusion Matrix: K-Means Clusters vs. Playlist Genres (Profile 6)')\n",
    "plt.ylabel('Actual Playlist Genre')\n",
    "plt.xlabel('K-Means Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une matrice de contingence pour les sous-genres de playlist\n",
    "playlist_subgenres_for_W_profile_6 = data.loc[data_songs_profile_6.index, 'playlist_subgenre']\n",
    "data_songs_profile_6['playlist_subgenre'] = playlist_subgenres_for_W_profile_6\n",
    "\n",
    "# Matrice de contingence : clusters K-Means vs sous-genres de playlist\n",
    "cm_subgenre_df_profile_6 = pd.crosstab(data_songs_profile_6['playlist_subgenre'], data_songs_profile_6['kmeans_cluster'])\n",
    "\n",
    "# Visualisation de la matrice de contingence\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm_subgenre_df_profile_6, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix: K-Means Clusters vs. Playlist Subgenres (Profile 6)')\n",
    "plt.ylabel('Actual Playlist Subgenre')\n",
    "plt.xlabel('K-Means Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Interprétation :**\n",
    "\n",
    "L’analyse des **clusters extraits du profil 6** (via NMF + k-means) révèle des résultats **globalement hétérogènes**, notamment lorsqu’on les compare aux **genres de playlists** : les morceaux sont **fortement dispersés entre les clusters**, ce qui rend l’interprétation difficile.\n",
    "\n",
    "Cependant, en se concentrant sur les **sous-genres musicaux**, **certains motifs apparaissent** et permettent de mieux comprendre la structure interne des clusters. Voici les principales observations :\n",
    "\n",
    "---\n",
    "\n",
    "##### **Une dispersion marquée des morceaux electro-House**\n",
    "\n",
    "Les morceaux d'**electro-house** (et dérivés) sont **présents dans presque tous les clusters**, **à l’exception du cluster 5**. Cela indique que :\n",
    "\n",
    "* Ces morceaux présentent **un large spectre de sonorités**, les rendant difficiles à regrouper de manière cohérente.\n",
    "* Cela suggère que la **NMF + k-means n’a pas réussi à isoler une structure claire** pour ce style, à la différence d’autres genres plus homogènes comme le hard-rock.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Clusters 0 et 3 : Des profils rap différenciés**\n",
    "\n",
    "Ces deux clusters sont dominés par des **sous-genres du rap**, mais selon des nuances distinctes :\n",
    "\n",
    "* Le **cluster 0** contient principalement du **gangster rap** et du **southern hip-hop**, qui y sont **deux fois plus représentés** que les autres styles de rap.\n",
    "* Le **cluster 3**, quant à lui, est **plus équilibré** : on y trouve des parts similaires de **trap**, **hip-hop**, **southern hip-hop** et **gangster rap**, avec aussi une présence notable de **latin hip-hop**.\n",
    "\n",
    "Ces différences montrent que **le modèle distingue finement certaines nuances à l’intérieur même du spectre rap**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Cluster 1 : Une dominante pop**\n",
    "\n",
    "À première vue, le **cluster 1** semble très hétérogène. Toutefois, en examinant les sous-genres les plus fréquents, une tendance claire émerge :\n",
    "\n",
    "* On y retrouve majoritairement des styles tels que **pop**, **pop-rock**, **post-teen pop**, **dance pop**, **latin pop**, **pop-edm**, et **indie poptimism**.\n",
    "\n",
    "Cela s’explique par la **polyvalence intrinsèque des morceaux pop**, souvent présents dans des playlists de styles variés — une **caractéristique reflétée dans leur regroupement** ici.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Cluster 2 : Le noyau dur du rock**\n",
    "\n",
    "Ce cluster est le **plus homogène** de tous :\n",
    "\n",
    "* Il regroupe en majorité des morceaux de **hard-rock**, ainsi que des variantes comme le **pop-rock**, **rock alternatif**, **indie poptimism**, ou encore **permanent wave**.\n",
    "\n",
    "Ce regroupement suggère que **les morceaux de rock (notamment hard) présentent des caractéristiques audio distinctes**, bien captées par la factorisation NMF et le groupement en clusters.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Cluster 5 : Des morceaux hybrides et alternatifs**\n",
    "\n",
    "Ce dernier cluster contient principalement des morceaux de type :\n",
    "\n",
    "* **indie poptimism**\n",
    "* **neo soul**\n",
    "* **urban contemporary**\n",
    "\n",
    "Il semble regrouper des morceaux **plus hybrides, subtils ou alternatifs**, peut-être à la **frontière entre plusieurs styles** — ce qui pourrait expliquer leur isolement dans ce cluster spécifique.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Bilan** :\n",
    "\n",
    "Malgré une **forte hétérogénéité globale du profil 6 de la NMF**, l’analyse fine des **sous-genres** permet d’**extraire des structures locales** intéressantes. En particulier :\n",
    "\n",
    "* Les **morceaux de hard-rock** sont **clairement isolés**.\n",
    "* Les **raps** sont répartis mais **organisés selon des affinités fines**.\n",
    "* Les **morceaux pop**, bien que omniprésents, montrent une **cohérence interne dans leur dispersion**.\n",
    "* Enfin, la **présence massive de l’electro-house dans presque tous les clusters** met en lumière **les limites du k-means à capturer les spécificités de ce style à travers la projection de la NMF**, ou bien la **diversité sonore intrinsèque** de ce genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons mettre en œuvre différentes méthodes de clustering afin d’identifier des groupes homogènes de morceaux au sein de notre jeu de données. L’objectif est de regrouper les morceaux présentant des caractéristiques similaires, sans utiliser d’information sur leur genre ou sous-genre, afin de révéler des structures ou des tendances cachées dans les données.  \n",
    "Nous appliquerons plusieurs algorithmes de clustering non supervisé, tels que **K-Means**, le **mélange gaussien (GMM)** et la **classification ascendante hiérarchique (CAH)**. Nous comparerons ensuite les résultats obtenus et analyserons les profils des clusters identifiés, en les reliant aux variables musicales et aux genres présents dans le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib import colors\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**IMPORTANT**  \n",
    "> Dans ce notebook nous avons fait le choix de faire le clustering pur sur le jeu *data_songs* et ensuite nous allons projeter les clusters obtenus sur les genres des playlists. Ce choix a été fait afin de se concentrer principalement sur les caractéristiques audios des morceaux afin d'obtenir des profils musicaux. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection factorielle des inividus (ACP)\n",
    "On va d'abord afficher la représentation factorielle des individus pour pouvoir voir si on est capable de distinguer des classes naturelles. Pour cela, nous effectuons comme dans la partie précédente une ACP sur le jeu *data_songs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des variables quantitatives de data_songs\n",
    "X = data_songs.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA : on garde 10 composantes pour l'affichage de la variance expliquée\n",
    "pca_songs = PCA(n_components=10)\n",
    "pca_songs_coords = pca_songs.fit_transform(X_scaled)\n",
    "\n",
    "explained_variance = pca_songs.explained_variance_ratio_\n",
    "\n",
    "eig = pd.DataFrame({\n",
    "    \"Dimension\": [f\"CP{i+1}\" for i in range(len(explained_variance))],\n",
    "    \"Variance\": np.round(pca_songs.explained_variance_, 2),\n",
    "    \"% variance expliquée\": np.round(explained_variance * 100, 1),\n",
    "    \"% variance cumulée\": np.round(np.cumsum(explained_variance) * 100, 1)\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.bar(range(1, 11), explained_variance[:10] * 100, align='center', color='coral', ecolor='black')\n",
    "ax1.set_xticks(range(1, 11))\n",
    "ax1.set_xlabel(\"Composante principale\")\n",
    "ax1.set_ylabel(\"% Variance expliquée\")\n",
    "ax1.set_title(\"Pourcentage de variance expliqué\", fontsize=16)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(range(1, 11), np.cumsum(explained_variance[:10]) * 100, color='coral', marker='o')\n",
    "ax2.axhline(80, color='grey', linestyle='--', alpha=0.5, label='80%')\n",
    "ax2.set_xlabel(\"Nombre de composantes\")\n",
    "ax2.set_ylabel(\"% Variance expliquée cumulée\")\n",
    "ax2.set_title(\"Pourcentage de variance expliqué cumulé\", fontsize=16)\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle(\"Résultat ACP sur data_songs\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient les mêmes résultats que pour l'analyse précédente. Nous allons donc faire le choix de faire nos analyses que sur les **3 premières composantes principales**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_songs_df = pd.DataFrame(pca_songs_coords[:, :3], columns=['CP1', 'CP2', 'CP3'])\n",
    "combinations = [('CP1', 'CP2'), ('CP2', 'CP3'), ('CP1', 'CP3')]\n",
    "\n",
    "# On récupère le genre des morceaux depuis le jeu de données initial\n",
    "pca_songs_with_genre = pca_songs_df.copy()\n",
    "pca_songs_with_genre['playlist_genre'] = data.loc[data_songs.index, 'playlist_genre'].values\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
    "\n",
    "# Ligne 1 : scatterplots sans couleur par genre\n",
    "for i, (x, y) in enumerate(combinations):\n",
    "    sns.scatterplot(\n",
    "        data=pca_songs_df,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color='steelblue',\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        ax=axes[0, i]\n",
    "    )\n",
    "    axes[0, i].set_title(f'Projection PCA : {x} vs {y}')\n",
    "    axes[0, i].axhline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    axes[0, i].axvline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "\n",
    "# Ligne 2 : scatterplots colorés par genre\n",
    "for i, (x, y) in enumerate(combinations):\n",
    "    show_legend = (i == 0) \n",
    "    sns.scatterplot(\n",
    "        data=pca_songs_with_genre,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue='playlist_genre',\n",
    "        palette='tab10',\n",
    "        s=10,\n",
    "        alpha=0.6,\n",
    "        ax=axes[1, i],\n",
    "        legend=show_legend\n",
    "    )\n",
    "    axes[1, i].set_title(f'Projection PCA : {x} vs {y} (par genre)')\n",
    "    axes[1, i].axhline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    axes[1, i].axvline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous projetons d’abord les morceaux sur les trois premiers axes principaux sans distinction de genre, afin d’observer si des regroupements naturels apparaissent dans l’espace réduit.  \n",
    "Ensuite, nous colorons les points selon le genre musical associé à chaque morceau pour voir si cette information permet de distinguer des groupes plus nets.\n",
    "\n",
    "Cependant, que ce soit sans ou avec la distinction de genre, aucune séparation claire ou cluster naturel n’apparaît visuellement dans les différents plans factoriels. Cela suggère que les genres sont fortement mélangés dans l’espace des composantes principales. On réussit néanmoins à distinguer que le style **EDM** à l'air de posséder des valeurs plus extrêmes que les autres genres (moins mélangés).  \n",
    "Cette observation motive l’utilisation de méthodes de clustering non supervisées pour aller plus loin dans l’identification de groupes homogènes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "Avant d’appliquer l’algorithme de clustering K-Means, il est nécessaire de choisir le nombre optimal de clusters à utiliser.\n",
    "Comme l’exploration visuelle précédente ne permet pas d’identifier clairement un nombre naturel de groupes, nous avons recours à la méthode du coude.  \n",
    "Cette méthode consiste à faire varier le nombre de clusters et à observer l’évolution de l’inertie (distortion) pour déterminer le point à partir duquel ajouter des clusters n’apporte plus de gain significatif.\n",
    "Le code suivant permet de visualiser ce critère et d’identifier le nombre de clusters optimal pour K-Means :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='k-means++', n_init='auto', random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans, k=(2, 12), metric='distortion')\n",
    "visualizer.fit(pca_songs_df.values)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après le critère, le nombre de classes optimal pour cette méthode de clustering est **5 classes**. Nous allons donc conserver ce nombre pour la suite de notre analyse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5 # nombre de clusters optimal\n",
    "kmeans = KMeans(n_clusters=K, init='k-means++', n_init='auto', max_iter=300, random_state=42)\n",
    "kmeans.fit(pca_songs_df)\n",
    "pca_songs_df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sorted(pca_songs_df['cluster'].unique())\n",
    "colors = plt.colormaps['Set2'].resampled(len(clusters))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].set_title('CP1 vs CP2')\n",
    "axes[1].set_title('CP2 vs CP3')\n",
    "axes[2].set_title('CP1 vs CP3')\n",
    "\n",
    "for i, cluster in enumerate(clusters):\n",
    "    subset = pca_songs_df[pca_songs_df['cluster'] == cluster]\n",
    "    axes[0].scatter(subset['CP1'], subset['CP2'], label=f'Cluster {cluster}', alpha=0.6, s=10, color=colors(i))\n",
    "    axes[1].scatter(subset['CP2'], subset['CP3'], label=f'Cluster {cluster}', alpha=0.6, s=10, color=colors(i))\n",
    "    axes[2].scatter(subset['CP1'], subset['CP3'], label=f'Cluster {cluster}', alpha=0.6, s=10, color=colors(i))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend(title='Cluster')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans chacune des représentations, nos clusters semblent être assez distincts. Il ne semble pas y avoir beaucoup de mélange de classes. \n",
    "\n",
    "Certaines classes semblent avoir une taille différente, pouvant indiquer un éventuel déséquilibre.\n",
    "\n",
    "Afin d'avoir une analyse plus complète de ces clusters, nous allons étudier les variables explicatives du jeu de données avec les clusters obtenus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étude des autres variables quantitatives avec nos clusters**  \n",
    "On a plusieurs manières d'étudier les variables quantitatives dans nos clusters, soit avec des boxplots (assez visuels), soit avec une `heatmap`, cela permet d'avoir les moyennes centralisées et on a un visuel global de répartitions dans les clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_songs['cluster'] = pca_songs_df['cluster'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'valence', 'tempo', 'track_popularity', \n",
    "    'release_year', 'duration_s'\n",
    "]\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = (len(features) + n_cols - 1) // n_cols  \n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='cluster', y=feature, data=data_songs, ax=axes[i], showfliers=False)\n",
    "    axes[i].set_title(f'{feature} par cluster KMeans')\n",
    "\n",
    "for j in range(len(features), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici l'analyse que nous pouvons fournir à l'aide de la lecture des boxplots.\n",
    "\n",
    "**Cluster 0 :**  \n",
    "* Morceaux avec une *danceability* moyenne, mais avec une *energy*, *loudness* et *tempo* très élevé.\n",
    "* L'*acousticness* et la *valence* sont assez faibles.\n",
    "* <u>**Profil**</u> **:** Morceaux dynamiques et puissants qui sont peu acoustiques et joyeux.\n",
    "\n",
    "**Cluster 1 :**\n",
    "* Haute *danceability* mais le reste des variables ont un profil plutôt moyen. \n",
    "* <u>**Profil**</u> **:** Morceaux très dansants, mais modérément dynamiques. \n",
    "\n",
    "**Cluster 2 :**\n",
    "* L'*acousticness* et l'*instrumentalness* sont élevés, pour le reste, tout est assez faible. \n",
    "* <u>**Profil**</u> **:** Morceaux calmes, acoustiques et peu joyeux. \n",
    "\n",
    "**Cluster 3 :**\n",
    "* La *danceability* est très élevée, de même que pour *energy*, *loudness* et *valence*. \n",
    "* <u>**Profil**</u> **:** Morceaux dynamiques, puissants, dansants et joyeux. \n",
    "\n",
    "**Cluster 4 :**\n",
    "* La *danceability* est élevé, ainsi qu'*energy*, *loudness* et *instrumentalness*. La *valence* est plutôt moyenne. \n",
    "* La durée des morceaux de ce cluster est plus longue que pour les autres. Et la popularité est très faible. \n",
    "* <u>**Profil**</u> **:** Morceaux instrumentaux, dynamiques, qui sont longs et peu populaires. \n",
    "\n",
    "D'après ces premières analyses, on peut penser aux genres musicaux suivants pour chaque cluster : \n",
    "* Cluster 0 : rock, électro. \n",
    "* Cluster 1 : pop, hip-hop.\n",
    "* Cluster 2 : musiques d'ambiances, ballades.\n",
    "* Cluster 3 : musiques très festives, comme la pop festive, dance.\n",
    "* Cluster 4 : musiques très instrumentales comme les bandes originales de films ou de l'électro. \n",
    "\n",
    "Nous allons ensuite afficher la proportion des genres dans les clusters. Cela va nous permettre d'éventuellement confirmer nos analyses faites précédemment. \n",
    "\n",
    "Pour valider et affiner l’interprétation de nos clusters, nous avons croisé l’appartenance aux clusters avec les genres et sous-genres musicaux à l’aide de tableaux croisés (crosstab) et de heatmaps. Cela permet de visualiser la répartition des genres au sein de chaque cluster et d’identifier d’éventuelles correspondances fortes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des clusters au DataFrame original\n",
    "data_with_clusters = data.merge(\n",
    "    data_songs[['track_artist', 'track_name', 'cluster']],\n",
    "    on=['track_artist', 'track_name'],\n",
    "    how='left'  \n",
    ")\n",
    "\n",
    "cluster_genre_table = pd.crosstab(\n",
    "    data_with_clusters['playlist_genre'],\n",
    "    data_with_clusters['cluster'],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "sns.heatmap(cluster_genre_table, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Proportions des genres par cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"genre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab cluster vs subgenre\n",
    "cluster_subgenre_table = pd.crosstab(\n",
    "    data_with_clusters['playlist_subgenre'],\n",
    "    data_with_clusters['cluster'],\n",
    "\n",
    "    normalize='index'\n",
    ")\n",
    "sns.heatmap(cluster_subgenre_table, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"\\nProportions des sous-genres par cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Sous-genre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats des crosstabs confirment nos analyses précédentes :\n",
    "\n",
    "* **Cluster 0** est fortement associé aux genres **rock** et sous-genres comme **hard rock, album rock, ou progressive electro house**, ce qui correspond à son profil dynamique, énergique et peu acoustique.\n",
    "\n",
    "* **Cluster 1** regroupe une part importante de morceaux **r&b, rap,** et des sous-genres comme **trap, hip pop, ou neo soul**, en cohérence avec son profil très dansant, populaire et modérément énergique.\n",
    "\n",
    "* **Cluster 2** est plus diffus mais montre une surreprésentation de sous-genres comme **hip hop ou neo soul**, ce qui correspond à un profil plus calme, acoustique ou instrumental.\n",
    "\n",
    "* **Cluster 3** concentre une forte proportion de morceaux **latin** et des sous-genres comme **reggaeton, latin pop, ou dance pop**, ce qui colle avec son profil festif, très dansant et joyeux. \n",
    "\n",
    "* **Cluster 4** est particulièrement présent dans des sous-genres instrumentaux ou **électro comme electro house, progressive electro house, ou big room**, ce qui correspond à son profil instrumental, dynamique et peu populaire.\n",
    "\n",
    "Ainsi, la correspondance entre clusters et genres/sous-genres musicaux, mise en évidence par les heatmaps, valide la pertinence et la cohérence de notre segmentation : chaque cluster regroupe bien des morceaux aux caractéristiques musicales proches, confirmant les profils identifiés par l’analyse descriptive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de Mélange Gaussien (GMM)\n",
    "\n",
    "Le modèle de mélange gaussien (GMM) est une méthode de clustering probabiliste qui permet de modéliser les données comme un mélange de plusieurs distributions gaussiennes. Contrairement à K-Means, GMM peut capturer des formes de clusters plus complexes et des variances différentes entre les clusters.\n",
    "\n",
    "Nous allons appliquer le GMM sur les mêmes données que pour K-Means, en utilisant les trois premières composantes principales de l'ACP. Nous allons également utiliser le critère de BIC pour déterminer le nombre optimal de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_scores = []\n",
    "n_components_range = range(2, 13)\n",
    "X_pca = pca_songs_df[['CP1', 'CP2', 'CP3']].copy()\n",
    "\n",
    "# Calcul des scores pour chaque nombre de clusters\n",
    "for n in n_components_range:\n",
    "    gmm = GaussianMixture(n_components=n, random_state=42)\n",
    "    gmm.fit(X_pca)\n",
    "    labels = gmm.predict(X_pca)\n",
    "    \n",
    "    bic_scores.append(gmm.bic(X_pca))\n",
    "    \n",
    "scores_df = pd.DataFrame({\n",
    "    \"Nombre de clusters\": n_components_range,\n",
    "    \"BIC\": bic_scores,\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(data=scores_df, x=\"Nombre de clusters\", y=\"BIC\", marker=\"o\", label=\"BIC\", color=\"blue\")\n",
    "\n",
    "bic_min = scores_df.loc[scores_df[\"BIC\"].idxmin(), \"Nombre de clusters\"]\n",
    "\n",
    "plt.axvline(x=bic_min, color=\"blue\", linestyle=\"--\", alpha=0.5)\n",
    "plt.title(\"Évaluation du nombre de clusters GMM (BIC)\")\n",
    "plt.xlabel(\"Nombre de clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "scores_df['BIC_diff'] = scores_df['BIC'].diff().abs()\n",
    "# Affichage du plus grand saut de score\n",
    "max_bic_diff = scores_df['BIC_diff'].max()\n",
    "max_bic_diff_index = scores_df['BIC_diff'].idxmax()\n",
    "if max_bic_diff_index > 0:\n",
    "    print(f\"\\nMaximum BIC difference is between {scores_df['Nombre de clusters'][max_bic_diff_index-1]} and {scores_df['Nombre de clusters'][max_bic_diff_index]} clusters: {max_bic_diff}\")\n",
    "else:\n",
    "    print(\"\\nNo BIC difference to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, le critère BIC indique que le nombre optimal de clusters est 10 clusters. Ce choix optimise le critère statistique, mais implique des groupes plus petits et une interprétation potentiellement plus complexe.\n",
    "\n",
    "Nous avons donc décidé de retenir ce nombre de clusters pour la suite de l’analyse, sans chercher à simplifier davantage le modèle. Les analyses et visualisations suivantes seront donc réalisées avec 10 clusters, conformément à l’optimum donné par le BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le modèle GMM et obtenir les labels\n",
    "gmm = GaussianMixture(n_components=10, random_state=42)\n",
    "gmm.fit(pca_songs_df[['CP1', 'CP2', 'CP3']])\n",
    "labels_gmm = gmm.predict(pca_songs_df[['CP1', 'CP2', 'CP3']])\n",
    "\n",
    "# Ajouter les clusters GMM au DataFrame\n",
    "pca_songs_df['cluster_gmm'] = labels_gmm\n",
    "data_songs['cluster_gmm'] = labels_gmm\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.scatterplot(x=pca_songs_df['CP1'], y=pca_songs_df['CP2'], hue=labels_10, palette='tab20', s=10, alpha=0.7, ax=axes[0])\n",
    "axes[0].set_title('GMM - 10 clusters : CP1 vs CP2')\n",
    "axes[0].axhline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "axes[0].axvline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "axes[0].legend(title='Cluster', loc='best', fontsize='small')\n",
    "\n",
    "\n",
    "sns.scatterplot(x=pca_songs_df['CP2'], y=pca_songs_df['CP3'], hue=labels_10, palette='tab10', s=10, alpha=0.7, ax=axes[1])\n",
    "axes[1].set_title('GMM - 10 clusters : CP2 vs CP3')\n",
    "axes[1].axhline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "axes[1].axvline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "axes[1].legend(title='Cluster', loc='best', fontsize='small')\n",
    "\n",
    "sns.scatterplot(x=pca_songs_df['CP1'], y=pca_songs_df['CP3'], hue=labels_10, palette='tab20', s=10, alpha=0.7, ax=axes[2])\n",
    "axes[2].set_title('GMM - 10 clusters : CP1 vs CP3')\n",
    "axes[2].axhline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "axes[2].axvline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "axes[2].legend(title='Cluster', loc='best', fontsize='small')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après nos graphes, dans certains plans les classes se distinguent assez, mais dans d'autres plans on peut voir des superpositions sans affichage distinct (CP2 vs. CP3 et CP1 vs. CP3). \n",
    "\n",
    "Nous allons maintenant afficher les boxplots, afin de trouver des profils type dans nos clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_songs['cluster_gmm'] = pca_songs_df['cluster_gmm'].values\n",
    "n_cols = 4\n",
    "n_rows = (len(features) + n_cols - 1) // n_cols  \n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='cluster_gmm', y=feature, data=data_songs, ax=axes[i], showfliers=False)\n",
    "    axes[i].set_title(f'{feature} par cluster GMM')\n",
    "\n",
    "for j in range(len(features), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des clusters GMM dans data initial\n",
    "data_with_gmm_clusters = data.merge(\n",
    "    data_songs[['track_artist', 'track_name', 'cluster_gmm']],\n",
    "    on=['track_artist', 'track_name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crosstab genre vs cluster_gmm\n",
    "cluster_gmm_genre_table = pd.crosstab(\n",
    "    data_with_gmm_clusters['playlist_genre'],\n",
    "    data_with_gmm_clusters['cluster_gmm'],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "# Crosstab subgenre vs cluster_gmm\n",
    "cluster_gmm_subgenre_table = pd.crosstab(\n",
    "    data_with_gmm_clusters['playlist_subgenre'],\n",
    "    data_with_gmm_clusters['cluster_gmm'],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "sns.heatmap(cluster_gmm_genre_table, annot=True, cmap='coolwarm', fmt='.2f', ax=axes[0])\n",
    "axes[0].set_title(\"Répartition des genres par cluster GMM\")\n",
    "axes[0].set_xlabel(\"Cluster\")\n",
    "axes[0].set_ylabel(\"Genre\")\n",
    "\n",
    "sns.heatmap(cluster_gmm_subgenre_table, annot=True, cmap='coolwarm', fmt='.2f', ax=axes[1])\n",
    "axes[1].set_title(\"Répartition des sous-genres par cluster GMM\")\n",
    "axes[1].set_xlabel(\"Cluster\")\n",
    "axes[1].set_ylabel(\"Sous-genre\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous effectuons une analyse croisée directement entre les profils des clusters obtenu par GMM et la répartition des genres et sous-genres :\n",
    "\n",
    "**Cluster 0 :**  \n",
    "- **Profil audio** : Très dynamique, dansant, joyeux, peu acoustique.\n",
    "- **Genres dominants** : EDM (22 %), pop (22 %), latin (19 %), rock (13 %), rap (13 %).\n",
    "- **Sous-genres marquants** : dance pop (30 %), big room (22 %), electro house (22 %), pop edm (25 %), post-teen pop (26 %).\n",
    "- **Conclusion** : Ce cluster regroupe surtout des morceaux électro, dance et pop très énergiques.\n",
    "\n",
    "**Cluster 1 :**  \n",
    "- **Profil audio** : Dansant, modérément dynamique, populaire.\n",
    "- **Genres dominants** : pop (22 %), rap (19 %), r&b (17 %), latin (17 %), rock (14 %), edm (11 %).\n",
    "- **Sous-genres marquants** : dance pop (25 %), hip pop (24 %), electropop (19 %), classic rock (17 %), indie poptimism (22 %), trap (27 %), tropical (27 %).\n",
    "- **Conclusion** : Cluster très varié, mais avec une forte composante pop urbaine et dance.\n",
    "\n",
    "**Cluster 2 :**  \n",
    "- **Profil audio** : Calme, très acoustique et instrumental, peu joyeux.\n",
    "- **Genres dominants** : pop (5 %), r&b (9 %), rock (6 %), edm (1 %), latin (3 %), rap (6 %).\n",
    "- **Sous-genres marquants** : hip hop (20 %), neo soul (12 %), instrumental, classic rock (6 %).\n",
    "- **Conclusion** : Morceaux calmes, ambiance, ballades, parfois hip-hop ou soul.\n",
    "\n",
    "**Cluster 3 :**  \n",
    "- **Profil audio** : Très instrumental, long, peu populaire.\n",
    "- **Genres dominants** : edm (9 %), rock (3 %), pop (2 %), latin (2 %), r&b (1 %), rap (0.5 %).\n",
    "- **Sous-genres marquants** : progressive electro house (19 %), electro house (11 %), big room (3 %).\n",
    "- **Conclusion** : Cluster très spécifique, morceaux instrumentaux, électro ou rock progressif.\n",
    "\n",
    "**Cluster 4 :**  \n",
    "- **Profil audio** : Dynamique, rapide, peu instrumental, ambiance électro/rock.\n",
    "- **Genres dominants** : rock (24 %), edm (19 %), pop (11 %), rap (5 %), r&b (3 %), latin (3 %).\n",
    "- **Sous-genres marquants** : hard rock (40 %), big room (30 %), permanent wave (23 %), pop edm (17 %).\n",
    "- **Conclusion** : Morceaux rock énergique, électro rapide, hard rock.\n",
    "\n",
    "**Cluster 5 :**  \n",
    "- **Profil audio** : Puissant, instrumental, long, peu populaire.\n",
    "- **Genres dominants** : edm (20 %), rock (10 %), pop (6 %), latin (2 %), r&b (2 %), rap (3 %).\n",
    "- **Sous-genres marquants** : big room (31 %), progressive electro house (25 %), electro house (18 %).\n",
    "- **Conclusion** : Morceaux électro instrumentaux, rock progressif, BO.\n",
    "\n",
    "**Cluster 6 :**  \n",
    "- **Profil audio** : Très dansant, joyeux, populaire, peu acoustique.\n",
    "- **Genres dominants** : latin (30 %), rap (26 %), r&b (15 %), pop (12 %), edm (6 %), rock (4 %).\n",
    "- **Sous-genres marquants** : reggaeton (50 %), latin pop (31 %), latin hip hop (27 %), gangster rap (31 %), hip hop (28 %), hip pop (25 %).\n",
    "- **Conclusion** : Morceaux très populaires, ambiance reggaeton, latin, hip-hop.\n",
    "\n",
    "**Cluster 7 :**  \n",
    "- **Profil audio** : Calme, acoustique, indie/alternative.\n",
    "- **Genres dominants** : pop (8 %), r&b (12 %), rock (13 %), edm (4 %), latin (5 %), rap (4 %).\n",
    "- **Sous-genres marquants** : album rock (18 %), classic rock (15 %), neo soul (15 %), new jack swing (7 %).\n",
    "- **Conclusion** : Indie, alternative, soul, rock doux.\n",
    "\n",
    "**Cluster 8 :**  \n",
    "- **Profil audio** : Très dansant, joyeux, pop/dance.\n",
    "- **Genres dominants** : latin (8 %), r&b (19 %), pop (7 %), edm (2 %), rock (7 %), rap (13 %).\n",
    "- **Sous-genres marquants** : neo soul (25 %), hip hop (15 %), hip pop (15 %), new jack swing (17 %).\n",
    "- **Conclusion** : Dance, pop joyeuse, soul, hip-hop.\n",
    "\n",
    "**Cluster 9 :**  \n",
    "- **Profil audio** : Très dynamique, joyeux, long, festif.\n",
    "- **Genres dominants** : r&b (16 %), latin (11 %), pop (6 %), edm (7 %), rock (6 %), rap (10 %).\n",
    "- **Sous-genres marquants** : new jack swing (44 %), latin hip hop (18 %), neo soul (14 %).\n",
    "- **Conclusion** : Morceaux festifs, dance longue, influence soul/latin.\n",
    "\n",
    "\n",
    "**Conclusion** :  \n",
    "Les heatmaps confirment et précisent les profils audio : chaque cluster GMM regroupe des morceaux aux caractéristiques musicales proches, avec des genres et sous-genres dominants cohérents avec les profils identifiés par les statistiques descriptives.  \n",
    "Cela valide la pertinence de la segmentation et facilite l’interprétation des groupes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification hiérarchique ascendante (CAH)\n",
    "\n",
    "La classification ascendante hiérarchique (CAH) est une méthode de clustering qui permet de regrouper les données en formant une hiérarchie de clusters. Contrairement à K-Means ou GMM, la CAH ne nécessite pas de spécifier le nombre de clusters à l’avance, mais produit un dendrogramme qui permet de visualiser la structure des données et de choisir un niveau de coupe pour obtenir un nombre souhaité de clusters.\n",
    "\n",
    "Nous allons appliquer la CAH sur les mêmes données que pour K-Means et GMM, en utilisant les trois premières composantes principales de l'ACP. Nous allons ensuite visualiser le dendrogramme pour déterminer le nombre de clusters à retenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, comme pour les méthodes précédentes, il faut trouver le nombre de clusters optimal. Pour cela nous allons utiliser deux méthodes : la méthode du score silhouette, qui va nous renvoyer le nombre de clusters pour lequel le score est maximal, et une méthode visuelle à l'aide d'un dendrogramme.   \n",
    "\n",
    "**Score silhouette**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(X, method='ward')\n",
    "scores = []\n",
    "for k in range(2, 8):\n",
    "    labels = fcluster(Z, k, criterion='maxclust')\n",
    "    score = silhouette_score(X, labels)\n",
    "    scores.append(score)\n",
    "optimal_k = range(2, 8)[scores.index(max(scores))]\n",
    "print(\"Nombre optimal de clusters (CAH, silhouette):\", optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dendrogramme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "Z = linkage(pca_songs_df[['CP1', 'CP2', 'CP3']], method='ward')\n",
    "dendrogram(Z, leaf_rotation=90, leaf_font_size=12, no_labels=True)\n",
    "\n",
    "plt.axhline(y=170, color='red', linestyle='--')\n",
    "plt.title('Dendrogramme - Méthode Ward')\n",
    "plt.xlabel('Index des morceaux (non affichés)')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater que les deux méthodes ne donnent pas le même nombre de clusters optimaux. En effet, le **score silhouette est maximal pour 2 clusters** tandis que le **dendrogramme est optimal pour 3 clusters**. \n",
    " \n",
    "Nous allons projeter les clusters dans les plans factoriels afin de les comparer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# CAH avec 2 clusters \n",
    "n_clusters = 2\n",
    "labels_cah_2 = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "unique_labels_2 = np.sort(np.unique(labels_cah_2))\n",
    "cah_label_map_2 = {old: new for new, old in enumerate(unique_labels_2)}\n",
    "labels_cah_remapped_2 = np.vectorize(cah_label_map_2.get)(labels_cah_2)\n",
    "\n",
    "for i, (x, y) in enumerate(combinations):\n",
    "    sns.scatterplot(\n",
    "        data=pca_songs_df.assign(cluster_cah_2=labels_cah_remapped_2),\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue='cluster_cah_2',\n",
    "        palette='Set2',\n",
    "        s=10,\n",
    "        alpha=0.7,\n",
    "        ax=axes[0, i]\n",
    "    )\n",
    "    axes[0, i].set_title(f'CAH - 2 clusters : {x} vs {y}')\n",
    "    axes[0, i].axhline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    axes[0, i].axvline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    axes[0, i].legend(title='Cluster', loc='best')\n",
    "\n",
    "# CAH avec 3 clusters (retenu pour la suite)\n",
    "n_clusters = 3\n",
    "labels_cah_3 = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "unique_labels_3 = np.sort(np.unique(labels_cah_3))\n",
    "cah_label_map_3 = {old: new for new, old in enumerate(unique_labels_3)}\n",
    "labels_cah_remapped_3 = np.vectorize(cah_label_map_3.get)(labels_cah_3)\n",
    "\n",
    "pca_songs_df['cluster_cah_3'] = labels_cah_remapped_3\n",
    "data_songs['cluster_cah_3'] = labels_cah_remapped_3\n",
    "\n",
    "for i, (x, y) in enumerate(combinations):\n",
    "    sns.scatterplot(\n",
    "        data=pca_songs_df,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue='cluster_cah_3',\n",
    "        palette='Set2',\n",
    "        s=10,\n",
    "        alpha=0.7,\n",
    "        ax=axes[1, i]\n",
    "    )\n",
    "    axes[1, i].set_title(f'CAH - 3 clusters : {x} vs {y}')\n",
    "    axes[1, i].axhline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    axes[1, i].axvline(0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    axes[1, i].legend(title='Cluster', loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Projection de 2 clusters**  \n",
    "On observe une séparation assez grossière de l'ensemble des morceaux en deux groupes. Les clusters ne sont pas de taille homogène, mettant en évidence l'opposition structurelle dans les données, mais chaque cluster regroupe une grande diversité de morceaux, donc cela pourrait se traduire par une forte hétérogénéité dans les analyses futures. \n",
    "\n",
    "**Projection de 3 clusters**  \n",
    "Avec trois clusters, la séparation devient automatiquement plus fine. \n",
    "* Dans certains plans factoriels la distinction des classes est assez simple, et dans d'autres plans les classes peuvent être légèrement mélangées. \n",
    "* Cette segmentation permet de mieux capturer la diversité des profils musicaux. **C'est celle que nous allons conserver dans les analyses suivantes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_songs['cluster_cah_3'] = pca_songs_df['cluster_cah_3'].values\n",
    "\n",
    "data_with_cah_clusters = data.merge(\n",
    "    data_songs[['track_artist', 'track_name', 'cluster_cah_3']],\n",
    "    on=['track_artist', 'track_name'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 4\n",
    "n_rows = (len(features) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='cluster_cah_3', y=feature, data=data_songs, ax=axes[i], showfliers=False, width=0.4)\n",
    "    axes[i].set_title(f'{feature} par cluster CAH')\n",
    "\n",
    "for j in range(len(features), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab genre vs cluster_cah_3\n",
    "cluster_cah_genre_table = pd.crosstab(\n",
    "    data_with_cah_clusters['playlist_genre'],\n",
    "    data_with_cah_clusters['cluster_cah_3'],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "# Crosstab subgenre vs cluster_cah_3\n",
    "cluster_cah_subgenre_table = pd.crosstab(\n",
    "    data_with_cah_clusters['playlist_subgenre'],\n",
    "    data_with_cah_clusters['cluster_cah_3'],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "sns.heatmap(cluster_cah_genre_table, annot=True, cmap='coolwarm', fmt='.2f', ax=axes[0])\n",
    "axes[0].set_title(\"Répartition des genres par cluster CAH\")\n",
    "axes[0].set_xlabel(\"Cluster\")\n",
    "axes[0].set_ylabel(\"Genre\")\n",
    "\n",
    "sns.heatmap(cluster_cah_subgenre_table, annot=True, cmap='coolwarm', fmt='.2f', ax=axes[1])\n",
    "axes[1].set_title(\"Répartition des sous-genres par cluster CAH\")\n",
    "axes[1].set_xlabel(\"Cluster\")\n",
    "axes[1].set_ylabel(\"Sous-genre\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les méthodes précédentes, nous croisons nos analyses avec les genres des playlists, nous permettant de mettre en avant des profils audios. \n",
    "\n",
    "**Cluster 0**\n",
    "- **Profil audio** :  \n",
    "  - *Danceability* moyenne, *energy* faible, *loudness* faible\n",
    "  - Très *acoustique* (0.56), *instrumentalness* élevé, *valence* faible\n",
    "  - *Popularité* la plus haute\n",
    "- **Genres dominants** :  \n",
    "  - Surreprésentation de **r&b** (23 %), **rock** (13 %), **pop** (11 %)\n",
    "- **Sous-genres marquants** :  \n",
    "  - *neo soul*, *hip hop*, *indie poptimism*, *classic rock*, *album rock*\n",
    "- **Interprétation** : Morceaux calmes, acoustiques, parfois instrumentaux, souvent issus du r&b, rock doux ou indie.\n",
    "\n",
    "**Cluster 1**\n",
    "- **Profil audio** :  \n",
    "  - *Danceability* très élevée, *energy* moyenne-haute, *loudness* modéré \n",
    "  - *Acousticness* faible, *instrumentalness* très faible, *valence* très élevée\n",
    "  - *Popularité* moyenne\n",
    "- **Genres dominants** :  \n",
    "  - **latin** (62 %), **rap** (61 %), **r&b** (53 %), **pop** (38 %)\n",
    "- **Sous-genres marquants** :  \n",
    "  - *reggaeton*, *latin hip hop*, *new jack swing*, *dance pop*, *hip pop*, *trap*\n",
    "- **Interprétation** : Morceaux très dansants, festifs, joyeux, peu acoustiques, typiques du latin, rap, r&b moderne.\n",
    "\n",
    "**Cluster 2**\n",
    "- **Profil audio** :  \n",
    "  - *Danceability* moyenne-basse, *energy* la plus élevée, *loudness* la plus forte\n",
    "  - *Acousticness* très faible, *instrumentalness* la plus élevée, *valence* moyenne\n",
    "  - *Popularité* la plus faible\n",
    "- **Genres dominants** :  \n",
    "  - **edm** (73 %), **rock** (66 %), **pop** (51 %)\n",
    "- **Sous-genres marquants** :  \n",
    "  - *big room*, *progressive electro house*, *hard rock*, *electro house*, *permanent wave*\n",
    "- **Interprétation** : Morceaux très dynamiques, puissants, peu acoustiques, souvent instrumentaux, typiques de l’EDM, rock énergique ou électro.\n",
    "\n",
    "\n",
    "**Conclusion**  \n",
    "La CAH distingue :\n",
    "- **Cluster 0** : Calme, acoustique, r&b/rock/indie, populaire.\n",
    "- **Cluster 1** : Très dansant, festif, latin/rap/r&b, joyeux, populaire.\n",
    "- **Cluster 2** : Très dynamique, EDM/rock, instrumental, peu populaire, morceaux longs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "data_with_clusters = data.merge(\n",
    "    data_songs[['track_artist', 'track_name', 'cluster', 'cluster_gmm', 'cluster_cah_3']],\n",
    "    on=['track_artist', 'track_name'],\n",
    "    how='left'\n",
    ")\n",
    "# --- Comparaison CAH vs GMM ---\n",
    "cm_cah_gmm = confusion_matrix(data_with_clusters['cluster_cah_3'], data_with_clusters['cluster_gmm'])\n",
    "row_ind_cah_gmm, col_ind_cah_gmm = linear_sum_assignment(-cm_cah_gmm)\n",
    "mapping_cah_gmm = {old: new for old, new in zip(col_ind_cah_gmm, row_ind_cah_gmm)}\n",
    "data_with_clusters['cluster_gmm_aligned_to_cah'] = data_with_clusters['cluster_gmm'].map(mapping_cah_gmm)\n",
    "cm_cah_gmm_aligned = confusion_matrix(\n",
    "    data_with_clusters['cluster_cah_3'],\n",
    "    data_with_clusters['cluster_gmm_aligned_to_cah']\n",
    ")\n",
    "ConfusionMatrixDisplay(cm_cah_gmm_aligned).plot()\n",
    "plt.xlabel('Clusters GMM (alignés sur CAH)')\n",
    "plt.ylabel('Clusters CAH')\n",
    "plt.title('Comparaison des clusters CAH et GMM (alignés)')\n",
    "plt.show()\n",
    "\n",
    "# --- Comparaison CAH vs KMeans ---\n",
    "cm_cah_kmeans = confusion_matrix(data_with_clusters['cluster_cah_3'], data_with_clusters['cluster'])\n",
    "row_ind_cah_kmeans, col_ind_cah_kmeans = linear_sum_assignment(-cm_cah_kmeans)\n",
    "mapping_cah_kmeans = {old: new for old, new in zip(col_ind_cah_kmeans, row_ind_cah_kmeans)}\n",
    "data_with_clusters['cluster_kmeans_aligned_to_cah'] = data_with_clusters['cluster'].map(mapping_cah_kmeans)\n",
    "cm_cah_kmeans_aligned = confusion_matrix(\n",
    "    data_with_clusters['cluster_cah_3'],\n",
    "    data_with_clusters['cluster_kmeans_aligned_to_cah']\n",
    ")\n",
    "ConfusionMatrixDisplay(cm_cah_kmeans_aligned).plot()\n",
    "plt.xlabel('Clusters KMeans (alignés sur CAH)')\n",
    "plt.ylabel('Clusters CAH')\n",
    "plt.title('Comparaison des clusters CAH et KMeans (alignés)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des méthodes de clustering\n",
    "Dans cette partie, nous appliquons une Analyse des Correspondances Multiples (MCA) pour comparer les résultats des différentes méthodes de clustering (K-Means, GMM, CAH). \n",
    "L’objectif est de visualiser les clusters obtenus par chaque méthode dans un espace factoriel commun, afin d’évaluer leur cohérence et leur séparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prince\n",
    "\n",
    "# On réduit certaines modalités afin de rendre l'analyse plus simple.\n",
    "# La MCA peut-être sensible aux nombre de modalités dans les colonnes catégorielles.\n",
    "freq_artists = data['track_artist'].value_counts()\n",
    "top_artists = freq_artists[freq_artists > 60].index\n",
    "data['track_artist_reduced'] = data['track_artist'].apply(lambda x: x if x in top_artists else 'Other')\n",
    "\n",
    "freq_albums = data['track_album_name'].value_counts()\n",
    "top_albums = freq_albums[freq_albums > 10].index\n",
    "data['track_album_name_reduced'] = data['track_album_name'].apply(lambda x: x if x in top_albums else 'Other')\n",
    "\n",
    "# Variables catégorielles sélectionnées pour la MCA\n",
    "cols_cat_reduced = ['track_artist_reduced', 'track_album_name_reduced', 'playlist_name', \n",
    "                    'playlist_genre', 'playlist_subgenre', 'key', 'mode']\n",
    "\n",
    "\n",
    "# Echantillonnage pour pour éviter les problèmes de performance\n",
    "# Vérification des valeurs manquantes\n",
    "data_sample = data.sample(n=5000, random_state=42)\n",
    "data_sample_clean = data_sample[cols_cat_reduced].astype(str)\n",
    "\n",
    "mca = prince.MCA(n_components=2, n_iter=3, random_state=42)\n",
    "mca_result = mca.fit_transform(data_sample_clean)\n",
    "\n",
    "eig_vals = mca.percentage_of_variance_\n",
    "cumul_vals = mca.cumulative_percentage_of_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique maintenant nos méthodes de clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "X = mca_result.values  # coordonnées MCA\n",
    "\n",
    "# KMeans avec 5 clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "labels_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# GMM avec 10 clusters\n",
    "gmm = GaussianMixture(n_components=10, random_state=42)\n",
    "labels_gmm = gmm.fit_predict(X)\n",
    "\n",
    "# CAH avec 3 clusters\n",
    "Z = linkage(X, method='ward')\n",
    "labels_cah = fcluster(Z, t=3, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher dans le plan de notre MCA nos clusters qui ont été obtenus. Afin de comparer les méthodes, nous allons afficher différents scores. \n",
    "\n",
    "* Le **silhouette score**, qu'on veut le plus élevé possible. Ce score mesure la cohésion interne des clusters et leur séparation.\n",
    "* Le score de **Calinski-Harabasz**, plus il est élevé, mieux c'est. Il mesure la séparation des clusters et leur compacité. \n",
    "* Le score de **Davies-Bouldin**, contrairement aux autres mesures, plus le score est bas, mieux c'est. Ce score mesure la similarité entre les clusters, et nous souhaitons des clusters différents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction pour les pourcentages de variance expliquée dans la MCA\n",
    "\n",
    "# Récupérer les pourcentages de variance expliquée de la MCA\n",
    "explained_var_mca = [eig_vals[0], eig_vals[1]]  # ou utiliser mca.eigenvalues_summary si disponible\n",
    "\n",
    "scores = {\n",
    "    'Méthode': ['KMeans (5)', 'GMM (10)', 'CAH (3)'],\n",
    "    'Silhouette': [\n",
    "        silhouette_score(X, labels_kmeans),\n",
    "        silhouette_score(X, labels_gmm),\n",
    "        silhouette_score(X, labels_cah)\n",
    "    ],\n",
    "    'Calinski-Harabasz': [\n",
    "        calinski_harabasz_score(X, labels_kmeans),\n",
    "        calinski_harabasz_score(X, labels_gmm),\n",
    "        calinski_harabasz_score(X, labels_cah)\n",
    "    ],\n",
    "    'Davies-Bouldin': [\n",
    "        davies_bouldin_score(X, labels_kmeans),\n",
    "        davies_bouldin_score(X, labels_gmm),\n",
    "        davies_bouldin_score(X, labels_cah)\n",
    "    ]\n",
    "}\n",
    "df_scores = pd.DataFrame(scores)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(22,5))\n",
    "\n",
    "# Plot KMeans\n",
    "axs[0].scatter(X[:,0], X[:,1], c=labels_kmeans, cmap='Set2', s=10)\n",
    "axs[0].set_title('KMeans (5 clusters)')\n",
    "axs[0].set_xlabel('MCA Dim 1')\n",
    "axs[0].set_ylabel('MCA Dim 2')\n",
    "\n",
    "# Plot GMM\n",
    "axs[1].scatter(X[:,0], X[:,1], c=labels_gmm, cmap='Set2', s=10)\n",
    "axs[1].set_title('GMM (10 clusters)')\n",
    "axs[1].set_xlabel('MCA Dim 1')\n",
    "\n",
    "# Plot CAH\n",
    "axs[2].scatter(X[:,0], X[:,1], c=labels_cah, cmap='Set2', s=10)\n",
    "axs[2].set_title('CAH (3 clusters)')\n",
    "axs[2].set_xlabel('MCA Dim 1')\n",
    "\n",
    "# Affichage des scores\n",
    "axs[3].axis('off')\n",
    "table_text = df_scores.round(3).to_string(index=False)\n",
    "axs[3].text(0, 0.5, table_text, fontsize=12, fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après nos graphiques, nous pouvons juger la séparation spatiale des clusters. \n",
    "\n",
    "Les plots obtenus par K-Means et CAH semblent bien séparer chaque classe. Pour celui obtenu par GMM, nous pouvons voir qu'il y a des recouvrements entre les classes, ce qui indique une méthode plus faible pour les séparations de classes. \n",
    "\n",
    "Les scores nous fournissent les informations suivantes :\n",
    "* **Silhouette :** \n",
    "  * **K-Means** a de loin le meilleur score (0.73), indiquant que les clusters sont très bien séparés. \n",
    "  * GMM et CAH ont eux des scores moins bons (0.58 et 0.63 respectivement).\n",
    "* **Calinski-Harabasz :**\n",
    "  * De nouveau **K-Means** possède le score le plus élevé, ce qui confirme la qualité de séparation.\n",
    "  * De même, GMM et CAH sont nettement en dessous. \n",
    "* **Davies-Bouldin :**\n",
    "  * **K-Means** a le score le plus bas (0.34), donc les classes sont distinctes. \n",
    "  * GMM a un score de 1.17, ce qui est très élevé. Cela confirme notre analyse visuelle. \n",
    "  * CAH lui a un score moyen. \n",
    "\n",
    "**Conclusion :** K-Means est de loin la méthode la plus adaptée à notre jeu de données. GMM semble sur-segmenter les données, et CAH forme des clusters plus larges, donc moins séparés. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous affichons maintenant la répartition des clusters ainsi que les genres et sous-genres dans l'espace MCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordonnées des modalités (genres et sous-genres)\n",
    "mod_coords = mca.column_coordinates(data_sample_clean)\n",
    "\n",
    "# Ajouter les clusters KMeans au DataFrame data_sample\n",
    "data_sample['cluster_kmeans'] = labels_kmeans\n",
    "\n",
    "# Barycentres des clusters dans l'espace MCA\n",
    "cluster_centers = []\n",
    "for k in sorted(data_sample['cluster_kmeans'].unique()):\n",
    "    cluster_centers.append(X[data_sample['cluster_kmeans'] == k].mean(axis=0))\n",
    "cluster_centers = np.array(cluster_centers)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Coordonnées des modalités\n",
    "mod_coords = mca.column_coordinates(data_sample_clean)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Projection des modalités de genre\n",
    "for idx in mod_coords.index:\n",
    "    if idx.startswith('playlist_genre_'):\n",
    "        plt.scatter(mod_coords.loc[idx, 0], mod_coords.loc[idx, 1], color='red', marker='x', s=80, label='Genre' if idx == 'playlist_genre_' + data_sample_clean['playlist_genre'].unique()[0] else \"\")\n",
    "        plt.text(mod_coords.loc[idx, 0], mod_coords.loc[idx, 1], idx.replace('playlist_genre_', ''), color='red', fontsize=12)\n",
    "\n",
    "\n",
    "# Projection des sous-genres\n",
    "for idx in mod_coords.index:\n",
    "    if idx.startswith('playlist_subgenre_'):\n",
    "        plt.scatter(mod_coords.loc[idx, 0], mod_coords.loc[idx, 1], color='green', marker='^', s=50, label='Sous-genre' if idx == 'playlist_subgenre_' + data_sample_clean['playlist_subgenre'].unique()[0] else \"\")\n",
    "        plt.text(mod_coords.loc[idx, 0], mod_coords.loc[idx, 1], idx.replace('playlist_subgenre_', ''), color='green', fontsize=8)\n",
    "\n",
    "plt.scatter(cluster_centers[:,0], cluster_centers[:,1], color='blue', s=100, label='Clusters')\n",
    "for i, (x, y) in enumerate(cluster_centers):\n",
    "    plt.text(x, y, f'Cluster {i}', color='blue', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.xlabel('MCA Dim 1')\n",
    "plt.ylabel('MCA Dim 2')\n",
    "plt.title(\"Projection MCA : Genres, Sous-genres et barycentres des clusters\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clusters et barycentres**\n",
    "\n",
    "Les barycentres des clusters (points bleus) indiquent la position moyenne des morceaux appartenant à chaque cluster dans l'espace MCA.\n",
    "Les clusters semblent bien séparés dans l'espace, ce qui suggère une bonne différenciation entre les groupes identifiés par l'algorithme de clustering.\n",
    "\n",
    "**Genres (croix rouges)**\n",
    "\n",
    "Les genres principaux **(pop, rap, latin, rock, etc.)** sont représentés par des croix rouges.\n",
    "\n",
    "Chaque genre est positionné dans l'espace en fonction des caractéristiques qualitatives associées aux morceaux qui lui appartiennent.\n",
    "\n",
    "Par exemple :\n",
    "* **pop** est situé dans une région proche des sous-genres comme **dance pop** et **indie poptimism**, ce qui reflète des caractéristiques communes.\n",
    "* **latin** est proche de sous-genres comme **reggaeton, latin pop, et tropical**, ce qui est cohérent avec son profil festif et dansant.\n",
    "* **rock** est associé à des sous-genres comme **hard rock, classic rock, et album rock,** soulignant son caractère acoustique et énergique.\n",
    "\n",
    "**Sous-genres (triangles verts)**\n",
    "\n",
    "Les sous-genres sont représentés par des triangles verts et sont regroupés autour des genres auxquels ils appartiennent.\n",
    "Par exemple :\n",
    "* Les sous-genres **trap, hip hop, et gangster rap** sont proches du genre **rap**, ce qui reflète leur forte association.\n",
    "* Les sous-genres progressive **electro house, electro house, et big room** sont proches de **edm**, ce qui correspond à leur nature électronique et instrumentale.\n",
    "\n",
    "**Interprétation des clusters**\n",
    "\n",
    "**Cluster 0 :** Situé dans une région associée à des sous-genres comme **electropop, post-teen pop, et dance pop,** ce cluster semble regrouper des morceaux pop modernes et dansants.\n",
    "\n",
    "**Cluster 1 :** Proche de **latin, reggaeton, et latin pop**, ce cluster regroupe des morceaux festifs et dansants, typiques de la musique latine.\n",
    "\n",
    "**Cluster 2 :** Associé à **rock, hard rock, et classic rock**, ce cluster regroupe des morceaux dynamiques et acoustiques.\n",
    "\n",
    "**Cluster 3 :** Proche de sous-genres électroniques comme **progressive electro house et electro house,** ce cluster regroupe des morceaux instrumentaux et dynamiques.\n",
    "\n",
    "**Cluster 4 :** Isolé dans une région éloignée, ce cluster semble regrouper des morceaux très spécifiques, peut-être instrumentaux ou expérimentaux.\n",
    "\n",
    "**Séparation des clusters**\n",
    "\n",
    "Les clusters sont bien séparés dans l'espace MCA, ce qui indique une bonne cohérence des groupes formés.\n",
    "Les genres et sous-genres proches des barycentres des clusters confirment la pertinence des regroupements.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Ce graphique met en évidence une bonne correspondance entre les clusters identifiés et les genres/sous-genres musicaux. Les barycentres des clusters sont cohérents avec les genres et sous-genres associés, ce qui valide la segmentation réalisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Système de recommandation\n",
    "\n",
    "### Objectif\n",
    "L'objectif de cette section est de développer un système de recommandation basé sur les profils musicaux latents identifiés par la NMF. Ce système permettra de :\n",
    "\n",
    "1. Recommander des **morceaux à ajouter à une playlist existante** en analysant son profil musical global\n",
    "2. Suggérer des **chansons similaires à un morceau spécifique choisi** par l'utilisateur\n",
    "\n",
    "### Méthodologie\n",
    "En se basant sur les 6 profils latents extraits (instrumental, énergique-intense, live, émotionnel-valence, acoustique-chant, rap-rythmé), le système calcule des mesures de similarité pour proposer des recommandations personnalisées et pertinentes.\n",
    "\n",
    "1. **Extraction des profils latents** : Utilisation des 6 profils musicaux latents identifiés par la NMF.\n",
    "2. **Calcul de similarité** : Mesures de similarité entre les morceaux ou le profil moyen d'une playlist et les profils latents pour déterminer les recommandations.\n",
    "3. **Recommandation personnalisée** : Proposer des morceaux en fonction des similarités calculées.\n",
    "\n",
    "Nous commençons par effectuer une recommandation à partir d'une chanson spécfique. Pour cela, nous allons utiliser la fonction `recommend_similar_tracks` qui prend en entrée un morceau et renvoie les morceaux similaires en fonction de leur profil musical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_similar_tracks(track_name, track_artist, num_recommendation=3):\n",
    "    # Trouver l'index de la chanson dans data_songs\n",
    "    song_idx = data_songs[\n",
    "        (data_songs['track_name'] == track_name) & \n",
    "        (data_songs['track_artist'] == track_artist)\n",
    "    ].index\n",
    "    \n",
    "    if len(song_idx) == 0:\n",
    "        return f\"Track '{track_name}' by '{track_artist}' not found in the dataset.\"\n",
    "    \n",
    "    song_idx = song_idx[0]\n",
    "    \n",
    "    # Récupérer le profil de la chanson dans profile_weights\n",
    "    song_profile = profile_weights.loc[song_idx].values.reshape(1, -1)\n",
    "    \n",
    "    # Calculer les similarités cosinus avec toutes les autres chansons\n",
    "    similarities = cosine_similarity(song_profile, profile_weights).flatten()\n",
    "    \n",
    "    # Trier les indices des chansons par similarité décroissante\n",
    "    similar_indices = similarities.argsort()[::-1]\n",
    "    \n",
    "    # Exclure la chanson elle-même et prendre les num_recommendation plus proches\n",
    "    similar_indices = [idx for idx in similar_indices if idx != song_idx][1:num_recommendation+1]\n",
    "    \n",
    "    # Récupérer les informations des chansons similaires\n",
    "    similar_tracks = data_songs.iloc[similar_indices][['track_name', 'track_artist']]\n",
    "    similar_tracks['similarity'] = similarities[similar_indices]\n",
    "    \n",
    "    return similar_tracks.reset_index(drop=True)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "recommend_similar_tracks(\"Thunderstruck\", \"AC/DC\", num_recommendation=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme nous renvoie les morceaux les plus similaires au morceau choisi, en se basant sur les profils musicaux latents. Ce sont des morceaux qui partagent des caractéristiques audio avec `Thunderstruck`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous allons faire une recommandation de morceaux à ajouter à une playlist existante avec la fonction `recommend_similar_tracks_playlist` qui prend en entrée une playlist et renvoie les morceaux similaires en fonction du profil musical moyen de la playlist.\n",
    "\n",
    "A partir de la playlist Dance Pop: Japan, nous allons extraire le profil musical moyen de cette playlist et recommander des morceaux similaires en fonction des profils musicaux latents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_songs_with_playlist = data_songs.copy()\n",
    "data_songs_with_playlist['playlist_name'] = data['playlist_name']\n",
    "\n",
    "\n",
    "def recommend_similar_tracks_playlist(playlist_name, num_recommendation=3):\n",
    "    # faire la moyenne des profils des chassons de la playlist\n",
    "    playlist_tracks = data_songs_with_playlist[data_songs_with_playlist['playlist_name'] == playlist_name]\n",
    "    if playlist_tracks.empty:\n",
    "        return f\"Playlist '{playlist_name}' not found in the dataset.\"\n",
    "    \n",
    "    # Calculer le profil moyen de la playlist\n",
    "    playlist_profile = profile_weights.loc[playlist_tracks.index].mean().values.reshape(1, -1)\n",
    "\n",
    "    # Calculer les similarités cosinus avec toutes les autres chansons\n",
    "    similarities = cosine_similarity(playlist_profile, profile_weights).flatten()\n",
    "\n",
    "    # Trier les indices des chansons par similarité décroissante\n",
    "    similar_indices = similarities.argsort()[::-1]\n",
    "    # Exclure les chansons de la playlist elle-même et prendre les num_recommendation plus proches\n",
    "    similar_indices = [idx for idx in similar_indices if idx not in playlist_tracks.index][:num_recommendation]\n",
    "\n",
    "    # Récupérer les informations des chansons similaires\n",
    "    similar_tracks = data_songs.iloc[similar_indices][['track_name', 'track_artist']]\n",
    "    similar_tracks['similarity'] = similarities[similar_indices]\n",
    "\n",
    "    return similar_tracks.reset_index(drop=True)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "recommend_similar_tracks_playlist(\"Dance Pop: Japan\", num_recommendation=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme nous propose les morceaux suivants :\n",
    "* Bailame Despacio - Nacho, Yandel, Bad Bunny\n",
    "* Notorious Thugs - The Notorious B.I.G., 2Pac, Diddy\n",
    "* Wasted on You - Louis Futon\n",
    "\n",
    "Après écoute, ces morceaux correspondent bien à l'esprit de la playlist Dance Pop: Japan. Ils sont dansants, joyeux et dynamiques, ce qui correspond au profil musical de la playlist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet d'analyse de données musicales a permis d'explorer en profondeur un dataset riche de plus de 30 000 morceaux issus de playlists Spotify, en appliquant diverses techniques d'analyse multivariée et d'apprentissage non supervisé.\n",
    "\n",
    "### Apports méthodologiques\n",
    "\n",
    "**Maîtrise d'un pipeline complet d'analyse**  \n",
    "Ce projet nous a permis de développer une expertise transversale en :\n",
    "- **Préparation et nettoyage** de données complexes\n",
    "- **Analyse exploratoire** approfondie avec visualisations avancées\n",
    "- **Application coordonnée** de multiples techniques d'analyse multivariée\n",
    "- **Validation et comparaison** rigoureuse des méthodes de clustering\n",
    "\n",
    "**Expertise en techniques d'analyse multivariée**  \n",
    "Nous avons acquis une maîtrise pratique de :\n",
    "- L'**Analyse en Composantes Principales (ACP)** pour la réduction de dimensionnalité\n",
    "- L'**Analyse des Correspondances Multiples (ACM)** pour les variables qualitatives\n",
    "- La **Factorisation Matricielle Non-Négative (NMF)** pour l'extraction de profils latents\n",
    "- Les **méthodes de clustering** (K-Means, GMM, CAH) avec optimisation des hyperparamètres\n",
    "\n",
    "### Découvertes scientifiques\n",
    "\n",
    "**Structures cachées dans les données musicales**  \n",
    "L'analyse a révélé des **patterns significatifs** :\n",
    "- **6 profils musicaux latents** distincts identifiés par NMF\n",
    "- **Correspondances fortes** entre caractéristiques audio et genres musicaux\n",
    "- **Segmentation naturelle** des morceaux en groupes homogènes\n",
    "\n",
    "**Validation de la cohérence des résultats**  \n",
    "La convergence des différentes méthodes confirme la **robustesse** de nos analyses :\n",
    "- Les clusters correspondent aux genres attendus\n",
    "- Les profils NMF sont musicalement interprétables\n",
    "- La MCA révèle des associations logiques entre variables\n",
    "\n",
    "### Compétences techniques développées\n",
    "\n",
    "**Programmation avancée en Python**  \n",
    "- Manipulation de **pandas** pour les données structurées\n",
    "- Visualisation sophistiquée avec **matplotlib/seaborn**\n",
    "- Implémentation d'algorithmes **scikit-learn** \n",
    "\n",
    "### Applications concrètes\n",
    "\n",
    "Ce projet démontre notre capacité à :\n",
    "- **Transformer** des données brutes en insights exploitables\n",
    "- **Développer** des systèmes de recommandation fonctionnels\n",
    "\n",
    "### Perspectives professionnelles\n",
    "\n",
    "Cette expérience nous prépare à :\n",
    "- **Analyser** tout type de données multidimensionnelles\n",
    "- **Conseiller** sur le choix de méthodes analytiques appropriées\n",
    "- **Communiquer** des résultats techniques\n",
    "\n",
    "Ce projet illustre parfaitement comment l'analyse de données peut révéler des structures cachées dans des domaines complexes, tout en développant une expertise technique solide et une approche méthodologique rigoureuse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
