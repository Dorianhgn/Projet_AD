{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(gridExtra)\n",
    "library(GGally)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(reshape2)\n",
    "library(FactoMineR) \n",
    "library(factoextra)\n",
    "library(glmnet) \n",
    "library(ggfortify)\n",
    "library(pROC)\n",
    "library(ROCR)\n",
    "library(ggpubr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture des données\n",
    "path <- \"data/\"\n",
    "song <- read.csv(paste0(path, \"spotify_songs.csv\"), header = TRUE, sep = \",\")\n",
    "\n",
    "# Premières lignes du jeu de données\n",
    "head(song)\n",
    "\n",
    "# Vérification du contenu\n",
    "summary(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check the data types\n",
    "str(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the track_id, track_album_id, playlist_id columns\n",
    "song <- song[, -c(1, 5, 9)]\n",
    "\n",
    "# As factor the categorical variables track_artist, playlist_genre, playlist_subgenre, key, mode, playlist_name, track_album_name\n",
    "song$playlist_name <- as.factor(song$playlist_name)\n",
    "song$track_album_name <- as.factor(song$track_album_name)\n",
    "song$track_artist <- as.factor(song$track_artist)\n",
    "song$playlist_genre <- as.factor(song$playlist_genre)\n",
    "song$playlist_subgenre <- as.factor(song$playlist_subgenre)\n",
    "song$key <- factor(song$key, levels = c(-1, 0:11), labels = c(\"No key detected\", \"C\", \"C♯/D♭\", \"D\", \"D♯/E♭\", \"E\", \"F\", \"F♯/G♭\", \"G\", \"G♯/A♭\", \"A\", \"A♯/B♭\", \"B\"))\n",
    "song$mode <- factor(song$mode, levels = c(0, 1), labels = c(\"minor\", \"major\"))\n",
    "\n",
    "# track_album_release_date to date (if the full date is not available, we will use the first day of the year)\n",
    "song$track_album_release_date <- as.Date(ifelse(nchar(song$track_album_release_date) != 10, \n",
    "                                                paste0(substr(song$track_album_release_date, 1, 4), \"-01-01\"), \n",
    "                                                song$track_album_release_date), \n",
    "                                         format = \"%Y-%m-%d\")\n",
    "\n",
    "# Convert the duration_ms to seconds and rename the column to duration_s\n",
    "song$duration_s <- song$duration_ms / 1000\n",
    "song$duration_ms <- NULL\n",
    "\n",
    "# Check the modified dataset\n",
    "summary(song)\n",
    "head(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "colSums(is.na(song))\n",
    "\n",
    "# Drop the missing values\n",
    "song <- na.omit(song)\n",
    "\n",
    "# Check the modified dataset\n",
    "colSums(is.na(song))\n",
    "\n",
    "str(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Réduction de dimension par Analyse en Composantes Principales (ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons effectuer une analyse en composantes principales (ACP) sur les données prétraitées. L'ACP est une technique de réduction de dimension qui permet de projeter les données d'origine dans un espace de dimension inférieure. Nous avons gardé 20 variables et nous allons étudier s'il est possible de réduire la dimensionnalité de ces données tout en préservant un maximum d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Format des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on ne sélectionne que les variables quantitatives, en y ajoutant une variable qualitative (playlist_genre) pour voir si elle a un impact sur la projection des données. On garde au final 11 variables quantitatives et 1 variable qualitative.\n",
    "\n",
    "On décide de normaliser les données avant de faire l'ACP car l'ACP est sensible à l'échelle des variables. On va donc centrer et réduire les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# PCA analysis using FactoMineR\n",
    "song_pca <- song[, c(3, 7, 9:10, 12, 14:20)]\n",
    "\n",
    "# Perform PCA\n",
    "pca <- PCA(song_pca,scale.unit = TRUE, graph = FALSE,ncp = 7,quali.sup = 2)\n",
    "\n",
    "# Afficher le pourcentage de variance expliquée par chaque composante principale\n",
    "fviz_eig(pca, addlabels = TRUE, ylim = c(0, 40))\n",
    "\n",
    "# Calculer la variance cumulée\n",
    "explained_variance <- pca$eig[, 2]  # La deuxième colonne contient le pourcentage de variance expliquée\n",
    "cumulative_variance <- cumsum(explained_variance) \n",
    "\n",
    "# Tracer la variance cumulée\n",
    "plot(cumulative_variance, xlab = \"Nombre de composantes principales\", ylab = \"Variance cumulée\", type = \"b\")\n",
    "abline(h = 80, col = \"red\", lty = 2)  # Ligne horizontale à 80% de variance expliquée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :** \n",
    "\n",
    "L’analyse de la variance expliquée montre que les 7 premières composantes principales permettent de représenter 80,1 % de la variance totale du jeu de données. Cela signifie que l’essentiel de l’information contenue dans les 11 variables numériques initiales (comme danceability, energy, speechiness, tempo, etc.) peut être résumé avec seulement 7 dimensions, ce qui représente une réduction significative de la complexité du dataset tout en conservant une bonne qualité descriptive.\n",
    "\n",
    "Dans cette optique de réduction de dimension, il serait pertinent de conserver ces 7 composantes principales pour la suite des analyses (clustering, visualisation, classification), car elles capturent la structure principale des données tout en éliminant le \"bruit\".\n",
    "\n",
    "Dans l’analyse factorielle, nous avons choisi d’interpréter les trois premières composantes principales, qui à elles seules expliquent 45 % de la variance totale. Elles offrent un bon compromis entre lisibilité et pertinence pour une visualisation ou une première analyse des relations entre les variables et les genres musicaux (playlist_genre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Corrélation des variables\n",
    "corrplot(pca$var$cor, is.corr = FALSE, method = \"ellipse\")\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 1-2\n",
    "fviz_pca_var(pca, axes=c(1,2),col.var = \"contrib\", gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), repel = TRUE) +\n",
    "  labs(title = \"Variables sur le plan factoriel\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 1-3\n",
    "  fviz_pca_var(pca, axes = c(1, 3), col.var = \"contrib\", \n",
    "         gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n",
    "         repel = TRUE) +\n",
    "    labs(title = \"Variables sur le plan factoriel (Dim 1-3)\") +\n",
    "    theme_minimal()\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 2-3\n",
    "  fviz_pca_var(pca, axes = c(2, 3), col.var = \"contrib\", \n",
    "         gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n",
    "         repel = TRUE) +\n",
    "    labs(title = \"Variables sur le plan factoriel (Dim 2-3)\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table des correlations et les trois graphiques ci-dessus représentent les projections des features sur les trois premières composantes principales nous donne des informations sur la structure des données réduites.\n",
    "\n",
    "**Composante principale 1 :**\n",
    "    \n",
    "Les variables energy (-0.91), loudness (-0.80) et acousticness (+0.72) sont linéairement corrélées avec la première composante principale, en soulignant que energy et loudness sont inversément corrélées avec acousticness. Cela indique que la CP1 oppose les morceaux énergiques, forts en volume et peu acoustiques (ex : rock, électro) aux morceaux calmes, acoustiques et peu énergétiques (ex : folk, classique).\n",
    "\n",
    "**Composante principale 2 :**\n",
    "\n",
    "Sur le graphique de gauche, on remarque une opposition des variables instrumentalness (+0.45), duration_s (+0.38) contre danceability (-0.68), valence (-0.62), track_popularity (-0.37), speechiness (-0.39).\n",
    "\n",
    "Cette composante principale oppose deux profils de morceaux :\n",
    "    D’un côté, les morceaux instrumentaux, longs et peu populaires (forte contribution de instrumentalness et duration_s), souvent associés à des genres comme le classique ou le jazz.\n",
    "    De l’autre, les chansons courtes, dansantes, joyeuses et populaires (forte contribution de danceability, valence et track_popularity), typiques de la pop ou de la musique de club.\n",
    "    Enfin, cette opposition suggère que les morceaux avec des paroles marquées (speechiness) et une structure rythmique engageante (danceability) sont plus susceptibles de générer de la popularité.\n",
    "\n",
    "**Composantes principales 2 et 3 :**\n",
    "\n",
    "Sur le graphique au centre, on peut extraire plusieurs informations :\n",
    "    Les morceaux dansants et joyeux (haute valence) s'opposent dans une moindre mesure aux morceaux de faible tempo. De plus, ces morceaux semblent avoir peu de versions live.\n",
    "    On observe aussi que les morceaux instrumentaux et longs ont généralement une faible popularité, tandis que les morceaux courts et peu instrumentaux sont souvent plus populaires, ce qui est typique de la musique pop, qui est souvent plus accessible et commerciale.\n",
    "\n",
    "**Composante principale 3 :**\n",
    "\n",
    "La troisième composante (CP3) révèle un paradoxe : elle regroupe des morceaux à fort potentiel dansant (danceability) et mood positif (valence), mais qui restent peu populaires (track_popularity). Ces morceaux sont souvent instrumentaux (instrumentalness), longs (duration_s) et à tempo faible (tempo), ce qui les éloigne des standards des charts. Cette composante pourrait représenter des créations artistiques équilibrant danse et complexité, mais peinant à atteindre un large public.\n",
    "\n",
    "\n",
    "La troisième composante principale met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "Du côté des contributions négatives, on retrouve des titres de pop et R&B calmes et acoustiques comme raindrops (an angel cried) (Ariana Grande) ou You Are The Reason (Calum Scott). Ces chansons ont :\n",
    "\n",
    "    une acousticness élevée (acapela, guitare acoustique, piano),\n",
    "    un tempo légèrement plus rapide que la médiane des morceaux,\n",
    "    une faible énergie, mais un potentiel émotionnel fort (valence variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "Les contributions positives, quant à elles, sont largement dominées par des morceaux EDM ou latino instrumentaux, comme I Feel Love ou Chase. Ces morceaux sont :\n",
    "\n",
    "    longs,\n",
    "    très instrumentaux,\n",
    "    énergiques mais souvent moins \"accessibles\" émotionnellement (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la PC3 oppose des créations acoustiques à forte charge émotionnelle à des morceaux instrumentaux, électroniques, longs, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque le signe des contributions est inversé par rapport à l'analyse en composantes principales (ACP) réalisée sous Python.\n",
    "\n",
    "**Remarque:** on peut noter que les valeurs ne sont pas exactement les mêmes que sur le notebook Python. L'ACP sous R ne prend pas forcément la même base que sur Python, ce qui explique les valeurs parfois négatives ou positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux comprendre à quoi correspond les type morceaux extraits par ces composantes principales, nous allons regarder les morceaux (individus) contribuant le plus à chacune des composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 1\n",
    "dim1_coords <- pca$ind$coord[, 1]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices <- order(dim1_coords)[1:5]\n",
    "max_indices <- order(dim1_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals <- song[c(min_indices, max_indices), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals$Dim1_Value <- dim1_coords[c(min_indices, max_indices)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim1_Value au début\n",
    "col_order <- c(\"Category\", \"Dim1_Value\", colnames(extreme_individuals)[1:(ncol(extreme_individuals)-2)])\n",
    "extreme_individuals <- extreme_individuals[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n",
    "\n",
    "Pour mieux cerner les types de morceaux représentés aux extrémités de la première composante principale (PC1), nous avons identifié les individus (chansons) ayant les contributions les plus élevées, positives comme négatives.\n",
    "\n",
    "    Du côté des contributions positives, on retrouve majoritairement des morceaux rock, hard rock ou pop rock très énergiques et puissants tels que American Idiot (Green Day), Beauty Queen (BLVK SWVN) ou ATTENTION ATTENTION (Shinedown). Ces morceaux sont caractérisés par une énergie élevée, une forte intensité sonore (loudness) et une faible acoustique, ce qui confirme bien la structure mise en évidence par la CP1. Notons aussi This Is How We Do It (Montell Jordan), un morceau R&B énergique, qui se distingue des autres par son genre mais partage les mêmes caractéristiques acoustiques.\n",
    "\n",
    "    À l’opposé, les morceaux à contribution très négative sur PC1 sont des titres à forte acoustique, peu énergiques et très faibles en loudness. Il s'agit notamment de sons ambiants, relaxants ou naturels, comme Peaceful Forest ou Tropical Rainforest at Dawn, mais aussi de titres R&B ou indie très doux (Small de chloe moriondo). Ces morceaux incarnent l'autre extrémité de la CP1 : des chansons calmes, acoustiques et à faible énergie, souvent issues de sous-genres comme tropical, indie poptimism ou new jack swing.\n",
    "\n",
    "Cette opposition renforce l’interprétation de la CP1 comme un axe énergie / intensité sonore vs. calme / acoustique, pertinent pour distinguer deux grandes familles de styles musicaux dans le dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 2\n",
    "dim2_coords <- pca$ind$coord[, 2]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices_dim2 <- order(dim2_coords)[1:5]\n",
    "max_indices_dim2 <- order(dim2_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals_dim2 <- song[c(min_indices_dim2, max_indices_dim2), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals_dim2$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals_dim2$Dim2_Value <- dim2_coords[c(min_indices_dim2, max_indices_dim2)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim2_Value au début\n",
    "col_order <- c(\"Category\", \"Dim2_Value\", colnames(extreme_individuals_dim2)[1:(ncol(extreme_individuals_dim2)-2)])\n",
    "extreme_individuals_dim2 <- extreme_individuals_dim2[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals_dim2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n",
    "\n",
    "Côté contributions positives, on retrouve des titres principalement rap et latino, tels que Suge de DaBaby ou LAX de B0nds. Ces morceaux sont :\n",
    "\n",
    "    courts,\n",
    "    dansants (haute danceability),\n",
    "    avec une valence élevée (émotion positive),\n",
    "    mais également avec un certain niveau de speechiness, notamment pour les titres rap.\n",
    "\n",
    "Ces morceaux partagent donc des caractéristiques propres aux chansons énergétiques, rythmées et populaires, souvent taillées pour le streaming, avec des formats courts, accrocheurs et directs.\n",
    "\n",
    "À l’opposé, les morceaux ayant une forte contribution négative à PC2 sont très différents : on retrouve des paysages sonores naturels, ambiants ou instrumentaux comme Rain Forest and Tropical Beach Sound, Caribbean Thunderstorm, ou encore Battlement. Ces titres sont :\n",
    "\n",
    "    longs,\n",
    "    instrumentaux (forte instrumentalness),\n",
    "    avec une faible valence et peu de parole,\n",
    "    et souvent issus de sous-genres comme tropical, album rock, ou ambient.\n",
    "\n",
    "Cela confirme l’interprétation initiale de la PC2 comme un axe opposant la musique instrumentale, longue et contemplative à une musique populaire, dansante et rythmée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 3\n",
    "dim3_coords <- pca$ind$coord[, 3]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices_dim3 <- order(dim3_coords)[1:5]\n",
    "max_indices_dim3 <- order(dim3_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals_dim3 <- song[c(min_indices_dim3, max_indices_dim3), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals_dim3$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals_dim3$Dim3_Value <- dim3_coords[c(min_indices_dim3, max_indices_dim3)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim3_Value au début\n",
    "col_order <- c(\"Category\", \"Dim3_Value\", colnames(extreme_individuals_dim3)[1:(ncol(extreme_individuals_dim3)-2)])\n",
    "extreme_individuals_dim3 <- extreme_individuals_dim3[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals_dim3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "La troisième composante principale met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "Du côté des contributions négatives, on retrouve des titres de pop et R&B calmes et acoustiques comme raindrops (an angel cried) (Ariana Grande) ou You Are The Reason (Calum Scott). Ces chansons ont :\n",
    "\n",
    "    une acousticness élevée (acapela, guitare acoustique, piano),\n",
    "    un tempo légèrement plus rapide que la médiane des morceaux,\n",
    "    une faible énergie, mais un potentiel émotionnel fort (valence variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "Les contributions positives, quant à elles, sont largement dominées par des morceaux EDM ou latino instrumentaux, comme I Feel Love ou Chase. Ces morceaux sont :\n",
    "\n",
    "    longs,\n",
    "    très instrumentaux,\n",
    "    énergiques mais souvent moins \"accessibles\" émotionnellement (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la PC3 oppose des créations acoustiques à forte charge émotionnelle à des morceaux instrumentaux, électroniques, longs, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque le signe des contributions est inversé par rapport à l'analyse en composantes principales (ACP) réalisée sous Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Sélectionner les variables numériques pertinentes (similaire à l'ACP)\n",
    "numerical_features <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                               \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                               \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "\n",
    "# S'assurer qu'il n'y a pas de NA\n",
    "numerical_features <- na.omit(numerical_features)\n",
    "\n",
    "# Limiter à 2000 chansons pour éviter crash mémoire\n",
    "set.seed(42)\n",
    "if (nrow(numerical_features) > 2000) {\n",
    "  sample_idx <- sample(seq_len(nrow(numerical_features)), 2000)\n",
    "  numerical_features <- numerical_features[sample_idx, ]\n",
    "}\n",
    "\n",
    "# Standardiser\n",
    "scaled_numerical_features <- scale(numerical_features)\n",
    "dist_matrix <- dist(scaled_numerical_features)\n",
    "\n",
    "# MDS sans add=TRUE\n",
    "mds_result <- cmdscale(dist_matrix, k = 2, eig = TRUE)\n",
    "\n",
    "mds_points <- as.data.frame(mds_result$points)\n",
    "colnames(mds_points) <- c(\"Dim1\", \"Dim2\")\n",
    "\n",
    "# Récupérer le genre correspondant\n",
    "if (exists(\"sample_idx\")) {\n",
    "  temp_df_for_mds <- song[, c(\"playlist_genre\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                              \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                              \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "  temp_df_for_mds_clean <- na.omit(temp_df_for_mds)\n",
    "  temp_df_for_mds_clean <- temp_df_for_mds_clean[sample_idx, ]\n",
    "} else {\n",
    "  temp_df_for_mds <- song[, c(\"playlist_genre\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                              \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                              \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "  temp_df_for_mds_clean <- na.omit(temp_df_for_mds)\n",
    "}\n",
    "\n",
    "mds_points$playlist_genre <- temp_df_for_mds_clean$playlist_genre\n",
    "\n",
    "# Visualisation\n",
    "ggplot(mds_points, aes(x = Dim1, y = Dim2, color = playlist_genre)) +\n",
    "  geom_point(alpha = 0.7) +\n",
    "  labs(title = \"MDS des chansons (basé sur les caractéristiques audio)\",\n",
    "       x = \"Dimension MDS 1\",\n",
    "       y = \"Dimension MDS 2\",\n",
    "       color = \"Genre de Playlist\") +\n",
    "  theme_minimal() +\n",
    "  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))\n",
    "\n",
    "# Goodness-of-fit\n",
    "cat(\"\\nGoodness-of-fit (GOF):\\n\")\n",
    "print(mds_result$GOF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(Rtsne)\n",
    "library(ggplot2)\n",
    "\n",
    "# Supprimer les doublons\n",
    "scaled_numerical_features_unique <- unique(scaled_numerical_features)\n",
    "\n",
    "# Identifier les lignes uniques\n",
    "unique_rows <- !duplicated(scaled_numerical_features)\n",
    "\n",
    "# Conserver uniquement les genres correspondant aux lignes uniques\n",
    "playlist_genre_unique <- temp_df_for_mds_clean$playlist_genre[unique_rows]\n",
    "\n",
    "# Exécuter t-SNE\n",
    "set.seed(42)\n",
    "tsne_result <- Rtsne(scaled_numerical_features_unique, dims = 2, perplexity = 30, verbose = TRUE)\n",
    "\n",
    "# Préparer le dataframe pour ggplot\n",
    "tsne_df <- as.data.frame(tsne_result$Y)\n",
    "colnames(tsne_df) <- c(\"Dim1\", \"Dim2\")\n",
    "tsne_df$playlist_genre <- playlist_genre_unique\n",
    "\n",
    "# Visualisation\n",
    "ggplot(tsne_df, aes(x = Dim1, y = Dim2, color = playlist_genre)) +\n",
    "  geom_point(alpha = 0.6) +\n",
    "  labs(title = \"t-SNE des chansons (caractéristiques audio)\",\n",
    "       x = \"Dimension 1\", y = \"Dimension 2\",\n",
    "       color = \"Genre de Playlist\") +\n",
    "  theme_minimal() +\n",
    "  guides(color = guide_legend(override.aes = list(size = 4, alpha = 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Interprétation des méthodes de réduction de dimensionnalité\n",
    "\n",
    "### Interprétation du MDS\n",
    "\n",
    "Le graphique issu de la MDS montre une concentration importante des points au centre, avec un fort chevauchement entre les différents genres musicaux (`pop`, `rap`, `r&b`, `rock`, etc.). Il n'y a pas de séparation nette ou de regroupement clair visible sur les deux dimensions principales.\n",
    "\n",
    "Le **Goodness-of-Fit (GOF)** est d’environ **0.34**, ce qui signifie que seulement **34 %** de la structure initiale des distances est préservée dans cette projection bidimensionnelle. Ce score relativement faible traduit une **perte d'information importante**, ce qui rend la visualisation difficile à interpréter de manière fiable.\n",
    "\n",
    "Cela suggère que :\n",
    "\n",
    "- Les genres musicaux ne se distinguent pas clairement sur la base des distances euclidiennes entre leurs caractéristiques audio normalisées.\n",
    "- La MDS, étant une méthode **linéaire**, ne capture pas bien les relations **non linéaires** qui pourraient exister entre les chansons.\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation du t-SNE\n",
    "\n",
    "Le graphique t-SNE montre une plus grande dispersion des points, avec des zones où certains genres comme `edm` ou `rap` semblent former des **sous-groupes partiellement distincts**. Cependant, on observe encore un chevauchement significatif entre les genres.\n",
    "\n",
    "Contrairement à la MDS, le t-SNE est une méthode **non linéaire** qui vise à préserver les **voisinages locaux** plutôt que les distances globales. Cela lui permet de mieux mettre en évidence les structures locales, comme des groupes compacts, même si les distances globales ne sont pas interprétables.\n",
    "\n",
    "L’interprétation du t-SNE suggère que :\n",
    "\n",
    "- Il existe quelques **régions homogènes** selon certains genres, mais aucune **séparation franche** entre clusters de genres.\n",
    "- Les caractéristiques audio seules ne suffisent probablement pas à **discriminer clairement** les genres musicaux.\n",
    "- Le t-SNE offre une visualisation plus riche que la MDS, mais reste difficile à interpréter en l’absence de clusters bien définis.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion commune\n",
    "\n",
    "Les deux méthodes révèlent que les genres musicaux dans ce jeu de données **ne sont pas linéairement séparables** sur la base des caractéristiques audio fournies. Le chevauchement visuel suggère soit :\n",
    "\n",
    "- une **proximité réelle** entre les genres sur le plan acoustique,\n",
    "- soit un **manque de variabilité** ou de pertinence dans les variables utilisées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## 2. Réduction de dimension par Analyse en Correspondances Multiples (MCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en Correspondances Multiples (MCA)\n",
    "\n",
    "### Objectif\n",
    "L'Analyse en Correspondances Multiples (MCA) a été réalisée pour explorer les relations entre les variables qualitatives du dataset Spotify. Cette méthode permet de visualiser les associations entre les modalités des variables qualitatives et d'identifier des clusters ou des oppositions significatives.\n",
    "\n",
    "**1. Variables catégorielles à utiliser dans la MCA**\n",
    "Voici les variables qualitatives que l'on pourrait envisager d'utiliser pour la MCA sur le dataset Spotify :  \n",
    "- `track_artist`  \n",
    "- `track_album_name` (attention à trop de modalités rares, peut-être garder que les plus fréquentes ou ne pas inclure à cause du grand nombre d’artistes)  \n",
    "- `playlist_name`  \n",
    "- `playlist_genre`  \n",
    "- `playlist_subgenre`  \n",
    "- `key`  \n",
    "- `mode`  \n",
    "\n",
    "---\n",
    "\n",
    "**2. Questions que la MCA peut aider à explorer**\n",
    "\n",
    "**a) Quels sont les groupes/cluster de modalités similaires ?**\n",
    "- Est-ce que certains genres et sous-genres de playlists s’associent fréquemment ?  \n",
    "- Certains \"modes\" (majeur/minor) sont-ils plus fréquents dans certains genres ?  \n",
    "- Y a-t-il des clés (`key`) musicales qui sont typiques de certains genres ou playlists ?  \n",
    "\n",
    "La MCA permettra de représenter graphiquement (biplot) ces modalités et d’identifier des associations fortes.\n",
    "\n",
    "**b) Est-ce que certains artistes ou playlists ont un profil qualitatif particulier ?**\n",
    "- Par exemple, certains artistes seraient-ils associés à un genre et sous-genre spécifiques, ou à un mode particulier ?  \n",
    "- Y a-t-il des clusters d’artistes / playlists qui partagent des caractéristiques particulières (clé, mode, genre) ?\n",
    "\n",
    "**3. Comment interpréter la MCA ici**\n",
    "\n",
    "- **Axes factoriels** : Chaque axe correspond à une dimension qui résume des associations fortes entre modalités. Par exemple, un axe peut opposer les genres \"Rock\" à \"Pop\", ou des clés majeures à mineures.\n",
    "- **Modalités proches dans l’espace** : Modalités proches signifient qu’elles co-apparaissent souvent dans les observations (ex. certains genres + mode majeur).\n",
    "- **Observation** : Si tu represents les observations (chansons) dans l’espace MCA, celles proches partagent des profils catégoriels similaires.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Utilisations concrètes/academic use cases**\n",
    "\n",
    "- **Profil des genres musicaux** : Comprendre quels modes/clés/sous-genres caractérisent les genres populaires sur Spotify.  \n",
    "- **Segmentation qualitative des playlists** : Y a-t-il des types de playlists/musiques qui partagent des caractéristiques qualitatives communes ?  \n",
    "- **Analyse de diversité** : Mesurer dans quelle mesure certains artistes/genres sont hétérogènes ou homogènes quant à leurs caractéristiques catégorielles.  \n",
    "- **Préparation à une classification** : Par exemple, combiner le résultat de la PCA (variables numériques) avec la MCA (variables qualitatives) dans une analyse factorielle mixte ou pour enrichir un modèle prédictif.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Exemple de questions précises à poser**\n",
    "\n",
    "- Les genres musicaux sont-ils liés à certaines tonalités ou modes ?  \n",
    "- Les sous-genres présents dans la même playlist sont-ils proches ou éloignés dans l’espace MCA ?  \n",
    "- Y a-t-il des clés rares ou des modes minoritaires associés à certains genres uniquement ?  \n",
    "- Peut-on détecter des groupes de playlists ou artistes avec des profils qualitatifs similaires ?  \n",
    "\n",
    "---\n",
    "\n",
    "**En conclusion**\n",
    "La MCA t’aide surtout à **explorer et visualiser les relations entre variables qualitatives** et leurs modalités sur ton dataset Spotify, ce qui complète bien la PCA sur les variables numériques. C’est une étape utile pour comprendre la structure qualitative de tes données avant d’envisager une modélisation supervisée ou une analyse plus approfondie.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sélection de toutes les variables qualitatives pertinentes pour la MCA\n",
    "qual_vars <- c( 'playlist_genre', 'key', 'mode')\n",
    "song_mca_all <- song[, qual_vars]\n",
    "\n",
    "# Réalisation de la MCA avec FactoMineR\n",
    "mca_all <- MCA(song_mca_all, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_all, col.var = \"cos2\", \n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Toutes les variables qualitatives\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables utilisées\n",
    "Les variables qualitatives sélectionnées pour cette analyse sont :\n",
    "- `playlist_genre` : Genre de la playlist (ex. rock, pop, rap, etc.).\n",
    "- `key` : Tonalité musicale (ex. C, D, E♭, etc.).\n",
    "- `mode` : Mode musical (majeur ou mineur).\n",
    "\n",
    "### Résultats\n",
    "\n",
    "#### 1. Axes factoriels\n",
    "- **Dim1 (8%)** : Cet axe semble opposer des genres musicaux et des tonalités spécifiques :\n",
    "  - À droite, des genres comme `rap` et des tonalités comme `A♯/B♭` sont associés à des morceaux modernes ou spécifiques.\n",
    "  - À gauche, des tonalités comme `C` et `G` sont associées à des genres comme `rock`, suggérant une relation avec des styles plus classiques.\n",
    "- **Dim2 (6.6%)** : Cet axe reflète une distinction entre les modes (`major` et `minor`) et leur association avec certains genres :\n",
    "  - En haut, le mode `major` est associé à des genres comme `rock`.\n",
    "  - En bas, le mode `minor` est plus proche de genres comme `rap` et `edm`.\n",
    "\n",
    "#### 2. Proximité des modalités\n",
    "- Les modalités proches sur le graphique sont souvent associées dans les données :\n",
    "  - `pop`, `latin`, `r&b` et `edm` sont centrés par rapport aux modes `minor`et `major`, indiquant qu'ils n'appartiennent pas clairement à un mode spécifique, mais partagent des caractéristiques communes.\n",
    "  - `rap` est également centré par rapport à ces modes, ce qui suggère que l'utilisation des modes majeurs et mineurs est assez équilibrée dans la composition des morceaux de rap. Toutefois, il reste distinct des groupes `pop`, `latin`, `r&b` et `edm`.\n",
    "  - `rock` est plus proche de `major`, ce qui suggère que les musiques de ce genre sont souvent associées à des tonalités majeures.\n",
    "  - Les tonalités comme `B`,`D♯/E♭`,`A♯/B♭`,`F♯/G♭`et `F` sont proches de `minor`, indiquant qu'elles sont souvent utilisées dans des morceaux en mode mineur.\n",
    "  - Les tonalités comme `C`, `G`,`D` sont proches de `major`, ce qui suggère qu'elles sont souvent utilisées dans des morceaux en mode majeur.\n",
    "\n",
    "#### 3. Cos2 (Qualité de représentation)\n",
    "- Les couleurs des points indiquent la qualité de représentation des modalités sur les deux premières dimensions :\n",
    "  - Les modalités avec des couleurs chaudes (orange/rouge) comme `major` ou `minor` sont bien représentées sur ces axes.\n",
    "  - Les modalités avec des couleurs froides (bleu/vert) comme certaines tonalités (`C`, `G`) sont moins bien représentées, ce qui signifie qu'elles pourraient être mieux expliquées par d'autres dimensions.\n",
    "\n",
    "### Conclusion\n",
    "Cette MCA met en évidence des associations claires entre les genres musicaux, les tonalités (`key`), et les modes (`major`/`minor`). Elle permet de visualiser les relations qualitatives dans les données et d'identifier des clusters ou des oppositions significatives. Par exemple :\n",
    "- `rock` est distinct des autres genres, avec des tonalités et un mode spécifiques.\n",
    "- `pop`, `latin`, `r&b` et `edm` partagent des caractéristiques similaires, mais ne sont pas clairement associés à un mode particulier.\n",
    "- `rap` est centré par rapport aux modes, mais reste distinct des autres genres.\n",
    "\n",
    "Ces résultats offrent une meilleure compréhension des structures qualitatives des données et peuvent être utilisés pour des analyses complémentaires, comme la segmentation ou la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Identifier les top artists\n",
    "top_artists <- c(\"Eminem\", \"Green Day\", \"David Guetta\", \"Ed Sheeran\")\n",
    "\n",
    "# Créer une nouvelle variable track_artist_grouped avec \"other\" pour les artistes non sélectionnés\n",
    "song$track_artist_grouped <- as.character(song$track_artist)\n",
    "song$track_artist_grouped[!(song$track_artist %in% top_artists)] <- \"other\"\n",
    "song$track_artist_grouped <- as.factor(song$track_artist_grouped)\n",
    "\n",
    "# Filtrer le dataset pour ne garder que les morceaux des top artists ou \"other\"\n",
    "song_top_other <- song[song$track_artist_grouped %in% c(top_artists, \"other\"), ]\n",
    "\n",
    "# Sélection des variables qualitatives pour la MCA\n",
    "qual_vars_top_other <- c('track_artist_grouped', 'playlist_genre', 'key', 'mode')\n",
    "song_mca_top_other <- song_top_other[, qual_vars_top_other]\n",
    "\n",
    "# Réalisation de la MCA\n",
    "mca_top_other <- MCA(song_mca_top_other, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_top_other, col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Top 4 artistes vs autres + genre, key, mode\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Proximité des modalités\n",
    "- Les artistes proches sur le graphique partagent des caractéristiques similaires :\n",
    "  - `Ed Sheeran` est proche des tonalités `A` et `D`, ainsi que du mode `major`, ce qui reflète son style musical souvent associé à des tonalités classiques.\n",
    "  - `Green Day` est également associé au mode `major` et à des tonalités comme `C` et `D`, typiques de leur style rock.\n",
    "  - `David Guetta` est lié à des tonalités comme `F` et `D♯/E♭`, souvent utilisées dans la musique électronique.\n",
    "  - `Eminem` est associé au mode `minor` et à des tonalités comme `A♯/B♭`, caractéristiques de son style rap.\n",
    "\n",
    "#### 2. Clusters identifiés\n",
    "  - `rock` est fortement associé à `Green Day` et au mode `major`.\n",
    "  - `rap` est lié à `Eminem` et au mode `minor`.\n",
    "  - `Ed Sheeran` est proche du centre, indiquant un style musical équilibré entre tonalités et modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Création de classe de popularité de track_popularity en facteur Très Populaire, Popularité moyenne, Peu populaire\n",
    "song$track_popularity_class <- cut(song$track_popularity, \n",
    "                                   breaks = c(-1, 20, 50, 100), \n",
    "                                   labels = c(\"Peu populaire\", \"Popularité moyenne\", \"Très populaire\"),\n",
    "                                   include.lowest = TRUE)\n",
    "\n",
    "#MCA avec la classe de popularité et playlist_genre\n",
    "qual_vars_popularity <- c('track_popularity_class','playlist_genre')\n",
    "song_mca_popularity <- song[, qual_vars_popularity]\n",
    "mca_popularity <- MCA(song_mca_popularity, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_popularity, col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Classe de popularité + key, mode\") +\n",
    "  theme_minimal()\n",
    "\n",
    "#MCA avec la classe de popularité et key\n",
    "qual_vars_popularity <- c('track_popularity_class','key')\n",
    "song_mca_popularity <- song[, qual_vars_popularity]\n",
    "mca_popularity <- MCA(song_mca_popularity, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_popularity, col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Classe de popularité + key, mode\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(NMF)\n",
    "# 2. Sélection des colonnes audio uniquement depuis song\n",
    "audio_features <- song %>%\n",
    "  select(danceability, energy, loudness, speechiness, acousticness,\n",
    "         instrumentalness, liveness, valence, tempo, duration_s) %>%\n",
    "  na.omit()\n",
    "\n",
    "# 3. Min-max scaling sur chaque colonne\n",
    "audio_features <- as.data.frame(lapply(audio_features, function(x) (x - min(x)) / (max(x) - min(x))))\n",
    "\n",
    "# 4. Conversion en matrice\n",
    "audio_matrix <- as.matrix(audio_features)\n",
    "\n",
    "# 5. Choix du nombre de composantes (ex. : 4 profils)\n",
    "nmf_result <- nmf(audio_matrix, rank = 4, method = \"brunet\", nrun = 10, seed = 123)\n",
    "\n",
    "# 6. Résumé\n",
    "print(nmf_result)\n",
    "\n",
    "# 7. Matrice W (coefficients pour chaque chanson)\n",
    "W <- basis(nmf_result)\n",
    "\n",
    "# 8. Matrice H (contributions de chaque feature à chaque profil)\n",
    "H <- coef(nmf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Sélection des features audio\n",
    "audio_features <- c('danceability', 'energy', 'loudness', 'speechiness',\n",
    "                   'acousticness', 'instrumentalness', 'liveness',\n",
    "                   'valence', 'tempo', 'duration_s')\n",
    "\n",
    "X <- song[, audio_features]\n",
    "\n",
    "# 2. Normalisation min-max (important pour la NMF)\n",
    "X_scaled <- as.data.frame(lapply(X, function(x) (x - min(x)) / (max(x) - min(x))))\n",
    "X_matrix <- as.matrix(X_scaled)\n",
    "\n",
    "# 3. Tester plusieurs valeurs de r (nombre de composants)\n",
    "errors <- c()\n",
    "r_values <- seq(2, 10, by = 2)\n",
    "\n",
    "for (r in r_values) {\n",
    "  nmf_model <- nmf(X_matrix, rank = r, method = \"brunet\", nrun = 5, seed = 42)\n",
    "  W <- basis(nmf_model)\n",
    "  H <- coef(nmf_model)\n",
    "  reconstruction <- W %*% H\n",
    "  error <- norm(X_matrix - reconstruction, type = \"F\") # norme de Frobenius\n",
    "  errors <- c(errors, error)\n",
    "}\n",
    "\n",
    "# 4. Tracer la courbe de l’erreur de reconstruction\n",
    "plot(r_values, errors, type = \"b\", pch = 19,\n",
    "     main = \"Erreur de reconstruction vs nombre de composants (r)\",\n",
    "     xlab = \"Nombre de composants (r)\",\n",
    "     ylab = \"Erreur de reconstruction (norme de Frobenius)\")\n",
    "grid()\n",
    "\n",
    "#On garde r=6 pour la suite soit 6 profils musicaux\n",
    "\n",
    "# 5. Application de la NMF avec 6 composantes\n",
    "nmf_model_6 <- nmf(X_matrix, rank = 6, method = \"brunet\", nrun = 10, seed = 42)\n",
    "W_6 <- basis(nmf_model_6)\n",
    "H_6 <- coef(nmf_model_6)\n",
    "\n",
    "# 6. Créer un data.frame pour la matrice H\n",
    "H_df <- as.data.frame(H_6)\n",
    "colnames(H_df) <- audio_features\n",
    "rownames(H_df) <- paste0(\"Profil \", 1:6)\n",
    "\n",
    "# 7. Affichage de la matrice H\n",
    "print(\"Matrice H (profils latents définis par les variables audio) :\")\n",
    "\n",
    "# 8. Visualisation : contribution des variables à chaque profil (heatmap)\n",
    "library(reshape2)\n",
    "library(ggplot2)\n",
    "H_df_long <- melt(as.matrix(H_df))\n",
    "colnames(H_df_long) <- c(\"Profil\", \"Variable\", \"Valeur\")\n",
    "\n",
    "ggplot(H_df_long, aes(x = Variable, y = Profil, fill = Valeur)) +\n",
    "    geom_tile() +\n",
    "    geom_text(aes(label = sprintf(\"%.2f\", Valeur)), size = 3) +\n",
    "    scale_fill_gradient(low = \"#E7F6D5\", high = \"#2171B5\") +\n",
    "    labs(title = \"Profils latents musicaux détectés par NMF (matrice H)\",\n",
    "             x = \"Caractéristiques audio\", y = \"Profils NMF\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Profils latents détectés\n",
    "\n",
    "L’analyse a révélé **6 profils musicaux latents** à partir des données. Chaque profil est défini par une combinaison unique de caractéristiques audio. Voici leur interprétation :\n",
    "\n",
    "* **Profil 1 : Profil Instrumental**\n",
    "\n",
    "  * Très forte **`instrumentalness`** avec très peu d'autres caractéristiques.\n",
    "  * Correspond clairement à des morceaux **purement instrumentaux**, probablement **ambient**, **classique** ou **bande-son**.\n",
    "\n",
    "* **Profil 2 : Profil Énergique-Intense**\n",
    "\n",
    "  * Caractérisé par de **très fortes valeurs en `energy`, `loudness`, `tempo`, `duration` et `danceability`**.\n",
    "  * Faible en composantes émotionnelles (`valence`), vocales et instrumentales.\n",
    "  * Ce profil pourrait correspondre à des morceaux **très dynamiques et bruyants**, typiques de l’**EDM** (house, electro, techno) ou du **hard-rock**/**metal**.\n",
    "\n",
    "* **Profil 3 : Profil Live**\n",
    "\n",
    "  * Faibles valeurs générales sauf une **forte `liveness`**.\n",
    "  * Peut représenter des morceaux **live**.\n",
    "\n",
    "* **Profil 4 : Profil Émotionnel-Valence**\n",
    "\n",
    "  * Faible en toutes dimensions sauf une très forte **`valence`**.\n",
    "  * Ce profil regroupe des morceaux **émotionnellement très positifs**, avec une ambiance **joyeuse ou euphorique**, indépendamment du tempo ou de l’énergie.\n",
    "\n",
    "* **Profil 5 : Profil Acoustique-Chant**\n",
    "\n",
    "  * Dominé par une forte **`acousticness`**.\n",
    "  * Ce profil, présente **`instrumentalness`=0**, et un faible **`speechiness`** mais différent de zéro.\n",
    "  * Ce profil regroupe possiblement des morceaux **acoustiques et chantés**.\n",
    "\n",
    "* **Profil 6 : Profil Rap-Rythmé**\n",
    "\n",
    "  * Forte `danceability` et `speechiness`.\n",
    "  * Ce profil semble capturer des morceaux **rythmés et très vocaux**, typiques du **rap**, **hip-hop**, voire certains morceaux **R\\&B urbains**.\n",
    "\n",
    "---\n",
    "\n",
    "Pour chaque profil, nous allons désormais regarder les morceaux qui y contribuent le plus fortement, pour confirmer ces résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pour chaque profil (colonne de W), trouver les 2 morceaux avec la valeur la plus élevée\n",
    "top_indices_per_profile <- apply(W_6, 2, function(col) order(col, decreasing = TRUE)[1:2])\n",
    "\n",
    "# Afficher les morceaux correspondants pour chaque profil\n",
    "for (i in 1:ncol(W_6)) {\n",
    "    cat(sprintf(\"\\nProfil %d :\\n\", i))\n",
    "    indices <- top_indices_per_profile[, i]\n",
    "    print(song[indices, c(\"track_name\", \"track_artist\", \"playlist_genre\", \"playlist_subgenre\")])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Profils latents détectés\n",
    "\n",
    "L’analyse a révélé **6 profils musicaux latents** à partir des données. Chaque profil est défini par une combinaison unique de caractéristiques audio. Voici des exemples de morceaux représentés par les différents profils :\n",
    "\n",
    "* **Profil 1 : Profil Instrumental**\n",
    "  * Exemples : `Flowers` de **The Deli**, `Tropical Forest` de **The Sleep Specialist**.\n",
    "\n",
    "* **Profil 2 : Profil Énergique-Intense**\n",
    "  * Exemples : `Roar - Adana Twins Remix` de **Patrice Bäumel**, `Tolerance For The Absurd - Acronym Remix` de **Irazu**.\n",
    "\n",
    "* **Profil 3 : Profil Live**\n",
    "  * Exemples : `Bienvenidos - Live` de **Miguel Rios**, `Sweet Child O' Mine - Live In Paris / 1992` de **Guns N' Roses**.\n",
    "\n",
    "* **Profil 4 : Profil Émotionnel-Valence**\n",
    "  * Exemples : `You Love It!` de **ripmattblack**, `Nobody's Heart` de **Sergeant Jay**.\n",
    "\n",
    "* **Profil 5 : Profil Acoustique-Chant**\n",
    "  * Exemples : `Lost Boy` de **Ruth B.**.\n",
    "\n",
    "* **Profil 6 : Profil Rap-Rythmé**\n",
    "  * Exemples : `Suge` de **DaBaby**, `LAX` de **B0nds**.\n",
    "\n",
    "---\n",
    "\n",
    "Ces résultats confirment les interprétations initiales des profils latents, et montrent que la NMF a réussi à extraire des caractéristiques musicales pertinentes à partir des données audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Système de recommandation basé sur les profils NMF\n",
    "\n",
    "# 1. Ajouter les profils NMF comme colonnes au dataframe original\n",
    "song_with_profiles <- song\n",
    "song_with_profiles[, paste0(\"profile_\", 1:6)] <- W_6\n",
    "\n",
    "# 2. Fonction pour recommander des chansons basées sur une playlist\n",
    "recommend_songs <- function(playlist_name, num_recommendations = 3) {\n",
    "    # Vérifier si la playlist existe\n",
    "    if(!(playlist_name %in% song_with_profiles$playlist_name)) {\n",
    "        stop(\"Playlist non trouvée dans le dataset\")\n",
    "    }\n",
    "    \n",
    "    # Récupérer les morceaux de la playlist\n",
    "    playlist_songs <- song_with_profiles[song_with_profiles$playlist_name == playlist_name, ]\n",
    "    \n",
    "    # Calculer le profil moyen de la playlist\n",
    "    playlist_profile <- colMeans(playlist_songs[, paste0(\"profile_\", 1:6)])\n",
    "    \n",
    "    # Exclure les morceaux déjà dans la playlist\n",
    "    other_songs <- song_with_profiles[song_with_profiles$playlist_name != playlist_name, ]\n",
    "    \n",
    "    # Calculer la similarité (distance euclidienne) entre le profil de la playlist et chaque morceau\n",
    "    similarities <- apply(other_songs[, paste0(\"profile_\", 1:6)], 1, function(song_profile) {\n",
    "        -sqrt(sum((song_profile - playlist_profile)^2))  # Négative car nous voulons maximiser\n",
    "    })\n",
    "    \n",
    "    # Trier les morceaux par similarité décroissante\n",
    "    other_songs$similarity <- similarities\n",
    "    recommendations <- other_songs[order(other_songs$similarity, decreasing = TRUE), ]\n",
    "    \n",
    "    # Retourner les top N recommandations\n",
    "    return(head(recommendations[, c(\"track_name\", \"track_artist\", \"playlist_genre\", \"playlist_subgenre\", \"similarity\")], num_recommendations))\n",
    "}\n",
    "\n",
    "# 3. Exemple d'utilisation\n",
    "# Obtenir les noms de playlists uniques\n",
    "unique_playlists <- unique(song_with_profiles$playlist_name)\n",
    "\n",
    "# Sélectionner une playlist aléatoire pour démonstration\n",
    "set.seed(123)\n",
    "example_playlist <- sample(unique_playlists, 1)\n",
    "\n",
    "# Afficher le nom de la playlist sélectionnée\n",
    "cat(\"Playlist sélectionnée:\", as.character(example_playlist), \"\\n\\n\")\n",
    "\n",
    "# Afficher quelques chansons de la playlist sélectionnée\n",
    "playlist_sample <- song_with_profiles[song_with_profiles$playlist_name == example_playlist, \n",
    "                                                                     c(\"track_name\", \"track_artist\", \"playlist_genre\")]\n",
    "cat(\"Exemple de chansons dans cette playlist:\\n\")\n",
    "print(head(playlist_sample, 3))\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Obtenir les recommandations sous la forme d'un tableau sans les playlist_subgenre\n",
    "recommendations <- recommend_songs(example_playlist, num_recommendations = 3)\n",
    "cat(\"Recommandations de chansons basées sur la playlist sélectionnée:\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Fonction pour recommander à partir d'une chanson spécifique\n",
    "recommend_from_song <- function(track_name, track_artist, num_recommendations = 3) {\n",
    "    # Trouver la chanson dans le dataset\n",
    "    song_idx <- which(song_with_profiles$track_name == track_name & \n",
    "                                        song_with_profiles$track_artist == track_artist)\n",
    "    \n",
    "    if(length(song_idx) == 0) {\n",
    "        stop(\"Chanson non trouvée dans le dataset\")\n",
    "    }\n",
    "    \n",
    "    # Récupérer le profil de la chanson\n",
    "    song_profile <- as.numeric(song_with_profiles[song_idx[1], paste0(\"profile_\", 1:6)])\n",
    "    \n",
    "    # Exclure la chanson elle-même\n",
    "    other_songs <- song_with_profiles[-song_idx, ]\n",
    "    \n",
    "    # Calculer la similarité\n",
    "    similarities <- apply(other_songs[, paste0(\"profile_\", 1:6)], 1, function(profile) {\n",
    "        -sqrt(sum((profile - song_profile)^2))\n",
    "    })\n",
    "    \n",
    "    # Trier par similarité\n",
    "    other_songs$similarity <- similarities\n",
    "    recommendations <- other_songs[order(other_songs$similarity, decreasing = TRUE), ]\n",
    "    \n",
    "    # Retourner les top N recommandations\n",
    "    return(head(recommendations[, c(\"track_name\", \"track_artist\", \"playlist_genre\", \"playlist_subgenre\", \"similarity\")], num_recommendations))\n",
    "}\n",
    "\n",
    "# Exemple d'utilisation de la recommandation par chanson\n",
    "# Sélectionner une chanson aléatoire\n",
    "set.seed(24)\n",
    "random_song_idx <- sample(1:nrow(song_with_profiles), 1)\n",
    "example_song <- song_with_profiles[random_song_idx, ]\n",
    "\n",
    "cat(\"\\n\\nRecommandation basée sur une chanson spécifique\\n\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"Chanson sélectionnée :\\n\")\n",
    "cat(\"Nom de la chanson:\", example_song$track_name, \"\\n\")\n",
    "cat(\"Artiste:\", as.character(example_song$track_artist), \"\\n\")\n",
    "\n",
    "# Obtenir les recommandations\n",
    "song_recommendations <- recommend_from_song(example_song$track_name, example_song$track_artist, 5)\n",
    "cat(\"Chansons similaires recommandées:\\n\")\n",
    "print(song_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Recommandation pour la playlist \"Tropical Beats\"\n",
    "playlist_name <- \"Tropical Beats\"\n",
    "num_recommendations <- 5\n",
    "recommendations <- recommend_songs(playlist_name, num_recommendations)\n",
    "cat(\"Recommandations pour la playlist 'Tropical Beats':\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Recommandation pour la chanson \"Thunderstruck\" de \"AC/DC\"\n",
    "track_name <- \"Thunderstruck\"\n",
    "track_artist <- \"AC/DC\"\n",
    "num_recommendations <- 5\n",
    "recommendations <- recommend_from_song(track_name, track_artist, num_recommendations)\n",
    "cat(\"Recommandations pour la chanson 'Thunderstruck' de 'AC/DC':\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
