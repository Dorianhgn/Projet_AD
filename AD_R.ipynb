{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Contexte et objectifs\n",
    "\n",
    "Ce projet analyse un dataset Spotify contenant des caractéristiques audio de milliers de chansons provenant de différents genres musicaux. L'objectif principal est d'explorer la structure des données musicales à travers diverses techniques d'analyse multivariée et de réduction de dimension.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Le dataset comprend des variables quantitatives (danceability, energy, valence, tempo, etc.) et qualitatives (genre, artiste, tonalité, mode) permettant une analyse complète des profils musicaux. Après prétraitement, nous disposons de données sur les caractéristiques audio objectives et les métadonnées descriptives des morceaux.\n",
    "\n",
    "## Approche méthodologique\n",
    "\n",
    "Cette analyse combine plusieurs techniques complémentaires :\n",
    "- **Analyse en Composantes Principales (ACP)** pour explorer les relations entre variables quantitatives et réduire la dimensionnalité\n",
    "- **Analyse des Correspondances Multiples (MCA)** pour étudier les associations entre variables qualitatives (genres, tonalités, modes)\n",
    "- **Analyse Factorielle Multiple (MFA)** pour intégrer simultanément données quantitatives et qualitatives dans une analyse unifiée\n",
    "- **Techniques de réduction non-linéaire** (MDS, t-SNE) pour visualiser la structure complexe des données musicales\n",
    "- **Factorisation Matricielle Non-négative (NMF)** pour identifier des profils musicaux latents et développer un système de recommandation\n",
    "- **Algorithmes de clustering** pour segmenter les morceaux en groupes homogènes selon leurs caractéristiques audio\n",
    "\n",
    "L'objectif est de comprendre comment les caractéristiques musicales s'organisent, identifier des patterns et profils musicaux distincts, et développer des applications pratiques comme un système de recommandation personnalisé basé sur les profils latents découverts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "## Préparation et nettoyage des données\n",
    "\n",
    "Le préprocessing est une étape cruciale qui conditionne la qualité des analyses statistiques ultérieures. Pour ce dataset Spotify, plusieurs transformations sont nécessaires :\n",
    "\n",
    "### Objectifs du préprocessing\n",
    "\n",
    "- **Élimination des variables non pertinentes** : Suppression des identifiants techniques (`track_id`, `album_id`, `playlist_id`) qui n'apportent pas d'information analytique\n",
    "- **Gestion des valeurs manquantes** : Identification et traitement des données incomplètes pour éviter les biais dans les analyses\n",
    "- **Standardisation des types de données** : Conversion des variables catégorielles et temporelles dans les formats appropriés\n",
    "- **Déduplication intelligente** : Conservation des versions les plus populaires des morceaux dupliqués\n",
    "- **Harmonisation des unités** : Conversion de la durée en secondes pour une meilleure interprétabilité\n",
    "\n",
    "### Impact sur les analyses multivariées\n",
    "\n",
    "Un preprocessing rigoureux garantit :\n",
    "- Des résultats d'ACP non biaisés par des échelles de variables hétérogènes\n",
    "- Une MCA cohérente avec des modalités catégorielles bien définies\n",
    "- Des algorithmes de clustering et de réduction de dimension plus performants\n",
    "- Une meilleure généralisation des modèles de recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(gridExtra)\n",
    "library(GGally)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(reshape2)\n",
    "library(FactoMineR) \n",
    "library(factoextra)\n",
    "library(glmnet) \n",
    "library(ggfortify)\n",
    "library(pROC)\n",
    "library(ROCR)\n",
    "library(ggpubr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture des données\n",
    "path <- \"data/\"\n",
    "song <- read.csv(paste0(path, \"spotify_songs.csv\"), header = TRUE, sep = \",\")\n",
    "\n",
    "# Premières lignes du jeu de données\n",
    "head(song)\n",
    "\n",
    "# Vérification du contenu\n",
    "summary(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check the data types\n",
    "str(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the track_id, track_album_id, playlist_id columns\n",
    "song <- song[, -c(1, 5, 9)]\n",
    "\n",
    "# As factor the categorical variables track_artist, playlist_genre, playlist_subgenre, key, mode, playlist_name, track_album_name\n",
    "song$playlist_name <- as.factor(song$playlist_name)\n",
    "song$track_album_name <- as.factor(song$track_album_name)\n",
    "song$track_artist <- as.factor(song$track_artist)\n",
    "song$playlist_genre <- as.factor(song$playlist_genre)\n",
    "song$playlist_subgenre <- as.factor(song$playlist_subgenre)\n",
    "song$key <- factor(song$key, levels = c(-1, 0:11), labels = c(\"No key detected\", \"C\", \"C♯/D♭\", \"D\", \"D♯/E♭\", \"E\", \"F\", \"F♯/G♭\", \"G\", \"G♯/A♭\", \"A\", \"A♯/B♭\", \"B\"))\n",
    "song$mode <- factor(song$mode, levels = c(0, 1), labels = c(\"minor\", \"major\"))\n",
    "\n",
    "# track_album_release_date to date (if the full date is not available, we will use the first day of the year)\n",
    "song$track_album_release_date <- as.Date(ifelse(nchar(song$track_album_release_date) != 10, \n",
    "                                                paste0(substr(song$track_album_release_date, 1, 4), \"-01-01\"), \n",
    "                                                song$track_album_release_date), \n",
    "                                         format = \"%Y-%m-%d\")\n",
    "\n",
    "# Convert the duration_ms to seconds and rename the column to duration_s\n",
    "song$duration_s <- song$duration_ms / 1000\n",
    "song$duration_ms <- NULL\n",
    "\n",
    "# Check the modified dataset\n",
    "summary(song)\n",
    "head(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "colSums(is.na(song))\n",
    "\n",
    "# Drop the missing values\n",
    "song <- na.omit(song)\n",
    "\n",
    "# Check the modified dataset\n",
    "colSums(is.na(song))\n",
    "\n",
    "str(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicated data\n",
    "cat(sum(duplicated(song)),'\\n')\n",
    "\n",
    "# Check for duplicated song names with same artist\n",
    "cat(sum(duplicated(song[, c(\"track_name\", \"track_artist\")])), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# New data set by removing columns playlist_name, playlist_genre, playlist_subgenre\n",
    "onlysongs <- song[, -c(6, 7, 8)]\n",
    "\n",
    "# Check for duplicated data\n",
    "cat(sum(duplicated(onlysongs)), '\\n')\n",
    "\n",
    "# Drop duplicates\n",
    "onlysongs <- unique(onlysongs)\n",
    "\n",
    "# Print number of songs with same name and same artist\n",
    "cat(sum(duplicated(onlysongs[, c(\"track_name\", \"track_artist\")])), '\\n')\n",
    "\n",
    "# print rows with name \"Something real\"\n",
    "onlysongs[onlysongs$track_name == \"Something Real\", ]\n",
    "\n",
    "# Remove duplicates with the same name and artist, keeping only one with the highest popularity\n",
    "onlysongs <- onlysongs %>%\n",
    "    group_by(track_name, track_artist) %>%\n",
    "    filter(track_popularity == max(track_popularity)) %>%\n",
    "    slice(1) %>%  # If there are ties in popularity, keep just one\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce pré-processing de nos données, nous avons fait différents choix pour traiter nos données qui sont les suivantes :\n",
    "* Nous avons supprimé les lignes du jeu qui ne possédaient des valeurs manquantes (nom d'artiste, de morceau...), et nous avons constaté que uniquement **5 lignes** avaient des données non spécifiées. Nous avons donc fait le choix de les supprimer en supposant que cela n'aurait pas d'impact, étant donné la taille du jeu de données initial.\n",
    "* Nous avons également supprimé les colonnes qui représentaient les identifiants des artistes, playlists, morceaux...car nous avons décidé de ne pas se baser dessus sur notre étude car c'est une suite de lettres et de chiffres. \n",
    "* Nous avons effectué quelques modifications sur les variables, en transformant certaines variables numériques en variables catégoriques et certains format d'affichage. \n",
    "\n",
    "Nous avons finalement souhaité étudier notre jeu de données initial en considérant deux jeux. Ce sont les suivants :\n",
    "* Dans certains cas nous utilisons le **jeu de données initialement fourni** (avec les modification effectuées dessus).\n",
    "* Dans d'autres cas nous utilisons un **jeu de données qui ne se base pas sur les playlists** auxquels les morceaux sont associés. Cela a permis de ne pas considérer les morceaux présents dans plusieurs playlists (identiques ou différentes) afin de pouvoir considérer uniquement leurs caractéristiques. De plus, afin de supprimer les éventuels *doublons* présents, nous avons fait le choix de conserver le morceau ayant la plus haute popularité. En effet, certains artistes sortent des EP et ces mêmes EPs sont également présents dans des albums, mais n'ont pas la même popularité. Donc pour ne pas biaiser d'éventuelles analyses, ce choix a été fait. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse exploratoire\n",
    "## Analyse univariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(onlysongs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Affichage d'histogrammes représentant la distribution de la popularité des chansons, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_s, avec la possibilité de modifier la taille des titres et du texte des axes\n",
    "options(repr.plot.width=15, repr.plot.height=15)\n",
    "par(mfrow=c(4, 3))\n",
    "hist(onlysongs$track_popularity, main=\"Popularité des chansons\", xlab=\"Popularité\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$danceability, main=\"Danceability\", xlab=\"Danceability\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$energy, main=\"Energy\", xlab=\"Energy\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$loudness, main=\"Loudness\", xlab=\"Loudness\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$speechiness, main=\"Speechiness\", xlab=\"Speechiness\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$acousticness, main=\"Acousticness\", xlab=\"Acousticness\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$instrumentalness, main=\"Instrumentalness\", xlab=\"Instrumentalness\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$liveness, main=\"Liveness\", xlab=\"Liveness\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$valence, main=\"Valence\", xlab=\"Valence\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$tempo, main=\"Tempo\", xlab=\"Tempo\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "hist(onlysongs$duration_s, main=\"Durée des chansons\", xlab=\"Durée (s)\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\")\n",
    "\n",
    "# Pour tempo et durée, on augmente le nombre de classes (breaks) pour avoir plus de barres\n",
    "hist(onlysongs$tempo, main=\"Tempo\", xlab=\"Tempo\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\", breaks=40)\n",
    "hist(onlysongs$duration_s, main=\"Durée des chansons\", xlab=\"Durée (s)\", ylab=\"Nombre de chansons\", col=\"lightblue\", border=\"black\", breaks=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater que la majorité des caractéristiques représentées suivent une distribution qui semble normale.  \n",
    "\n",
    "Concernant la distribution de la **popularité**, il y a une grande fréquence de morceaux dont la popularité est nulle. Cela s'explique par les critères de notations de *Spotify*, qui note la popularité d'un morceau en fonction de ses écoutes, si elles ont été nombreuses ou encore récentes.  \n",
    "\n",
    "L'**acoustique** d'un morceau est noté entre 0.0 et 1.0. \n",
    "* 0.0 représente un morceau perçu comme non acoustique.\n",
    "* 1.0 représente à l'inverse un morceau acoustique.  \n",
    "  \n",
    "Grâce à la distribution, nous pouvons constater qu'une grande fréquence des morceaux présents dans ce jeu possèdent une acoustique nulle, cela peut déjà donner une première analyse sur le fait que le jeu de données est principalement composé de musiques de type *électronique* ou *synthétique*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=10)\n",
    "par(mfrow=c(2, 3))\n",
    "\n",
    "# Histogramme pour la variable 'mode'\n",
    "mode_counts <- table(onlysongs$mode)\n",
    "barplot(\n",
    "  mode_counts,\n",
    "  main = \"Distribution de la variable 'mode'\",\n",
    "  xlab = \"Mode\",\n",
    "  ylab = \"Fréquence\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\",\n",
    "  las = 1 # Labels horizontaux\n",
    ")\n",
    "\n",
    "# Histogramme pour la variable 'key'\n",
    "key_counts <- table(onlysongs$key)\n",
    "barplot(\n",
    "  key_counts,\n",
    "  main = \"Distribution de la variable 'key'\",\n",
    "  xlab = \"Key\",\n",
    "  ylab = \"Fréquence\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\",\n",
    "  las = 1 # Labels horizontaux\n",
    ")\n",
    "# Conversion de la variable 'track_album_release_date' en format Date\n",
    "onlysongs$track_album_release <- as.Date(onlysongs$track_album_release_date)\n",
    "\n",
    "# Extraction de l'année de sortie\n",
    "onlysongs$release_year <- format(onlysongs$track_album_release, \"%Y\")\n",
    "\n",
    "# Comptage des occurrences par année\n",
    "release_year_counts <- table(onlysongs$release_year)\n",
    "\n",
    "# Création de l'histogramme\n",
    "barplot(\n",
    "  release_year_counts,\n",
    "  main = \"Distribution des années de sortie des albums\",\n",
    "  xlab = \"Année de sortie\",\n",
    "  ylab = \"Nombre de morceaux\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\",\n",
    "  las = 2 # Rotation des labels pour les rendre lisibles\n",
    ")\n",
    "\n",
    "# Histogramme pour la variable 'playlist_genre'\n",
    "genre_counts <- table(song$playlist_genre)\n",
    "barplot(\n",
    "  genre_counts,\n",
    "  main = \"Distribution de la variable 'playlist_genre'\",\n",
    "  xlab = \"Genre de la playlist\",\n",
    "  ylab = \"Fréquence\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\",\n",
    "  las = 2 # Rotation des labels pour les rendre lisibles\n",
    ")\n",
    "\n",
    "# Histogramme pour la variable 'playlist_subgenre'\n",
    "subgenre_counts <- table(song$playlist_subgenre)\n",
    "barplot(\n",
    "  subgenre_counts,\n",
    "  main = \"Distribution de la variable 'playlist_subgenre'\",\n",
    "  xlab = \"Sous-genre de la playlist\",\n",
    "  ylab = \"Fréquence\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\",\n",
    "  las = 2 # Rotation des labels pour les rendre lisibles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concernant la distribution des variables qualitatives, on remarque qu'au niveau des modes de musique, il y a une plus forte présence de gammes majeures que de gammes mineures. Pour le choix de la clé, on peut voir que la clé `D#E` est beaucoup moins présente que les autres. Pour ce qui est du reste des clés, on peut considérer qu'il n'y a pas vraiment d'autres extrêmes de présence ou d'absence. Pour la distribution des dates de sortie, nous avons un très gros pic de sortie d'albums en 2019. \n",
    "Finalement, pour la ditribution des genres et sous-genres, elle est à peu près similaires pour tous les genres, même si certains sous-genres sont beaucoup moins présents. Cela est dû à une présence de sous-genres moins connus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Agrandis le texte des titres et des axes\n",
    "options(repr.plot.width=15, repr.plot.height=10)\n",
    "\n",
    "# Création des catégories pour la variable 'speechiness'\n",
    "onlysongs$speechiness_category <- cut(\n",
    "  onlysongs$speechiness,\n",
    "  breaks = c(0, 0.33, 0.66, 1),\n",
    "  labels = c(\"Music\", \"Speech and music\", \"Speech\"),\n",
    "  include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Comptage des occurrences dans chaque catégorie\n",
    "speechiness_counts <- table(onlysongs$speechiness_category)\n",
    "\n",
    "# Création de l'histogramme\n",
    "barplot(\n",
    "  speechiness_counts,\n",
    "  main = \"Distribution des catégories de 'speechiness'\",\n",
    "  xlab = \"Catégories de speechiness\",\n",
    "  ylab = \"Nombre de morceaux\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\"\n",
    ")\n",
    "\n",
    "# Création des catégories pour la variable 'instrumentalness'\n",
    "onlysongs$instrumentalness_category <- cut(\n",
    "  onlysongs$instrumentalness,\n",
    "  breaks = c(0, 0.5, 1),\n",
    "  labels = c(\"Vocal\", \"Instrumental\"),\n",
    "  include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Comptage des occurrences dans chaque catégorie\n",
    "instrumentalness_counts <- table(onlysongs$instrumentalness_category)\n",
    "\n",
    "# Création de l'histogramme\n",
    "barplot(\n",
    "  instrumentalness_counts,\n",
    "  main = \"Distribution des catégories de 'instrumentalness'\",\n",
    "  xlab = \"Catégories de instrumentalness\",\n",
    "  ylab = \"Nombre de morceaux\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\"\n",
    ")\n",
    "\n",
    "# Création des catégories pour la variable 'liveness'\n",
    "onlysongs$liveness_category <- cut(\n",
    "  onlysongs$liveness,\n",
    "  breaks = c(0, 0.8, 1),\n",
    "  labels = c(\"Studio\", \"Live\"),\n",
    "  include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Comptage des occurrences dans chaque catégorie\n",
    "liveness_counts <- table(onlysongs$liveness_category)\n",
    "\n",
    "# Création de l'histogramme\n",
    "barplot(\n",
    "  liveness_counts,\n",
    "  main = \"Distribution des catégories de 'liveness'\",\n",
    "  xlab = \"Catégories de liveness\",\n",
    "  ylab = \"Nombre de morceaux\",\n",
    "  col = \"lightblue\",\n",
    "  border = \"black\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables speechiness, instrumentalness et liveness, les intervalles dans lesquels les morceaux ont été classés, s'interprètent de la manière suivante : \n",
    "* **speechiness :** \n",
    "  * $<0.33$ : faible présence de paroles\n",
    "  * $[0.33,0.66]$ : présence modérée de paroles\n",
    "  * $>0.66$ : forte présence de paroles \n",
    "* **instrumentalness :** \n",
    "  * $\\le 0.5$ : peu ou pas instrumental\n",
    "  * $>0.5$ : très instrumental\n",
    "* **liveness :** \n",
    "  * $\\le 0.8$ : morceau probablement produit en studio\n",
    "  * $>0.8$ : morceau probablement produit en live (concert, public)\n",
    "\n",
    "D'après les distributions obtenues, la majorité des morceaux sont considérés comme possédant peu de paroles et qui n'ont pas été produits en live. Concernant l'instrumentalité des morceaux, nous pouvons constater que la majorité des morceaux sont instrumentaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse multivariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Affichage des colonnes de onlysongs\n",
    "colnames(onlysongs)\n",
    "\n",
    "# Affichage de la matrice de corrélation des colonnes popularity, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_s\n",
    "correlation_matrix <- cor(onlysongs[, c(\"track_popularity\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\")])\n",
    "corrplot(correlation_matrix, method = \"number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables semblent très peu corrélées entre elles pour la plupart, mais nous pouvons néanmoins constater les corrélations qui suivent.  \n",
    "- **Corrélation positive :** \n",
    "    - *loudness* et *energy* : corrélation forte (0.69). Cela semble cohérent, on lie le dynamisme d'un morceau au bruit ressenti.\n",
    "    - *valence* et *danceability* : légère corrélation (0.33). La valence mesure la positivité d'un morceau donc plus un morceau est positif, plus il est dansant.\n",
    "\n",
    "- **Corrélation négative :**\n",
    "    - *acousticness* et *energy* : corrélation négative modérée (-0.55). Plus une musique est perçue comme acoustique, moins elle est perçue comme énergique. Cela permet d'opposer des morceaux calmes à des morceaux dynamiques. \n",
    "    - *acousticness* et *loudness* : corrélation négative modérée (-0.38). Cela met en avant l'opposition entre un morceau bruyant et un morceau calme (acoustique).\n",
    "\n",
    "Pour le reste on a des corrélations assez faibles, qu'elles soient positives ou négatives. Cela ne nous permet pas de mettre en avant d'autres liens entre les variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Scatterplot pour visualiser la relation entre l'accousticness et l'energy\n",
    "ggplot(onlysongs, aes(x = acousticness, y = energy)) +\n",
    "  geom_point(aes(color = track_popularity), alpha = 0.5) +\n",
    "  scale_color_gradient(low = \"blue\", high = \"red\") +\n",
    "  labs(title = \"Relation entre l'acousticness et l'energy\",\n",
    "       x = \"Acousticness\",\n",
    "       y = \"Energy\",\n",
    "       color = \"Popularité\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Scatterplot pour visualiser la relation entre l'acousticness et la loudness\n",
    "ggplot(onlysongs, aes(x = acousticness, y = loudness)) +\n",
    "  geom_point(aes(color = track_popularity), alpha = 0.5) +\n",
    "  scale_color_gradient(low = \"blue\", high = \"red\") +\n",
    "  labs(title = \"Relation entre l'acousticness et la loudness\",\n",
    "       x = \"Acousticness\",\n",
    "       y = \"Loudness\",\n",
    "       color = \"Popularité\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Scatterplot pour visualiser la relation entre la loudness et l'energy\n",
    "ggplot(onlysongs, aes(x = loudness, y = energy)) +\n",
    "  geom_point(aes(color = track_popularity), alpha = 0.5) +\n",
    "  scale_color_gradient(low = \"blue\", high = \"red\") +\n",
    "  labs(title = \"Relation entre la loudness et l'energy\",\n",
    "       x = \"Loudness\",\n",
    "       y = \"Energy\",\n",
    "       color = \"Popularité\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#scatterplot pour visualiser la relation entre la danceability et valence\n",
    "ggplot(onlysongs, aes(x = danceability, y = valence)) +\n",
    "  geom_point(aes(color = track_popularity), alpha = 0.5) +\n",
    "  scale_color_gradient(low = \"blue\", high = \"red\") +\n",
    "  labs(title = \"Relation entre la danceability et la valence\",\n",
    "       x = \"Danceability\",\n",
    "       y = \"Valence\",\n",
    "       color = \"Popularité\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de vérifier ces corrélations, nous avons affiché les scatterplots les représentant.  \n",
    "\n",
    "Les deux premiers graphiques représentent bien la **corrélation négative**. En effet lorsqu'une des deux variables évolue, la seconde diminue. En effet, entre les variables **Acousticness** contre **Energy et Loudness**, cette opposition vient du fait que les musiques acoustiques sont plus calmes, en opposition aux musiques énergétiques et bruyantes.\n",
    "\n",
    "Pour les deux autres graphiques, à l'inverse nous remarquons bien des **corrélations positives**, en effet à mesure qu'une des deux variables augmente, la seconde aussi. Pour la **loudness et l'energy**, comme dit juste avant, une musique plus bruyante sera ressentie plus énergétique pour l'auditeur. Pour la **danceability et la valence**, une musique sur laquelle un auditeur voudra danser sera nécessairement plus joyeuse, ce qui est représenté par la valence.  \n",
    "\n",
    "Nous avons décidé d'effectuer l'affichage en fonction de la **popularité**, mais comme nous pouvous le voir, il y a des morceaux de différentes popularités qui sont placés aux mêmes endroits, nous pouvons donc penser que la popularité n'a aucune influence sur les variables représentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Histogrammes de la popularité des chansons par genre, un histogramme par genre, en utilisant les données \"song\"\n",
    "options(repr.plot.width=15, repr.plot.height=10)\n",
    "par(mfrow=c(3, 2))\n",
    "for (genre in levels(song$playlist_genre)) {\n",
    "  hist(song$track_popularity[song$playlist_genre == genre], \n",
    "       main = paste(\"Popularité des chansons dans le genre\", genre), \n",
    "       xlab = \"Popularité\", \n",
    "       ylab = \"Nombre de chansons\", \n",
    "       col = \"lightblue\", \n",
    "       border = \"black\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Histogrammes de la popularité des chansons par sous-genre, un histogramme par sous-genre, en utilisant les données \"song\"\n",
    "options(repr.plot.width=15, repr.plot.height=10)\n",
    "par(mfrow=c(3, 2))\n",
    "for (subgenre in levels(song$playlist_subgenre)) {\n",
    "  hist(song$track_popularity[song$playlist_subgenre == subgenre], \n",
    "       main = paste(\"Popularité des chansons dans le sous-genre\", subgenre), \n",
    "       xlab = \"Popularité\", \n",
    "       ylab = \"Nombre de chansons\", \n",
    "       col = \"lightblue\", \n",
    "       border = \"black\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la distribution des sous-genres, les distributions sont beaucoup plus hétérogènes. Effectivement, certains sous-genres étant moins présents que d'autres, la distribution de la popularité n'est pas la même que la distribution de la popularité globale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction de l'année de sortie\n",
    "onlysongs$release_year <- format(onlysongs$track_album_release_date, \"%Y\")\n",
    "\n",
    "# Calcul de la popularité moyenne par année de sortie\n",
    "average_popularity_by_year <- onlysongs %>%\n",
    "  group_by(release_year) %>%\n",
    "  summarise(mean_popularity = mean(track_popularity, na.rm = TRUE))\n",
    "\n",
    "# Création du graphique\n",
    "ggplot(average_popularity_by_year, aes(x = as.numeric(release_year), y = mean_popularity)) +\n",
    "  geom_line(color = \"blue\") +\n",
    "  geom_point(color = \"red\") +\n",
    "  labs(title = \"Popularité moyenne des musiques par année de sortie\",\n",
    "       x = \"Année de sortie\",\n",
    "       y = \"Popularité moyenne\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'une variable décennie à partir de l'année de sortie\n",
    "onlysongs$decade <- paste0(substr(onlysongs$release_year, 1, 3), \"0s\")\n",
    "\n",
    "# Calcul de la popularité moyenne par décennie\n",
    "average_popularity_by_decade <- onlysongs %>%\n",
    "    group_by(decade) %>%\n",
    "    summarise(mean_popularity = mean(track_popularity, na.rm = TRUE))\n",
    "\n",
    "# Tracé du graphique de popularité moyenne par décennie avec une courbe\n",
    "ggplot(average_popularity_by_decade, aes(x = decade, y = mean_popularity, group = 1)) +\n",
    "    geom_line(color = \"blue\", size = 1.2) +\n",
    "    geom_point(color = \"red\", size = 3) +\n",
    "    labs(title = \"Popularité moyenne des musiques par décennie\",\n",
    "            x = \"Décennie\",\n",
    "            y = \"Popularité moyenne\") +\n",
    "    theme_minimal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Comptage du nombre de morceaux par décennie\n",
    "decade_counts <- onlysongs %>%\n",
    "    group_by(decade) %>%\n",
    "    summarise(\n",
    "        n_morceaux = n(),\n",
    "        pct_pop0 = mean(track_popularity == 0) * 100,\n",
    "        pct_pop_note = mean(track_popularity > 0) * 100,\n",
    "        sd_popularity = sd(track_popularity)\n",
    "    ) %>%\n",
    "    arrange(decade)\n",
    "\n",
    "# Affichage du tableau\n",
    "print(decade_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Par année :**\n",
    "- Sur le premier graphe on peut lire la popularité moyenne des morceaux par année. Cela reste difficilement interprétable car il y a beaucoup de variations. \n",
    "- Nous pouvons néanmoins constater qu'avant 1960 il y a une tendance de popularité haute, mais qu'après ça oscille entre 30 et 50/60. \n",
    "- La moyenne de popularité totale est de 40.45.  \n",
    "\n",
    "Pour une interprétation plus globale nous avons regardé la popularité des morceaux en les regroupant par décennie de parution.\n",
    "\n",
    "**Par décennie :**\n",
    "  - On a une tendance de popularité très haute pour les musiques sorties entre 1950-1980. Cela peut s'expliquer notamment pour les musiques sorties entre 1950-60 : \n",
    "      - Peu de musiques sorties pendant ces années sont présentes dans le jeu de données.\n",
    "      - Il y a une moins grande diversité dans les notes comme il y a moins de musiques. Donc si celles-ci sont très bien notées alors ces années auront nécessairement une moyenne de popularité élevée.\n",
    "      - Si nous croisons ces résultats à l'écart-type associé qui est élevé, nous pouvons conclure que par le faible nombre de morceaux, cette décennie n'est pas représentative. Les décennies suivantes sont plus stables. \n",
    "  - Le minimum des moyennes de popularité par décennie est atteint pour les musiques des années 2000 :\n",
    "      - Cela peut s'expliquer par le nombre de morceaux qui n'ont pas de note de popularité, avec presque 19% des morceaux qui ont une note de 0. \n",
    "      - Donc soit ces morceaux n'ont été que très peu écoutés, soit les morceaux n'ont pas connu de succès, augmentant l'écart-type par rapport aux années précédentes. \n",
    "  - À l'inverse, dès 2020, la dispersion est plus faible avec peu de morceaux non notés, mais un nombre de morceaux assez faible, donc les morceaux ont une popularité en moyenne assez similaire avec moins de morceaux à succès et non succès extrêmes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Comptage du nombre de musiques par genre et par année\n",
    "songs_by_genre_year <- song %>%\n",
    "    group_by(release_year = format(track_album_release_date, \"%Y\"), playlist_genre) %>%\n",
    "    summarise(count = n(), .groups = \"drop\")\n",
    "\n",
    "# Création du graphique\n",
    "    ggplot(songs_by_genre_year, aes(x = as.numeric(release_year), y = count, color = playlist_genre)) +\n",
    "        geom_line() +\n",
    "        labs(title = \"Nombre de musiques sorties par genre et par année\",\n",
    "             x = \"Année de sortie\",\n",
    "             y = \"Nombre de morceaux\",\n",
    "             color = \"Genre\") +\n",
    "        theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons observé les années de sortie en fonction du genre de musique. On remarque que le **rock** est le style qui était le plus présent entre les **années 1970 jusqu'à 1990**. Ensuite, les autres styles se sont développés très rapidement, notamment avec le style **EDM* qui est le plus présent dans les années **2010 à 2020**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul du nombre de playlists différentes par genre\n",
    "playlists_per_genre <- song %>%\n",
    "    group_by(playlist_genre) %>%\n",
    "    summarise(n_playlists = n_distinct(playlist_name))\n",
    "\n",
    "# Affichage du résultat\n",
    "print(playlists_per_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons effectué une rapide analyse univariée sur les genres et les sous-genres des playlists, donc sur le jeu de donné fourni initialement.   \n",
    "\n",
    "Nous pouvons remarquer que le nombre de playlists par genre est plutôt équilibré avec en moyenne 76 playlists par genres. Néanmoins, on peut constater que le genre **EDM** est majoritairement présent dans le jeu de données, et que le genre **rock** est celui qui est minoritaire. Le reste des genres se différencie uniquement par quelques centaines de morceaux.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Liste des variables numériques à tracer\n",
    "numeric_vars <- c(\"track_popularity\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                  \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\")\n",
    "\n",
    "# Affichage des courbes de densité pour chaque variable numérique selon le genre\n",
    "library(ggplot2)\n",
    "library(tidyr)\n",
    "\n",
    "# Passage au format long pour ggplot2\n",
    "song_long <- song %>%\n",
    "  pivot_longer(cols = all_of(numeric_vars), names_to = \"variable\", values_to = \"value\")\n",
    "\n",
    "# Tracé des courbes de densité pour chaque variable, colorées par genre\n",
    "ggplot(song_long, aes(x = value, color = playlist_genre, fill = playlist_genre)) +\n",
    "  geom_density(alpha = 0.2) +\n",
    "  facet_wrap(~ variable, scales = \"free\", ncol = 3) +\n",
    "  labs(title = \"Distribution des variables numériques selon le genre de musique\",\n",
    "       x = \"Valeur\", y = \"Densité\", color = \"Genre\", fill = \"Genre\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'essayer de comprendre les spécificités des morceaux présents dans le jeu de données, nous avons analysé les différentes **distributions des variables quantitatives** selon le genre des playlists. L'objectif est d'identifier ici les différences pouvant caractériser les genres musicaux. Ces courbes de densité permettent de visualiser où se concentrent la majorité des morceaux.  \n",
    "\n",
    "<u>*Analyse des distributions et des genres :*</u>\n",
    "\n",
    "* **Danceability :**\n",
    "  * Le genre **latin** et le **rap** se distinguent particulièrement avec des valeurs de danceability proche de 0.8, indiquant des morceaux très dansants pour ces genres. \n",
    "  * À l'inverse, le genre **rock** est plus dispersé, indiquant que certains morceaux sont très dansants, d'autres pas du tout.\n",
    "  \n",
    "* **EDM**\n",
    "  * Ce genre semble se distinguer sur plusieurs points, en effet d'après les distributions, les morceaux du type EDM auront tendance à donner un ressenti **dynamique (energy)** (densité autour de 0.9), **bruyant** et se dinstingue par son **tempo** se trouvant autour de 130 BPM, valeur caractérisant généralement les morceaux d'EDM, techno...\n",
    "  * Néanmoins, les musiques de ce genre musical ne semblent pas être ressenties comme positives ou joyeuses d'après leur valence.\n",
    "  * Et on retrouve bien la corrélation négative avec l'**acousticness**.\n",
    "  \n",
    "* **Popularity :**\n",
    "  * Si l'on ne prend en compte le pic à 0 (qui concerne les morceaux non notés), mais seulement au second pic, on peut remarquer :\n",
    "    * **EDM** semble être le genre le moins populaire, mais la présence de la queue de distribution vers les valeurs élevées peut traduire la présence de morceaux à succès. \n",
    "    * Le **rap** possède une popularité plutôt moyenne par rapport aux autres genres, et ne semble pas avoir beaucoup de morceaux ayant connu un grand succès, mais l'inverse est aussi vrai, il ne semble pas y avoir beaucoup de morceaux à faible audience.\n",
    "    * La **pop** et **latin** sont les genres les plus populaires.\n",
    "\n",
    "* **Energy :**\n",
    "  * L'**EDM** est le genre le plus dynamique. \n",
    "  * La distribution plus large pour les genres comme **r&b**, **rap** ou encore **latin** aura plutôt tendance à indiquer que ces genres regroupent à la fois des morceaux calmes et énergiques.\n",
    "\n",
    "* **Valence :**\n",
    "  * Le genre **latin** se distingue particulièrement par sa valence élevée, traduisant des musiques plutôt joyeuses.\n",
    "  * La distribution globale de la valence est large (tous genres confondus) traduisant une grande diversité émotionnelle produite par les morceaux des différents genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des moyennes par genre pour chaque variable\n",
    "average_values_by_genre <- song %>%\n",
    "    group_by(playlist_genre) %>%\n",
    "    summarise(\n",
    "        danceability = mean(danceability, na.rm = TRUE),\n",
    "        energy = mean(energy, na.rm = TRUE),\n",
    "        loudness = mean(loudness, na.rm = TRUE),\n",
    "        mode = mean(as.numeric(mode), na.rm = TRUE),\n",
    "        speechiness = mean(speechiness, na.rm = TRUE),\n",
    "        acousticness = mean(acousticness, na.rm = TRUE),\n",
    "        instrumentalness = mean(instrumentalness, na.rm = TRUE),\n",
    "        liveness = mean(liveness, na.rm = TRUE),\n",
    "        valence = mean(valence, na.rm = TRUE),\n",
    "        tempo = mean(tempo, na.rm = TRUE),\n",
    "        duration_ms = mean(duration_s * 1000, na.rm = TRUE)\n",
    "    )\n",
    "\n",
    "# Affichage du tableau\n",
    "print(average_values_by_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données révèlent que les genres **EDM et Latin** se caractérisent par une énergie élevée et une forte propension à être dansant, ce qui les rend adaptés à des contextes festifs. La **pop** présente un équilibre entre **énergie** et **dansabilité**, tandis que le **R&B** et le **rap** mettent davantage l'accent sur les éléments parlés, avec une **énergie** modérée. Le **rock**, bien qu'énergique, est moins orienté vers la danse. Enfin, l'**EDM** est le genre le plus électronique, tandis que le **R&B** se distingue par son caractère plus acoustique. Ces caractéristiques reflètent les traits distinctifs propres à chaque genre musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Diagramme en barres empliées de la variable \"Key\" en fonction du genre de la musique\n",
    "ggplot(song, aes(x = playlist_genre, fill = key)) +\n",
    "  geom_bar(position = \"fill\") +\n",
    "  labs(title = \"Répartition de la variable 'Key' par genre de musique\",\n",
    "       x = \"Genre de musique\",\n",
    "       y = \"Proportion\",\n",
    "       fill = \"Key\") +\n",
    "  theme_minimal() +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette distribution des clés par genre, nous ne remarquons pas de clés spécifiques à certains genres. Certaines clés sont plus présentes que d'autres dans les genres, mais rien de très significatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Diagramme en barre empillés de la variable \"Mode\" en fonction du genre de la musique\n",
    "ggplot(song, aes(x = playlist_genre, fill = mode)) +\n",
    "  geom_bar(position = \"fill\") +\n",
    "  labs(title = \"Répartition de la variable 'Mode' par genre de musique\",\n",
    "       x = \"Genre de musique\",\n",
    "       y = \"Proportion\",\n",
    "       fill = \"Mode\") +\n",
    "  theme_minimal() +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les modes en revanche, on voit que pour le **rock**, nous avons une tendance à avoir un mode plutôt **majeur**. Pour les autres styles de musiques, la répartition du mode est relativement équilibré, à 50-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculer le nombre de playlists différentes dans lesquelles chaque chanson apparaît\n",
    "playlist_count <- song %>%\n",
    "    group_by(track_name, track_artist) %>%\n",
    "    summarise(n_playlists = n_distinct(playlist_name),\n",
    "                        track_popularity = max(track_popularity)) %>%\n",
    "    ungroup()\n",
    "\n",
    "# Calcul de la corrélation entre le nombre de playlists et la popularité\n",
    "correlation <- cor(playlist_count$n_playlists, playlist_count$track_popularity)\n",
    "\n",
    "# Affichage du résultat\n",
    "cat(\"Corrélation entre le nombre de playlists et la popularité :\", correlation, \"\\n\")\n",
    "\n",
    "# Visualisation\n",
    "ggplot(playlist_count, aes(x = n_playlists, y = track_popularity)) +\n",
    "    geom_point(alpha = 1, color = \"blue\", size = 4) +\n",
    "    labs(title = \"Corrélation entre le nombre de playlists et la popularité\",\n",
    "             x = \"Nombre de playlists\",\n",
    "             y = \"Popularité de la chanson\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, nous avons décidé de regarder s'il y avait un lien entre la popularité d'une musique et le nombre de fois où elle est présente dans une playlist. On remarque que les musiques qui sont présentes dans beaucoup de playlists ont tendance à avoir une popularité élevée. En revanche, l'inverse n'est pas forcément vraie. En effet, des musiques avec une popularité élevée ($>80$) peuvent être présentes dans une unique playlist. Ce critère n'est donc pas forcément représentatif de la popularité d'une musique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réduction de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons effectuer une analyse en composantes principales (ACP) sur les données prétraitées. L'ACP est une technique de réduction de dimension qui permet de projeter les données d'origine dans un espace de dimension inférieure. Nous avons gardé 20 variables et nous allons étudier s'il est possible de réduire la dimensionnalité de ces données tout en préservant un maximum d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en Composantes Principales (ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on ne sélectionne que les variables quantitatives, en y ajoutant une variable qualitative (playlist_genre) pour voir si elle a un impact sur la projection des données. On garde au final 11 variables quantitatives et 1 variable qualitative.\n",
    "\n",
    "On décide de normaliser les données avant de faire l'ACP car l'ACP est sensible à l'échelle des variables. On va donc centrer et réduire les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# PCA analysis using FactoMineR\n",
    "song_pca <- song[, c(3, 7, 9:10, 12, 14:20)]\n",
    "\n",
    "# Perform PCA\n",
    "pca <- PCA(song_pca,scale.unit = TRUE, graph = FALSE,ncp = 7,quali.sup = 2)\n",
    "\n",
    "# Afficher le pourcentage de variance expliquée par chaque composante principale\n",
    "fviz_eig(pca, addlabels = TRUE, ylim = c(0, 40))\n",
    "\n",
    "# Calculer la variance cumulée\n",
    "explained_variance <- pca$eig[, 2]  # La deuxième colonne contient le pourcentage de variance expliquée\n",
    "cumulative_variance <- cumsum(explained_variance) \n",
    "\n",
    "# Tracer la variance cumulée\n",
    "plot(cumulative_variance, xlab = \"Nombre de composantes principales\", ylab = \"Variance cumulée\", type = \"b\")\n",
    "abline(h = 80, col = \"red\", lty = 2)  # Ligne horizontale à 80% de variance expliquée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :** \n",
    "\n",
    "L’analyse de la variance expliquée montre que les 7 premières composantes principales permettent de représenter 80,1 % de la variance totale du jeu de données. Cela signifie que l’essentiel de l’information contenue dans les 11 variables numériques initiales (comme danceability, energy, speechiness, tempo, etc.) peut être résumé avec seulement 7 dimensions, ce qui représente une réduction significative de la complexité du dataset tout en conservant une bonne qualité descriptive.\n",
    "\n",
    "Dans cette optique de réduction de dimension, il serait pertinent de conserver ces 7 composantes principales pour la suite des analyses (clustering, visualisation, classification), car elles capturent la structure principale des données tout en éliminant le \"bruit\".\n",
    "\n",
    "Dans l’analyse factorielle, nous avons choisi d’interpréter les trois premières composantes principales, qui à elles seules expliquent 45 % de la variance totale. Elles offrent un bon compromis entre lisibilité et pertinence pour une visualisation ou une première analyse des relations entre les variables et les genres musicaux (playlist_genre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Corrélation des variables\n",
    "corrplot(pca$var$cor, is.corr = FALSE, method = \"ellipse\")\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 1-2\n",
    "fviz_pca_var(pca, axes=c(1,2),col.var = \"contrib\", gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), repel = TRUE) +\n",
    "  labs(title = \"Variables sur le plan factoriel\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 1-3\n",
    "  fviz_pca_var(pca, axes = c(1, 3), col.var = \"contrib\", \n",
    "         gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n",
    "         repel = TRUE) +\n",
    "    labs(title = \"Variables sur le plan factoriel (Dim 1-3)\") +\n",
    "    theme_minimal()\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 2-3\n",
    "  fviz_pca_var(pca, axes = c(2, 3), col.var = \"contrib\", \n",
    "         gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n",
    "         repel = TRUE) +\n",
    "    labs(title = \"Variables sur le plan factoriel (Dim 2-3)\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table des correlations et les trois graphiques ci-dessus représentent les projections des features sur les trois premières composantes principales nous donne des informations sur la structure des données réduites.\n",
    "\n",
    "**Composante principale 1 :**\n",
    "    \n",
    "Les variables **energy** (-0.91), **loudness** (-0.80) et **acousticness** (+0.72) sont linéairement corrélées avec la première composante principale, en soulignant que energy et loudness sont inversément corrélées avec acousticness. Cela indique que la CP1 oppose les morceaux énergiques, forts en volume et peu acoustiques (ex : rock, électro) aux morceaux calmes, acoustiques et peu énergétiques (ex : folk, classique).\n",
    "\n",
    "**Composante principale 2 :**\n",
    "\n",
    "Sur le graphique de gauche, on remarque une opposition des variables **instrumentalness** (+0.45), **duration_s** (+0.38) contre **danceability** (-0.68), **valence** (-0.62), **track_popularity** (-0.37), **speechiness** (-0.39).\n",
    "\n",
    "Cette composante principale oppose deux profils de morceaux :\n",
    "    D’un côté, les morceaux instrumentaux, longs et peu populaires (forte contribution de instrumentalness et duration_s), souvent associés à des genres comme le classique ou le jazz.\n",
    "    De l’autre, les chansons courtes, dansantes, joyeuses et populaires (forte contribution de danceability, valence et track_popularity), typiques de la pop ou de la musique de club.\n",
    "    Enfin, cette opposition suggère que les morceaux avec des paroles marquées (speechiness) et une structure rythmique engageante (danceability) sont plus susceptibles de générer de la popularité.\n",
    "\n",
    "**Composantes principales 2 et 3 :**\n",
    "\n",
    "Sur le graphique au centre, on peut extraire plusieurs informations :\n",
    "    Les morceaux dansants et joyeux (haute valence) s'opposent dans une moindre mesure aux morceaux de faible tempo. De plus, ces morceaux semblent avoir peu de versions live.\n",
    "    On observe aussi que les morceaux instrumentaux et longs ont généralement une faible popularité, tandis que les morceaux courts et peu instrumentaux sont souvent plus populaires, ce qui est typique de la musique pop, qui est souvent plus accessible et commerciale.\n",
    "\n",
    "**Composante principale 3 :**\n",
    "\n",
    "La troisième composante (CP3) révèle un paradoxe : elle regroupe des morceaux à fort potentiel dansant (danceability) et mood positif (valence), mais qui restent peu populaires (track_popularity). Ces morceaux sont souvent instrumentaux (instrumentalness), longs (duration_s) et à tempo faible (tempo), ce qui les éloigne des standards des charts. Cette composante pourrait représenter des créations artistiques équilibrant danse et complexité, mais peinant à atteindre un large public.\n",
    "\n",
    "\n",
    "La troisième composante principale met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "Du côté des contributions négatives, on retrouve des titres de pop et R&B calmes et acoustiques comme raindrops (an angel cried) (Ariana Grande) ou You Are The Reason (Calum Scott). Ces chansons ont :\n",
    "\n",
    "    une acousticness élevée (acapela, guitare acoustique, piano),\n",
    "    un tempo légèrement plus rapide que la médiane des morceaux,\n",
    "    une faible énergie, mais un potentiel émotionnel fort (valence variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "Les contributions positives, quant à elles, sont largement dominées par des morceaux EDM ou latino instrumentaux, comme I Feel Love ou Chase. Ces morceaux sont :\n",
    "\n",
    "    longs,\n",
    "    très instrumentaux,\n",
    "    énergiques mais souvent moins \"accessibles\" émotionnellement (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la PC3 oppose des créations acoustiques à forte charge émotionnelle à des morceaux instrumentaux, électroniques, longs, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque le signe des contributions est inversé par rapport à l'analyse en composantes principales (ACP) réalisée sous Python.\n",
    "\n",
    "**Remarque:** on peut noter que les valeurs ne sont pas exactement les mêmes que sur le notebook Python. L'ACP sous R ne prend pas forcément la même base que sur Python, ce qui explique les valeurs parfois négatives ou positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux comprendre à quoi correspond les composantes, nous allons regarder les morceaux (individus) contribuant le plus à chacune des composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 1\n",
    "dim1_coords <- pca$ind$coord[, 1]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices <- order(dim1_coords)[1:5]\n",
    "max_indices <- order(dim1_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals <- song[c(min_indices, max_indices), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals$Dim1_Value <- dim1_coords[c(min_indices, max_indices)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim1_Value au début\n",
    "col_order <- c(\"Category\", \"Dim1_Value\", colnames(extreme_individuals)[1:(ncol(extreme_individuals)-2)])\n",
    "extreme_individuals <- extreme_individuals[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n",
    "\n",
    "Pour mieux cerner les types de morceaux représentés aux extrémités de la première composante principale (PC1), nous avons identifié les individus (chansons) ayant les contributions les plus élevées, positives comme négatives.\n",
    "\n",
    "Du côté des **contributions positives**, on retrouve majoritairement des morceaux **rock, hard rock ou pop rock très énergiques et puissants** tels que American Idiot (Green Day), Beauty Queen (BLVK SWVN) ou ATTENTION ATTENTION (Shinedown). Ces morceaux sont caractérisés par une énergie élevée, une forte intensité sonore (loudness) et une faible acoustique, ce qui confirme bien la structure mise en évidence par la CP1. Notons aussi This Is How We Do It (Montell Jordan), un morceau R&B énergique, qui se distingue des autres par son genre mais partage les mêmes caractéristiques acoustiques.\n",
    "\n",
    "À l’opposé, les morceaux à **contribution très négative** sur PC1 sont des titres à **forte acoustique, peu énergiques et très faibles en loudness**. Il s'agit notamment de sons ambiants, relaxants ou naturels, comme Peaceful Forest ou Tropical Rainforest at Dawn, mais aussi de titres R&B ou indie très doux (Small de chloe moriondo). Ces morceaux incarnent l'autre extrémité de la CP1 : des chansons calmes, acoustiques et à faible énergie, souvent issues de sous-genres comme tropical, indie poptimism ou new jack swing.\n",
    "\n",
    "Cette opposition renforce l’interprétation de la CP1 comme un axe énergie / intensité sonore vs. calme / acoustique, pertinent pour distinguer deux grandes familles de styles musicaux dans le dataset.\n",
    "\n",
    "Nous faison de même pour les deux autres composantes principales, en regardant les morceaux qui contribuent le plus à chacune des composantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 2\n",
    "dim2_coords <- pca$ind$coord[, 2]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices_dim2 <- order(dim2_coords)[1:5]\n",
    "max_indices_dim2 <- order(dim2_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals_dim2 <- song[c(min_indices_dim2, max_indices_dim2), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals_dim2$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals_dim2$Dim2_Value <- dim2_coords[c(min_indices_dim2, max_indices_dim2)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim2_Value au début\n",
    "col_order <- c(\"Category\", \"Dim2_Value\", colnames(extreme_individuals_dim2)[1:(ncol(extreme_individuals_dim2)-2)])\n",
    "extreme_individuals_dim2 <- extreme_individuals_dim2[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals_dim2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n",
    "\n",
    "Côté contributions positives, on retrouve des titres principalement rap et latino, tels que Suge de DaBaby ou LAX de B0nds. Ces morceaux sont :\n",
    "\n",
    "    courts,\n",
    "    dansants (haute danceability),\n",
    "    avec une valence élevée (émotion positive),\n",
    "    mais également avec un certain niveau de speechiness, notamment pour les titres rap.\n",
    "\n",
    "Ces morceaux partagent donc des caractéristiques propres aux chansons énergétiques, rythmées et populaires, souvent taillées pour le streaming, avec des formats courts, accrocheurs et directs.\n",
    "\n",
    "À l’opposé, les morceaux ayant une forte contribution négative à PC2 sont très différents : on retrouve des paysages sonores naturels, ambiants ou instrumentaux comme Rain Forest and Tropical Beach Sound, Caribbean Thunderstorm, ou encore Battlement. Ces titres sont :\n",
    "\n",
    "    longs,\n",
    "    instrumentaux (forte instrumentalness),\n",
    "    avec une faible valence et peu de parole,\n",
    "    et souvent issus de sous-genres comme tropical, album rock, ou ambient.\n",
    "\n",
    "Cela confirme l’interprétation initiale de la PC2 comme un axe opposant la musique instrumentale, longue et contemplative à une musique populaire, dansante et rythmée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 3\n",
    "dim3_coords <- pca$ind$coord[, 3]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices_dim3 <- order(dim3_coords)[1:5]\n",
    "max_indices_dim3 <- order(dim3_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals_dim3 <- song[c(min_indices_dim3, max_indices_dim3), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals_dim3$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals_dim3$Dim3_Value <- dim3_coords[c(min_indices_dim3, max_indices_dim3)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim3_Value au début\n",
    "col_order <- c(\"Category\", \"Dim3_Value\", colnames(extreme_individuals_dim3)[1:(ncol(extreme_individuals_dim3)-2)])\n",
    "extreme_individuals_dim3 <- extreme_individuals_dim3[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals_dim3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "La troisième composante principale met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "Du côté des contributions négatives, on retrouve des titres de pop et R&B calmes et acoustiques comme raindrops (an angel cried) (Ariana Grande) ou You Are The Reason (Calum Scott). Ces chansons ont :\n",
    "\n",
    "    une acousticness élevée (acapela, guitare acoustique, piano),\n",
    "    un tempo légèrement plus rapide que la médiane des morceaux,\n",
    "    une faible énergie, mais un potentiel émotionnel fort (valence variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "Les contributions positives, quant à elles, sont largement dominées par des morceaux EDM ou latino instrumentaux, comme I Feel Love ou Chase. Ces morceaux sont :\n",
    "\n",
    "    longs,\n",
    "    très instrumentaux,\n",
    "    énergiques mais souvent moins \"accessibles\" émotionnellement (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la PC3 oppose des créations acoustiques à forte charge émotionnelle à des morceaux instrumentaux, électroniques, longs, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque le signe des contributions est inversé par rapport à l'analyse en composantes principales (ACP) réalisée sous Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS\n",
    "\n",
    "Le **MDS (Multidimensional Scaling)** est une technique de réduction de dimension non linéaire qui permet de visualiser des données en préservant les distances entre les points. Dans notre cas, nous allons l'appliquer sur les données prétraitées pour obtenir une représentation en 2D des morceaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Sélectionner les variables numériques pertinentes (similaire à l'ACP)\n",
    "numerical_features <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                               \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                               \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "\n",
    "# S'assurer qu'il n'y a pas de NA\n",
    "numerical_features <- na.omit(numerical_features)\n",
    "\n",
    "# Limiter à 2000 chansons pour éviter crash mémoire\n",
    "set.seed(42)\n",
    "if (nrow(numerical_features) > 2000) {\n",
    "  sample_idx <- sample(seq_len(nrow(numerical_features)), 2000)\n",
    "  numerical_features <- numerical_features[sample_idx, ]\n",
    "}\n",
    "\n",
    "# Standardiser\n",
    "scaled_numerical_features <- scale(numerical_features)\n",
    "dist_matrix <- dist(scaled_numerical_features)\n",
    "\n",
    "# MDS sans add=TRUE\n",
    "mds_result <- cmdscale(dist_matrix, k = 2, eig = TRUE)\n",
    "\n",
    "mds_points <- as.data.frame(mds_result$points)\n",
    "colnames(mds_points) <- c(\"Dim1\", \"Dim2\")\n",
    "\n",
    "# Récupérer le genre correspondant\n",
    "if (exists(\"sample_idx\")) {\n",
    "  temp_df_for_mds <- song[, c(\"playlist_genre\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                              \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                              \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "  temp_df_for_mds_clean <- na.omit(temp_df_for_mds)\n",
    "  temp_df_for_mds_clean <- temp_df_for_mds_clean[sample_idx, ]\n",
    "} else {\n",
    "  temp_df_for_mds <- song[, c(\"playlist_genre\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                              \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                              \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "  temp_df_for_mds_clean <- na.omit(temp_df_for_mds)\n",
    "}\n",
    "\n",
    "mds_points$playlist_genre <- temp_df_for_mds_clean$playlist_genre\n",
    "\n",
    "# Visualisation\n",
    "ggplot(mds_points, aes(x = Dim1, y = Dim2, color = playlist_genre)) +\n",
    "  geom_point(alpha = 0.7) +\n",
    "  labs(title = \"MDS des chansons (basé sur les caractéristiques audio)\",\n",
    "       x = \"Dimension MDS 1\",\n",
    "       y = \"Dimension MDS 2\",\n",
    "       color = \"Genre de Playlist\") +\n",
    "  theme_minimal() +\n",
    "  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))\n",
    "\n",
    "# Goodness-of-fit\n",
    "cat(\"\\nGoodness-of-fit (GOF):\\n\")\n",
    "print(mds_result$GOF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "Nous allons désormais réaliser un **t-SNE** (t-distributed Stochastic Neighbor Embedding) pour visualiser en 2D la proximité (ou la similarité) entre les chansons Spotify selon leurs caractéristiques audio (danceability, energy, loudness, etc.), pour voir **si des genres musicaux distincts émergent sous forme de groupes**. A l'inverse de la PCA et de la MDS, le **t-SNE est une méthode non linéaire** qui pourrait capturer des relations différentes entre les données que celles révélées par les méthodes linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"Rtsne\")\n",
    "library(Rtsne)\n",
    "library(ggplot2)\n",
    "\n",
    "# Supprimer les doublons\n",
    "scaled_numerical_features_unique <- unique(scaled_numerical_features)\n",
    "\n",
    "# Identifier les lignes uniques\n",
    "unique_rows <- !duplicated(scaled_numerical_features)\n",
    "\n",
    "# Conserver uniquement les genres correspondant aux lignes uniques\n",
    "playlist_genre_unique <- temp_df_for_mds_clean$playlist_genre[unique_rows]\n",
    "\n",
    "# Exécuter t-SNE\n",
    "set.seed(42)\n",
    "tsne_result <- Rtsne(scaled_numerical_features_unique, dims = 2, perplexity = 30, verbose = TRUE)\n",
    "\n",
    "# Préparer le dataframe pour ggplot\n",
    "tsne_df <- as.data.frame(tsne_result$Y)\n",
    "colnames(tsne_df) <- c(\"Dim1\", \"Dim2\")\n",
    "tsne_df$playlist_genre <- playlist_genre_unique\n",
    "\n",
    "# Visualisation\n",
    "ggplot(tsne_df, aes(x = Dim1, y = Dim2, color = playlist_genre)) +\n",
    "  geom_point(alpha = 0.6) +\n",
    "  labs(title = \"t-SNE des chansons (caractéristiques audio)\",\n",
    "       x = \"Dimension 1\", y = \"Dimension 2\",\n",
    "       color = \"Genre de Playlist\") +\n",
    "  theme_minimal() +\n",
    "  guides(color = guide_legend(override.aes = list(size = 4, alpha = 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Interprétation des méthodes de MDS et t-SNE\n",
    "\n",
    "### Interprétation du MDS\n",
    "\n",
    "Le graphique issu de la MDS montre une concentration importante des points au centre, avec un fort chevauchement entre les différents genres musicaux (`pop`, `rap`, `r&b`, `rock`, etc.). Il n'y a pas de séparation nette ou de regroupement clair visible sur les deux dimensions principales.\n",
    "\n",
    "Le **Goodness-of-Fit (GOF)** est d’environ **0.34**, ce qui signifie que seulement **34 %** de la structure initiale des distances est préservée dans cette projection bidimensionnelle. Ce score relativement faible traduit une **perte d'information importante**, ce qui rend la visualisation difficile à interpréter de manière fiable.\n",
    "\n",
    "Cela suggère que :\n",
    "\n",
    "- Les genres musicaux ne se distinguent pas clairement sur la base des distances euclidiennes entre leurs caractéristiques audio normalisées.\n",
    "- La MDS, étant une méthode **linéaire**, ne capture pas bien les relations **non linéaires** qui pourraient exister entre les chansons.\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation du t-SNE\n",
    "\n",
    "Le graphique t-SNE montre une plus grande dispersion des points, avec des zones où certains genres comme `edm` ou `rap` semblent former des **sous-groupes partiellement distincts**. Cependant, on observe encore un chevauchement significatif entre les genres.\n",
    "\n",
    "Contrairement à la MDS, le t-SNE est une méthode **non linéaire** qui vise à préserver les **voisinages locaux** plutôt que les distances globales. Cela lui permet de mieux mettre en évidence les structures locales, comme des groupes compacts, même si les distances globales ne sont pas interprétables.\n",
    "\n",
    "L’interprétation du t-SNE suggère que :\n",
    "\n",
    "- Il existe quelques **régions homogènes** selon certains genres, mais aucune **séparation franche** entre clusters de genres.\n",
    "- Les caractéristiques audio seules ne suffisent probablement pas à **discriminer clairement** les genres musicaux.\n",
    "- Le t-SNE offre une visualisation plus riche que la MDS, mais reste difficile à interpréter en l’absence de clusters bien définis.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion commune\n",
    "\n",
    "Les deux méthodes révèlent que les genres musicaux dans ce jeu de données **ne sont pas linéairement séparables** sur la base des caractéristiques audio fournies. Le chevauchement visuel suggère soit :\n",
    "\n",
    "- une **proximité réelle** entre les genres sur le plan acoustique,\n",
    "- soit un **manque de variabilité** ou de pertinence dans les variables utilisées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Analyse en Correspondances Multiples (MCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif\n",
    "\n",
    "L'Analyse en Correspondances Multiples (MCA) va être utilisée afin de visualiser les associations entre les modalités des variables qualitatives et d'identifier des clusters ou des oppositions significatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des variables quantitatives en catégories\n",
    "\n",
    "Pour enrichir l'analyse des correspondances multiples (MCA), nous proposons de convertir les variables quantitatives en variables qualitatives ordinales. Cette transformation permet d'intégrer les caractéristiques audio numériques dans une analyse factorielle adaptée aux données catégorielles.\n",
    "\n",
    "#### Critères de segmentation\n",
    "\n",
    "La catégorisation tient compte des seuils naturels d'interprétation des caractéristiques audio :\n",
    "\n",
    "**Variables binaires (seuil à 0.5)** : \n",
    "- `danceability`, `energy`, `valence` : Séparation entre niveaux faible/élevé selon la médiane théorique\n",
    "- `instrumentalness` : Distinction claire entre morceaux vocaux et instrumentaux\n",
    "\n",
    "**Variables à seuils spécifiques** :\n",
    "- `speechiness` : Seuil à 0.3 pour différencier musique pure vs. contenu parlé (rap, podcast)\n",
    "- `liveness` : Seuil à 0.8 pour capturer les vraies performances live\n",
    "- `popularity` : Segmentation en tertiles (0-20, 20-75, 75-100) reflétant les distributions réelles de Spotify\n",
    "\n",
    "**Variables temporelles** :\n",
    "- `tempo` : Classification musicologique standard (lent <100, modéré 100-150, rapide >150 BPM)\n",
    "- `duration` : Segmentation basée sur les formats musicaux (courts <2min, moyens 2-4min, longs >4min)\n",
    "- `decade` : Regroupement par décennies avec fusion des années 1950s-1960s pour équilibrer les effectifs\n",
    "\n",
    "Cette approche préserve la signification musicale des variables tout en créant des catégories équilibrées pour l'analyse MCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'un data.frame catégorique selon les règles demandées\n",
    "\n",
    "df_cat_custom <- data.frame(row.names = rownames(song))\n",
    "\n",
    "# Popularity\n",
    "df_cat_custom$popularity_cat <- cut(\n",
    "    song$track_popularity,\n",
    "    breaks = c(-1, 20, 75, 100),\n",
    "    labels = c(\"Peu populaire\", \"Popularité moyenne\", \"Très populaire\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Speechiness\n",
    "df_cat_custom$speechiness_cat <- cut(\n",
    "    song$speechiness,\n",
    "    breaks = c(-0.01, 0.3, 1.0),  # Ajuster les seuils\n",
    "    labels = c(\"Peu de paroles\", \"Paroles dominantes\"),  # Deux classes seulement\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Danceability\n",
    "df_cat_custom$danceability_cat <- cut(\n",
    "    song$danceability,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Peu dansant\", \"Dansant\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Energy\n",
    "df_cat_custom$energy_cat <- cut(\n",
    "    song$energy,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Peu énergique\", \"Energique\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Instrumentalness\n",
    "df_cat_custom$instrumentalness_cat <- cut(\n",
    "    song$instrumentalness,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Peu instrumental\", \"Instrumentale\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Liveness\n",
    "df_cat_custom$liveness_cat <- cut(\n",
    "    song$liveness,\n",
    "    breaks = c(-0.01, 0.8, 1.0),\n",
    "    labels = c(\"Pas live\", \"Live\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Valence\n",
    "df_cat_custom$valence_cat <- cut(\n",
    "    song$valence,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Triste\", \"Joyeux\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Tempo\n",
    "df_cat_custom$tempo_cat <- cut(\n",
    "    song$tempo,\n",
    "    breaks = c(-Inf,100, 150, Inf),\n",
    "    labels = c(\"Tempo lent\", \"Tempo modéré\", \"Tempo rapide\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Duration (en secondes)\n",
    "df_cat_custom$duration_cat <- cut(\n",
    "    song$duration_s,\n",
    "    breaks = c(-0.01, 120, 240, Inf),\n",
    "    labels = c(\"Morceaux courts\", \"Morceaux moyennement longs\", \"Morceaux longs\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Décennie de sortie de l'album\n",
    "years <- as.numeric(format(song$track_album_release_date, \"%Y\"))\n",
    "df_cat_custom$decade <- ifelse(\n",
    "    !is.na(years),\n",
    "    paste0(floor(years / 10) * 10, \"s\"),\n",
    "    \"unknown\"\n",
    ")\n",
    "\n",
    "#Fusionner 50s et 60s\n",
    "df_cat_custom$decade <- recode(df_cat_custom$decade, \n",
    "                               \"1950s\" = \"1950s-1960s\", \n",
    "                               \"1960s\" = \"1950s-1960s\")\n",
    "\n",
    "head(df_cat_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "Dans un premier temps, nous allons nous intéresser aux trois variables catégorielles suivantes :Les variables qualitatives sélectionnées pour cette première analyse sont :\n",
    "- `playlist_genre` : Genre de la playlist (ex. rock, pop, rap, etc.).\n",
    "- `key` : Tonalité musicale (ex. C, D, E♭, etc.).\n",
    "- `mode` : Mode musical (majeur ou mineur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sélection de toutes les variables qualitatives pertinentes pour la MCA\n",
    "qual_vars <- c( 'playlist_genre', 'key', 'mode')\n",
    "song_mca_all <- song[, qual_vars]\n",
    "\n",
    "# Réalisation de la MCA avec FactoMineR\n",
    "mca_all <- MCA(song_mca_all, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_all, col.var = \"cos2\", \n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Toutes les variables qualitatives\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Axes factoriels\n",
    "- **Dim1 (8%)** : Cet axe semble opposer des genres musicaux et des tonalités spécifiques :\n",
    "  - À droite, des genres comme `rap` et des tonalités comme `A♯/B♭` sont associés à des morceaux modernes ou spécifiques.\n",
    "  - À gauche, des tonalités comme `C` et `G` sont associées à des genres comme `rock`, suggérant une relation avec des styles plus classiques.\n",
    "- **Dim2 (6.6%)** : Cet axe reflète une distinction entre les modes (`major` et `minor`) et leur association avec certains genres :\n",
    "  - En haut, le mode `major` est associé à des genres comme `rock`.\n",
    "  - En bas, le mode `minor` est plus proche de genres comme `rap` et `edm`.\n",
    "\n",
    "#### 2. Proximité des modalités\n",
    "- Les modalités proches sur le graphique sont souvent associées dans les données :\n",
    "  - `pop`, `latin`, `r&b` et `edm` sont centrés par rapport aux modes `minor`et `major`, indiquant qu'ils n'appartiennent pas clairement à un mode spécifique, mais partagent des caractéristiques communes.\n",
    "  - `rap` est également centré par rapport à ces modes, ce qui suggère que l'utilisation des modes majeurs et mineurs est assez équilibrée dans la composition des morceaux de rap. Toutefois, il reste distinct des groupes `pop`, `latin`, `r&b` et `edm`.\n",
    "  - `rock` est plus proche de `major`, ce qui suggère que les musiques de ce genre sont souvent associées à des tonalités majeures.\n",
    "  - Les tonalités comme `B`,`D♯/E♭`,`A♯/B♭`,`F♯/G♭`et `F` sont proches de `minor`, indiquant qu'elles sont souvent utilisées dans des morceaux en mode mineur.\n",
    "  - Les tonalités comme `C`, `G`,`D` sont proches de `major`, ce qui suggère qu'elles sont souvent utilisées dans des morceaux en mode majeur.\n",
    "\n",
    "#### 3. Cos2 (Qualité de représentation)\n",
    "- Les couleurs des points indiquent la qualité de représentation des modalités sur les deux premières dimensions :\n",
    "  - Les modalités avec des couleurs chaudes (orange/rouge) comme `major` ou `minor` sont bien représentées sur ces axes.\n",
    "  - Les modalités avec des couleurs froides (bleu/vert) comme certaines tonalités (`C`, `G`) sont moins bien représentées, ce qui signifie qu'elles pourraient être mieux expliquées par d'autres dimensions.\n",
    "\n",
    "### Conclusion\n",
    "Cette MCA met en évidence des associations claires entre les genres musicaux, les tonalités (`key`), et les modes (`major`/`minor`). Elle permet de visualiser les relations qualitatives dans les données et d'identifier des clusters ou des oppositions significatives. Par exemple :\n",
    "- `rock` est distinct des autres genres, avec des tonalités et un mode spécifiques.\n",
    "- `pop`, `latin`, `r&b` et `edm` partagent des caractéristiques similaires, mais ne sont pas clairement associés à un mode particulier.\n",
    "- `rap` est centré par rapport aux modes, mais reste distinct des autres genres.\n",
    "\n",
    "Ces résultats offrent une meilleure compréhension des structures qualitatives des données et peuvent être utilisés pour des analyses complémentaires, comme la segmentation ou la classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se propose ensuite d'identifier les top artists afin de valider cette MCA et de voir si les artistes les plus populaires sont bien représentés dans les genres identifiés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Identifier les top artists\n",
    "top_artists <- c(\"Eminem\", \"Green Day\", \"David Guetta\", \"Ed Sheeran\")\n",
    "\n",
    "# Créer une nouvelle variable track_artist_grouped avec \"other\" pour les artistes non sélectionnés\n",
    "song$track_artist_grouped <- as.character(song$track_artist)\n",
    "song$track_artist_grouped[!(song$track_artist %in% top_artists)] <- \"other\"\n",
    "song$track_artist_grouped <- as.factor(song$track_artist_grouped)\n",
    "\n",
    "# Filtrer le dataset pour ne garder que les morceaux des top artists ou \"other\"\n",
    "song_top_other <- song[song$track_artist_grouped %in% c(top_artists, \"other\"), ]\n",
    "\n",
    "# Sélection des variables qualitatives pour la MCA\n",
    "qual_vars_top_other <- c('track_artist_grouped', 'playlist_genre', 'key', 'mode')\n",
    "song_mca_top_other <- song_top_other[, qual_vars_top_other]\n",
    "\n",
    "# Réalisation de la MCA\n",
    "mca_top_other <- MCA(song_mca_top_other, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_top_other, col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Top 4 artistes vs autres + genre, key, mode\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Proximité des modalités\n",
    "- Les artistes proches sur le graphique partagent des caractéristiques similaires :\n",
    "  - `Ed Sheeran` est proche des tonalités `A` et `D`, ainsi que du mode `major`, ce qui reflète son style musical souvent associé à des tonalités classiques.\n",
    "  - `Green Day` est également associé au mode `major` et à des tonalités comme `C` et `D`, typiques de leur style rock.\n",
    "  - `David Guetta` est lié à des tonalités comme `F` et `D♯/E♭`, souvent utilisées dans la musique électronique.\n",
    "  - `Eminem` est associé au mode `minor` et à des tonalités comme `A♯/B♭`, caractéristiques de son style rap.\n",
    "\n",
    "#### 2. Clusters identifiés\n",
    "  - `rock` est fortement associé à `Green Day` et au mode `major`.\n",
    "  - `rap` est lié à `Eminem` et au mode `minor`.\n",
    "  - `Ed Sheeran` est proche du centre, indiquant un style musical équilibré entre tonalités et modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un deuxième temps, nous allons effectuer une Analyse des Correspondances Multiples (MCA) en rajoutant les variables qualitatives construites à partir des variables quantitatives. Cela nous permettra d'explorer les relations entre les genres musicaux et les caractéristiques audio de manière plus approfondie.\n",
    "\n",
    "#### Variables utilisées\n",
    "\n",
    "Les variables qualitatives sélectionnées pour cette analyse sont :\n",
    "- `playlist_genre` : Genre de la playlist (ex. rock, pop, rap, edm, r&b, latin).\n",
    "- `popularity_cat` : Catégorie de popularité (Peu populaire, Popularité moyenne, Très populaire).\n",
    "- `speechiness_cat` : Présence de paroles (Peu de paroles, Paroles dominantes).\n",
    "- `danceability_cat` : Potentiel dansant (Peu dansant, Dansant).\n",
    "- `energy_cat` : Niveau d'énergie (Peu énergique, Énergique).\n",
    "- `instrumentalness_cat` : Caractère instrumental (Peu instrumental, Instrumentale).\n",
    "- `liveness_cat` : Caractère live (Pas live, Live).\n",
    "- `valence_cat` : Valence émotionnelle (Triste, Joyeux).\n",
    "- `tempo_cat` : Catégorie de tempo (Tempo lent, Tempo modéré, Tempo rapide).\n",
    "- `duration_cat` : Durée des morceaux (Morceaux courts, Morceaux moyennement longs, Morceaux longs).\n",
    "- `decade` : Décennie de sortie (1950s-1960s, 1970s, 1980s, 1990s, 2000s, 2010s, 2020s).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# D'abord, ajouter les variables catégorielles créées précédemment à song\n",
    "song$popularity_cat <- df_cat_custom$popularity_cat\n",
    "song$speechiness_cat <- df_cat_custom$speechiness_cat\n",
    "song$danceability_cat <- df_cat_custom$danceability_cat\n",
    "song$energy_cat <- df_cat_custom$energy_cat\n",
    "song$instrumentalness_cat <- df_cat_custom$instrumentalness_cat\n",
    "song$liveness_cat <- df_cat_custom$liveness_cat\n",
    "song$valence_cat <- df_cat_custom$valence_cat\n",
    "song$tempo_cat <- df_cat_custom$tempo_cat\n",
    "song$duration_cat <- df_cat_custom$duration_cat\n",
    "song$decade <- df_cat_custom$decade\n",
    "\n",
    "# MCA avec toutes les variables qualitatives + les variables catégorielles créées\n",
    "qual_vars_cat <- c('playlist_genre', \n",
    "                   'popularity_cat', 'speechiness_cat', \n",
    "                   'danceability_cat', 'energy_cat', \n",
    "                   'instrumentalness_cat', 'liveness_cat', \n",
    "                   'valence_cat', 'tempo_cat', \n",
    "                   'duration_cat', 'decade')\n",
    "song_mca_cat <- song[, qual_vars_cat]\n",
    "\n",
    "# Réalisation de la MCA\n",
    "mca_cat <- MCA(song_mca_cat, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_cat, col.var = \"cos2\",\n",
    "                   gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "                   repel = TRUE) +\n",
    "  labs(title = \"MCA - Variables catégorielles\",\n",
    "         subtitle = \"Variables incluses: playlist_genre, popularity_cat, speechiness_cat, danceability_cat,\\nenergy_cat, instrumentalness_cat, liveness_cat, valence_cat, tempo_cat,\\nduration_cat, decade\",\n",
    "         caption = \"Les couleurs indiquent la qualité de représentation (cos2) des modalités\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"bottom\",\n",
    "            plot.title = element_text(size = 16),\n",
    "            plot.subtitle = element_text(size = 12, color = \"gray40\"),\n",
    "            plot.caption = element_text(size = 10, color = \"gray50\"),\n",
    "            axis.text = element_text(size = 12),\n",
    "            axis.title = element_text(size = 14)) +\n",
    "  guides(color = guide_colorbar(title = \"Cos2\", \n",
    "                                                title.position = \"top\",\n",
    "                                                barwidth = 15,\n",
    "                                                barheight = 1))\n",
    "\n",
    "# Afficher avec une taille plus grande\n",
    "options(repr.plot.width = 18, repr.plot.height = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. **Axes factoriels**\n",
    "\n",
    "##### **Dimension 1 (8.15%)** :\n",
    "\n",
    "Cet axe semble opposer :\n",
    "\n",
    "* **À droite** : des genres et époques associés à une musique plus **live**, **peu dansante**, **rock** et **années 1970–1980**, avec une tendance à la **longueur**.\n",
    "* **À gauche** : des genres comme **EDM**, **rap**, ou **pop des années 2010–2020**, associés à des morceaux plus **courts**, **instrumentaux**, **très populaires**, avec **paroles dominantes**, souvent **joyeux**.\n",
    "\n",
    "##### **Dimension 2 (7.14%)** :\n",
    "\n",
    "Cet axe reflète plutôt une opposition d’ambiance :\n",
    "\n",
    "* **En bas** : Musiques plus **live**, **peu dansantes**, parfois **instrumentales**, associées à des décennies anciennes (1950s–1980s).\n",
    "* **En haut** : Musiques plus **rapides**, **énergétiques**, **avec paroles dominantes**, parfois **r\\&b** ou **pop**.\n",
    "\n",
    "> La projection est inversée selon la dim 1 par rapport aux résultats sous R. Cela n'affecte pas l'interprétation, seule l’orientation spatiale est différente.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Proximité des modalités**\n",
    "\n",
    "* Les genres **rap**, **latin**, **court**, **très populaire** et **paroles dominantes** sont regroupés → musique courte, populaire, axée sur le texte.\n",
    "* Le **rock** est fortement associé à la **décennie 1980**, à un **caractère live** et **peu dansant**.\n",
    "* **EDM** est très proche de **instrumentale**, indiquant des morceaux sans paroles.\n",
    "* Les catégories **\"paroles dominantes\"**, **\"peu instrumental\"**, et **\"énergique\"** sont toutes proches, suggérant que beaucoup de morceaux énergiques contiennent beaucoup de texte.\n",
    "* **Pop des années 2010s et 2020s**, **dansants**, morceaux **moyennement long** se positionne plutôt au centre, ce qui reflète une certaine **polyvalence**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Cos² (qualité de représentation)**\n",
    "\n",
    "* Les modalités bien représentées par les deux axes incluent :\n",
    "\n",
    "  * `rock`, `live`, `très populaire`, `joyeux`, `paroles dominantes`, `peu dansant`\n",
    "* Les modalités avec des bulles plus petites comme `minor`, `pop`, `latin`, `r&b` sont moins bien représentées → elles nécessiteraient plus de dimensions pour être bien décrites.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Cette MCA met en évidence des **clusters sémantiques clairs** entre les genres, l’époque, les caractéristiques émotionnelles et musicales :\n",
    "\n",
    "* **Le rock des années 70–80** est clairement identifiable : live, peu dansant, majeur, long.\n",
    "* **Le EDM et l’instrumental** vont de pair, souvent peu dansants, modernes, peu de texte.\n",
    "* **Le rap** est court, populaire, avec des paroles dominantes, souvent dans un registre énergique mais pas exclusivement mineur ou majeur.\n",
    "* **La pop des années 2010s–2020s** est très mixte : ni clairement joyeuse ni triste, ni très rapide ni lente → un profil \"standard\" qui touche un large public."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Analyse Factorielle Multiple (MFA)\n",
    "\n",
    "L’Analyse Factorielle Multiple (MFA) est une méthode d’analyse exploratoire multivariée qui permet d’étudier simultanément plusieurs groupes de variables de nature différente, notamment des variables quantitatives (caractéristiques audio) et qualitatives (genre, tonalité, mode, etc.). \n",
    "\n",
    "Dans le contexte de ce projet Spotify, la MFA est particulièrement pertinente car elle va permettre de :\n",
    "- **Combiner** dans une même analyse les profils audio des morceaux et leurs attributs qualitatifs (genre, mode, key, etc.), en tenant compte de la structure de chaque groupe de variables.\n",
    "- **Explorer les liens** entre les caractéristiques musicales objectives et les catégories musicales, pour voir par exemple si certains genres ou modes sont associés à des profils audio spécifiques.\n",
    "- **Visualiser la structure globale** du jeu de données en intégrant toutes les dimensions importantes, ce qui offre une vision plus complète que l’ACP (centrée sur le quantitatif) ou la MCA (centrée sur le qualitatif) seules.\n",
    "\n",
    "La MFA est donc un outil idéal pour comprendre comment les différentes facettes des chansons (audio et catégorielles) s’articulent et pour identifier des profils ou des clusters mixtes dans le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Analyse Factorielle Multiple (MFA) : audio + genre\n",
    "\n",
    "# 1. Préparer les données pour MFA avec playlist_genre\n",
    "mfa_data_genre <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\",\n",
    "              \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\", \"playlist_genre\")]\n",
    "\n",
    "# S'assurer que playlist_genre est un facteur\n",
    "mfa_data_genre$playlist_genre <- as.factor(mfa_data_genre$playlist_genre)\n",
    "\n",
    "# 2. Définir les groupes : 10 variables audio (quantitatives), 1 qualitative (playlist_genre)\n",
    "group_genre <- c(10, 1)\n",
    "type_genre <- c(\"s\", \"n\")  # 1 groupe quanti, 1 groupe quali\n",
    "\n",
    "# 3. Réaliser la MFA\n",
    "mfa_genre <- MFA(mfa_data_genre, group = group_genre, type = type_genre, \n",
    "         name.group = c(\"Audio\", \"Genre\"), graph = FALSE)\n",
    "\n",
    "# 4. Visualisation des individus colorés par genre\n",
    "fviz_mfa_ind(mfa_genre, habillage = mfa_data_genre$playlist_genre, palette = \"Set2\", \n",
    "       addEllipses = TRUE, ellipse.type = \"confidence\", label = \"none\") +\n",
    "  labs(title = \"MFA : projection des chansons selon audio et genre\") +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation de l'Analyse Factorielle Multiple (MFA)\n",
    "\n",
    "#### **Analyse audio + genre**\n",
    "\n",
    "La MFA intégrant les caractéristiques audio et les genres musicaux révèle une **structuration claire** des genres selon leurs profils acoustiques :\n",
    "\n",
    "**Séparation des genres :**\n",
    "- Les genres forment des **clusters relativement distincts** dans l'espace factoriel, confirmant que les caractéristiques audio permettent une différenciation entre styles musicaux\n",
    "- Certains genres comme **rock** et **edm** montrent une **séparation nette**, reflétant leurs profils acoustiques contrastés (rock : acoustique, live vs. edm : électronique, synthétique)\n",
    "- D'autres genres comme **pop** et **latin** présentent une **plus grande diversité interne** et un chevauchement partiel, suggérant une variabilité stylistique au sein de ces catégories\n",
    "\n",
    "**Axes factoriels :**\n",
    "- Les axes révèlent des **oppositions claires** entre profils musicaux :\n",
    "    - **Rock** : associé à des caractéristiques plus classiques (acousticness, liveness)\n",
    "    - **EDM** : orienté vers des profils modernes et électroniques (energy, danceability)\n",
    "    - **Rap** : caractérisé par des aspects rythmiques et vocaux (speechiness, tempo)\n",
    "\n",
    "\n",
    "Ce graphique met en évidence la structuration des genres musicaux en fonction des caractéristiques audio. Il montre que certains genres (comme le rock et l'edm) sont bien séparés, tandis que d'autres (comme le pop et le latin) partagent des caractéristiques communes avec plusieurs genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Analyse Factorielle Multiple (MFA) : audio + decade\n",
    "\n",
    "# 1. Préparer les données pour MFA avec decade\n",
    "mfa_data_decade <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\",\n",
    "                           \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\", \"decade\")]\n",
    "\n",
    "# S'assurer que decade est un facteur\n",
    "mfa_data_decade$decade <- as.factor(mfa_data_decade$decade)\n",
    "\n",
    "# 2. Définir les groupes : 10 variables audio (quantitatives), 1 qualitative (decade)\n",
    "group_decade <- c(10, 1)\n",
    "type_decade <- c(\"s\", \"n\")  # 1 groupe quanti, 1 groupe quali\n",
    "\n",
    "# 3. Réaliser la MFA\n",
    "mfa_decade <- MFA(mfa_data_decade, group = group_decade, type = type_decade, \n",
    "                  name.group = c(\"Audio\", \"Decade\"), graph = FALSE)\n",
    "\n",
    "# 4. Visualisation des individus colorés par décennie\n",
    "fviz_mfa_ind(mfa_decade, habillage = mfa_data_decade$decade, palette = \"Set1\", \n",
    "             addEllipses = TRUE, ellipse.type = \"confidence\", label = \"none\") +\n",
    "  labs(title = \"MFA : projection des chansons selon audio et décennie\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Analyse audio + décennie**\n",
    "\n",
    "La MFA intégrant les caractéristiques audio et les décennies de sortie des morceaux révèle une **structuration temporelle claire** des chansons selon leurs profils acoustiques.\n",
    "\n",
    "**Séparation des décennies :**\n",
    "- Les décennies forment des **clusters relativement distincts** dans l'espace factoriel, confirmant que les caractéristiques audio évoluent au fil du temps\n",
    "- Les morceaux des **années 1950s-1960s et 1970s** montrent une séparation nette\n",
    "- Les morceaux des **années 2000s, 2010s et 2020s** présentent une plus grande diversité interne et un chevauchement partiel, suggérant une variabilité stylistique accrue dans les productions modernes\n",
    "\n",
    "Ce graphique met en évidence l'**évolution des caractéristiques musicales au fil des décennies**. Il montre que les morceaux anciens (1950s-1970s) sont bien séparés des morceaux modernes (2000s-2020s), tandis que les décennies intermédiaires (1980s-1990s) servent de transition entre ces deux périodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Analyse Factorielle Multiple (MFA) : audio + popularity\n",
    "\n",
    "# 1. Préparer les données pour MFA avec popularity_cat\n",
    "mfa_data_popularity <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\",\n",
    "                               \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\", \"popularity_cat\")]\n",
    "\n",
    "# S'assurer que popularity_cat est un facteur\n",
    "mfa_data_popularity$popularity_cat <- as.factor(mfa_data_popularity$popularity_cat)\n",
    "\n",
    "# 2. Définir les groupes : 10 variables audio (quantitatives), 1 qualitative (popularity_cat)\n",
    "group_popularity <- c(10, 1)\n",
    "type_popularity <- c(\"s\", \"n\")  # 1 groupe quanti, 1 groupe quali\n",
    "\n",
    "# 3. Réaliser la MFA\n",
    "mfa_popularity <- MFA(mfa_data_popularity, group = group_popularity, type = type_popularity, \n",
    "                     name.group = c(\"Audio\", \"Popularity\"), graph = FALSE)\n",
    "\n",
    "# 4. Visualisation des individus colorés par popularité\n",
    "fviz_mfa_ind(mfa_popularity, habillage = mfa_data_popularity$popularity_cat, palette = \"viridis\", \n",
    "             addEllipses = TRUE, ellipse.type = \"confidence\", label = \"none\") +\n",
    "  labs(title = \"MFA : projection des chansons selon audio et popularité\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "#### **Analyse audio + popularité**\n",
    "\n",
    "La MFA intégrant les caractéristiques audio et les niveaux de popularité des morceaux révèle une structuration claire des chansons selon leur popularité.\n",
    "\n",
    "**Séparation des niveaux de popularité :**\n",
    "\n",
    "Les morceaux forment des clusters relativement distincts dans l'espace factoriel, confirmant que les caractéristiques audio influencent leur popularité.\n",
    "\n",
    "Les morceaux **très populaires** montrent une concentration nette.\n",
    "\n",
    "Les morceaux **peu populaires** présentent une plus grande diversité interne et un chevauchement partiel, suggérant une variabilité stylistique accrue ou des caractéristiques acoustiques et instrumentales.\n",
    "\n",
    "Ce graphique met en évidence les relations entre les caractéristiques musicales et la popularité. Il montre que les morceaux très populaires se distinguent par des profils spécifiques, tandis que les morceaux peu populaires sont plus variés. Les morceaux de popularité moyenne occupent une position intermédiaire, suggérant que la popularité est influencée par une combinaison de caractéristiques audio et de facteurs contextuels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## NMF\n",
    "\n",
    "La Factorisation Matricielle Non-Négative (NMF) est une technique de réduction de dimension qui permet de décomposer une matrice en deux matrices de facteurs non négatifs. Dans le contexte de l'analyse des données musicales, NMF est particulièrement utile pour identifier des motifs latents ou des profils musicaux à partir des caractéristiques audio.\n",
    "\n",
    "### Objectif de la NMF\n",
    "L'objectif de la NMF dans ce projet est de découvrir des profils musicaux latents qui peuvent représenter des styles ou des genres musicaux spécifiques. En factorisant les données audio, nous espérons extraire des caractéristiques communes qui peuvent être utilisées pour la recommandation de musique ou pour mieux comprendre la structure des genres musicaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(NMF)\n",
    "# 2. Sélection des colonnes audio uniquement depuis song\n",
    "audio_features <- song %>%\n",
    "  select(danceability, energy, loudness, speechiness, acousticness,\n",
    "         instrumentalness, liveness, valence, tempo, duration_s) %>%\n",
    "  na.omit()\n",
    "\n",
    "# 3. Min-max scaling sur chaque colonne\n",
    "audio_features <- as.data.frame(lapply(audio_features, function(x) (x - min(x)) / (max(x) - min(x))))\n",
    "\n",
    "# 4. Conversion en matrice\n",
    "audio_matrix <- as.matrix(audio_features)\n",
    "\n",
    "# 5. Choix du nombre de composantes (ex. : 4 profils)\n",
    "nmf_result <- nmf(audio_matrix, rank = 4, method = \"brunet\", nrun = 10, seed = 123)\n",
    "\n",
    "# 6. Résumé\n",
    "print(nmf_result)\n",
    "\n",
    "# 7. Matrice W (coefficients pour chaque chanson)\n",
    "W <- basis(nmf_result)\n",
    "\n",
    "# 8. Matrice H (contributions de chaque feature à chaque profil)\n",
    "H <- coef(nmf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Sélection des features audio\n",
    "audio_features <- c('danceability', 'energy', 'loudness', 'speechiness',\n",
    "                   'acousticness', 'instrumentalness', 'liveness',\n",
    "                   'valence', 'tempo', 'duration_s')\n",
    "\n",
    "X <- song[, audio_features]\n",
    "\n",
    "# 2. Normalisation min-max (important pour la NMF)\n",
    "X_scaled <- as.data.frame(lapply(X, function(x) (x - min(x)) / (max(x) - min(x))))\n",
    "X_matrix <- as.matrix(X_scaled)\n",
    "\n",
    "# 3. Tester plusieurs valeurs de r (nombre de composants)\n",
    "errors <- c()\n",
    "r_values <- seq(2, 10, by = 2)\n",
    "\n",
    "for (r in r_values) {\n",
    "  nmf_model <- nmf(X_matrix, rank = r, method = \"brunet\", nrun = 5, seed = 42)\n",
    "  W <- basis(nmf_model)\n",
    "  H <- coef(nmf_model)\n",
    "  reconstruction <- W %*% H\n",
    "  error <- norm(X_matrix - reconstruction, type = \"F\") # norme de Frobenius\n",
    "  errors <- c(errors, error)\n",
    "}\n",
    "\n",
    "# 4. Tracer la courbe de l’erreur de reconstruction\n",
    "plot(r_values, errors, type = \"b\", pch = 19,\n",
    "     main = \"Erreur de reconstruction vs nombre de composants (r)\",\n",
    "     xlab = \"Nombre de composants (r)\",\n",
    "     ylab = \"Erreur de reconstruction (norme de Frobenius)\")\n",
    "grid()\n",
    "\n",
    "#On garde r=6 pour la suite soit 6 profils musicaux\n",
    "\n",
    "# 5. Application de la NMF avec 6 composantes\n",
    "nmf_model_6 <- nmf(X_matrix, rank = 6, method = \"brunet\", nrun = 10, seed = 42)\n",
    "W_6 <- basis(nmf_model_6)\n",
    "H_6 <- coef(nmf_model_6)\n",
    "\n",
    "# 6. Créer un data.frame pour la matrice H\n",
    "H_df <- as.data.frame(H_6)\n",
    "colnames(H_df) <- audio_features\n",
    "rownames(H_df) <- paste0(\"Profil \", 1:6)\n",
    "\n",
    "# 7. Affichage de la matrice H\n",
    "print(\"Matrice H (profils latents définis par les variables audio) :\")\n",
    "\n",
    "# 8. Visualisation : contribution des variables à chaque profil (heatmap)\n",
    "library(reshape2)\n",
    "library(ggplot2)\n",
    "H_df_long <- melt(as.matrix(H_df))\n",
    "colnames(H_df_long) <- c(\"Profil\", \"Variable\", \"Valeur\")\n",
    "\n",
    "ggplot(H_df_long, aes(x = Variable, y = Profil, fill = Valeur)) +\n",
    "    geom_tile() +\n",
    "    geom_text(aes(label = sprintf(\"%.2f\", Valeur)), size = 3) +\n",
    "    scale_fill_gradient(low = \"#E7F6D5\", high = \"#2171B5\") +\n",
    "    labs(title = \"Profils latents musicaux détectés par NMF (matrice H)\",\n",
    "             x = \"Caractéristiques audio\", y = \"Profils NMF\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'erreur de reconstruction décroit jusqu'à notre nombre variables totales, on choisit arbitrairement de prendre 6 facteurs pour la suite de l'analyse, ce qui va nous donner 6 profils musicaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Profils latents détectés\n",
    "\n",
    "L’analyse a révélé **6 profils musicaux latents** à partir des données. Chaque profil est défini par une combinaison unique de caractéristiques audio. Voici leur interprétation :\n",
    "\n",
    "* **Profil 1 : Profil Instrumental**\n",
    "\n",
    "  * Très forte **`instrumentalness`** avec très peu d'autres caractéristiques.\n",
    "  * Correspond clairement à des morceaux **purement instrumentaux**, probablement **ambient**, **classique** ou **bande-son**.\n",
    "\n",
    "* **Profil 2 : Profil Énergique-Intense**\n",
    "\n",
    "  * Caractérisé par de **très fortes valeurs en `energy`, `loudness`, `tempo`, `duration` et `danceability`**.\n",
    "  * Faible en composantes émotionnelles (`valence`), vocales et instrumentales.\n",
    "  * Ce profil pourrait correspondre à des morceaux **très dynamiques et bruyants**, typiques de l’**EDM** (house, electro, techno) ou du **hard-rock**/**metal**.\n",
    "\n",
    "* **Profil 3 : Profil Live**\n",
    "\n",
    "  * Faibles valeurs générales sauf une **forte `liveness`**.\n",
    "  * Peut représenter des morceaux **live**.\n",
    "\n",
    "* **Profil 4 : Profil Émotionnel-Valence**\n",
    "\n",
    "  * Faible en toutes dimensions sauf une très forte **`valence`**.\n",
    "  * Ce profil regroupe des morceaux **émotionnellement très positifs**, avec une ambiance **joyeuse ou euphorique**, indépendamment du tempo ou de l’énergie.\n",
    "\n",
    "* **Profil 5 : Profil Acoustique-Chant**\n",
    "\n",
    "  * Dominé par une forte **`acousticness`**.\n",
    "  * Ce profil, présente **`instrumentalness`=0**, et un faible **`speechiness`** mais différent de zéro.\n",
    "  * Ce profil regroupe possiblement des morceaux **acoustiques et chantés**.\n",
    "\n",
    "* **Profil 6 : Profil Rap-Rythmé**\n",
    "\n",
    "  * Forte `danceability` et `speechiness`.\n",
    "  * Ce profil semble capturer des morceaux **rythmés et très vocaux**, typiques du **rap**, **hip-hop**, voire certains morceaux **R\\&B urbains**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons mettre en œuvre différentes méthodes de clustering afin d’identifier des groupes homogènes de morceaux au sein de notre jeu de données. L’objectif est de regrouper les morceaux présentant des caractéristiques similaires, sans utiliser d’information sur leur genre ou sous-genre, afin de révéler des structures ou des tendances cachées dans les données.  \n",
    "Nous appliquerons plusieurs algorithmes de clustering non supervisé, tels que **K-Means**, le **mélange gaussien (GMM)** et la **classification ascendante hiérarchique (CAH)**. Nous comparerons ensuite les résultats obtenus et analyserons les profils des clusters identifiés, en les reliant aux variables musicales et aux genres présents dans le jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**IMPORTANT**  \n",
    "> Dans ce notebook nous avons fait le choix de faire le clustering pur sur le jeu *data_songs* et ensuite nous allons projeter les clusters obtenus sur les genres des playlists. Ce choix a été fait afin de se concentrer principalement sur les caractéristiques audios des morceaux afin d'obtenir des profils musicaux. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection factorielle des individus (ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va d'abord afficher la représentation factorielle des individus pour pouvoir voir si on est capable de distinguer des classes naturelles. Pour cela, nous effectuons comme dans la partie précédente une ACP sur le jeu *data_songs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sélection des variables numériques pour l'ACP sur onlysongs\n",
    "onlysongs_pca_data <- onlysongs %>%\n",
    "    select(track_popularity, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_s)\n",
    "\n",
    "# Réalisation de l'ACP avec centrage et réduction\n",
    "onlysongs_pca <- PCA(onlysongs_pca_data, scale.unit = TRUE, graph = TRUE)\n",
    "\n",
    "# Affichage du pourcentage de variance expliquée par chaque composante principale\n",
    "fviz_eig(onlysongs_pca, addlabels = TRUE, ylim = c(0, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Affichage des individus sur les plans factoriels (Dim 1-2, 2-3, 1-3) pour l'ACP onlysongs\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             geom = \"point\", \n",
    "             col.ind = \"cos2\", # Coloration selon la qualité de représentation\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"Projection des individus sur le plan factoriel (Dim 1-2)\") +\n",
    "  theme_minimal()\n",
    "\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             axes = c(2, 3),\n",
    "             geom = \"point\", \n",
    "             col.ind = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"Projection des individus sur le plan factoriel (Dim 2-3)\") +\n",
    "  theme_minimal()\n",
    "\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             axes = c(1, 3),\n",
    "             geom = \"point\", \n",
    "             col.ind = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"Projection des individus sur le plan factoriel (Dim 1-3)\") +\n",
    "  theme_minimal()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons la projection de tous les points sur les trois premières dimensions de la PCA calculée précédemment. Les points les plus au centre sont les moins bien représentés pour ces dimensions en général, tandis que ceux qui sont plus éloignés sont mieux représentés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "Avant d’appliquer l’algorithme de clustering K-Means, il est nécessaire de choisir le nombre optimal de clusters à utiliser.\n",
    "Comme l’exploration visuelle précédente ne permet pas d’identifier clairement un nombre naturel de groupes, nous avons recours à la méthode du coude.  \n",
    "Cette méthode consiste à faire varier le nombre de clusters et à observer l’évolution de l’inertie (distortion) pour déterminer le point à partir duquel ajouter des clusters n’apporte plus de gain significatif.\n",
    "Le code suivant permet de visualiser ce critère et d’identifier le nombre de clusters optimal pour K-Means :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Vérifier le nombre de composantes principales disponibles\n",
    "n_components <- ncol(onlysongs_pca$ind$coord)\n",
    "\n",
    "# Méthode du coude (elbow method) pour déterminer le nombre optimal de clusters sur les coordonnées PCA de onlysongs\n",
    "set.seed(42)\n",
    "k_values <- 2:10\n",
    "inertia_pca_onlysongs <- numeric(length(k_values))\n",
    "# Utilisation des 7 premières composantes principales\n",
    "pca_coords <- onlysongs_pca$ind$coord[, 1:n_components]\n",
    "\n",
    "for (i in seq_along(k_values)) {\n",
    "    k <- k_values[i]\n",
    "    kmeans_result <- kmeans(pca_coords, centers = k, nstart = 25)\n",
    "    inertia_pca_onlysongs[i] <- kmeans_result$tot.withinss\n",
    "}\n",
    "\n",
    "plot(k_values, inertia_pca_onlysongs, type = \"b\", pch = 19, col = \"blue\",\n",
    "     xlab = \"Nombre de clusters (k)\", ylab = \"Inertie intra-cluster\",\n",
    "     main = \"Méthode du coude (K-means sur PCA onlysongs)\",\n",
    "     xlim = c(min(k_values) - 1, max(k_values) + 1))  # Élargir légèrement la plage de l'axe des abscisses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de classes optimal pour cette méthode de clustering semble être **5 classes**. Nous allons donc conserver ce nombre pour la suite de notre analyse. Même si le coude ne semble pas être très visible, nous choisissons ce nombre de cluster en se basant sur le nombre choisi dans le notebook python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# K-means sur les coordonnées PCA de onlysongs avec k = 5 clusters\n",
    "set.seed(42)\n",
    "kmeans_pca_onlysongs <- kmeans(onlysongs_pca$ind$coord[, 1:n_components], centers = 5, nstart = 25)\n",
    "\n",
    "# Ajout des labels de cluster au dataset onlysongs\n",
    "onlysongs$kmeans_pca_cluster <- as.factor(kmeans_pca_onlysongs$cluster)\n",
    "\n",
    "# Visualisation des clusters sur les deux premières composantes principales\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             geom = \"point\", \n",
    "             col.ind = onlysongs$kmeans_pca_cluster, \n",
    "             palette = \"jco\", \n",
    "             addEllipses = TRUE) +\n",
    "  labs(title = \"K-means (k=5) sur ACP onlysongs (projection Dim 1-2)\") +\n",
    "  theme_minimal()\n",
    "\n",
    "#affichage sur les dimensions principales 2-3\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             axes = c(2, 3),\n",
    "             geom = \"point\", \n",
    "             col.ind = onlysongs$kmeans_pca_cluster, \n",
    "             palette = \"jco\", \n",
    "             addEllipses = TRUE) +\n",
    "    labs(title = \"K-means (k=5) sur ACP onlysongs (projection Dim 2-3)\") +\n",
    "    theme_minimal()\n",
    "\n",
    "#affichage sur les dimensions principales 1-3\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             axes = c(1, 3),\n",
    "             geom = \"point\", \n",
    "             col.ind = onlysongs$kmeans_pca_cluster, \n",
    "             palette = \"jco\", \n",
    "             addEllipses = TRUE) +\n",
    "    labs(title = \"K-means (k=5) sur ACP onlysongs (projection Dim 1-3)\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, les clusters ne semblent pas bien se distinguer les uns des autres. Nous avons du mélange entre les clusters en fonction des dimensions.\n",
    "\n",
    "Certaines classes semblent avoir une taille différente, pouvant indiquer un éventuel déséquilibre.   \n",
    "Afin d'avoir une analyse plus complète de ces clusters, nous allons étudier les variables explicatives du jeu de données avec les clusters obtenus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étude des autres variables quantitatives avec nos clusters**  \n",
    "On a plusieurs manières d'étudier les variables quantitatives dans nos clusters, soit avec des boxplots (assez visuels), soit avec une `heatmap`, cela permet d'avoir les moyennes centralisées et on a un visuel global de répartitions dans les clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Passage au format long pour ggplot, en utilisant les clusters obtenus précédemment (kmeans_pca_cluster)\n",
    "onlysongs_long <- melt(\n",
    "    cbind(onlysongs[, c(\"kmeans_pca_cluster\")], onlysongs_pca_data),\n",
    "    id.vars = \"kmeans_pca_cluster\"\n",
    ")\n",
    "\n",
    "# Affichage des boxplots pour chaque variable par cluster\n",
    "ggplot(onlysongs_long, aes(x = kmeans_pca_cluster, y = value, fill = kmeans_pca_cluster)) +\n",
    "    geom_boxplot(outlier.size = 0.5) +\n",
    "    facet_wrap(~ variable, scales = \"free_y\") +\n",
    "    labs(title = \"Boxplots des variables quantitatives par cluster (K-means PCA onlysongs)\",\n",
    "         x = \"Cluster\", y = \"Valeur\") +\n",
    "    theme_minimal() +\n",
    "    theme(legend.position = \"none\")\n",
    "\n",
    "#agrandir beaucoup la taille des graphes\n",
    "options(repr.plot.width=40, repr.plot.height=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons que certains clusters se distinguent plus pour certains caractéristiques de leurs musiques.\n",
    "- Pour le **cluster 1**, il semble contenir seul un certain type de tempo, puisque la marge des tempos est très peu écartée contrairement aux autres clusters. Aussi, il contient beaucoup de morceaux avec une instrumentalness élevée.\n",
    "- Pour le **cluster 2**, il contient les musiques avec un energy plus faible, ainsi qu'une acousticness élevée (qui sont corrélées négativement comme on l'a vu dans la partie exploratoire)\n",
    "- Pour le **cluster 3**, il contient des musiques ayant une danceability plus faible.\n",
    "- Pour le **cluster 4**, il se distingue par des sons ayant une speechiness élevée, donc des morceaux très parlés avec peu d'intruments.\n",
    "- Pour le **cluster 5**, celui-ci contient les morceaux avec une valence plus élevée et une liveness faiblesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fusionner song avec les clusters de onlysongs (sur track_name et track_artist)\n",
    "song_with_cluster <- song %>%\n",
    "    left_join(onlysongs[, c(\"track_name\", \"track_artist\", \"kmeans_pca_cluster\")], \n",
    "              by = c(\"track_name\", \"track_artist\"))\n",
    "\n",
    "# Retirer les musiques qui n'ont pas de cluster\n",
    "song_with_cluster_noNA <- song_with_cluster %>%\n",
    "    filter(!is.na(kmeans_pca_cluster))\n",
    "\n",
    "# Afficher un aperçu du résultat\n",
    "head(song_with_cluster_noNA[, c(\"track_name\", \"track_artist\", \"kmeans_pca_cluster\")])\n",
    "\n",
    "#affichage du nombre de données total\n",
    "cat(\"Nombre total de données dans song_with_cluster_noNA :\", nrow(song_with_cluster_noNA), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'une table de contingence : nombre de musiques genre et par cluster\n",
    "heatmap_data <- song_with_cluster_noNA %>%\n",
    "    group_by(kmeans_pca_cluster, playlist_genre) %>%\n",
    "    summarise(count = n(), .groups = \"drop\")\n",
    "\n",
    "# Conversion en matrice pour la heatmap\n",
    "heatmap_matrix <- reshape2::acast(heatmap_data, playlist_genre ~ kmeans_pca_cluster, value.var = \"count\", fill = 0)\n",
    "\n",
    "# Création de la heatmap avec ggplot2 (format long)\n",
    "heatmap_long <- as.data.frame(as.table(heatmap_matrix))\n",
    "colnames(heatmap_long) <- c(\"playlist_genre\", \"kmeans_pca_cluster\", \"count\")\n",
    "\n",
    "ggplot(heatmap_long, aes(x = kmeans_pca_cluster, y = playlist_genre, fill = count)) +\n",
    "    geom_tile(color = \"white\") +\n",
    "    geom_text(aes(label = count), color = \"black\", size = 10) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "    labs(title = \"Nombre de musiques par sous-genre et par cluster\",\n",
    "         x = \"Cluster\",\n",
    "         y = \"Sous-genre\",\n",
    "         fill = \"Nombre\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 20),\n",
    "          axis.text.y = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons maintenant ajouté les genres pour voir leur présence dans les clusters. Nous allons analysé les genres des musiques en se basant sur l'analyse des clusters précédentes.\n",
    "- **Cluster 1 :** Majorité de musiques du style EDM, on peut donc penser que ce style de musique possède souvent le même tempo.\n",
    "- **Cluster 2 :** Majorité de sons R&B,  qui semble donc avoir une energy plus faible et une acousticness élevée.\n",
    "- **Cluster 3 :** Beaucoup de sons rock, pop et edm. Ils semblent être liés à une danceability plus faible, ce qui peut être cohérent, puisque certains sons de ces genres ne sont pas fait pour danser.\n",
    "- **Cluster 4 :** Majorité de musiques rap. Cohérent avec la speechiness très élevée puisque c'est un style de musique très parlé.\n",
    "- **Cluster 5 :** présence de beaucoup de style de musique différents. Cela explique pourquoi dans l'analyse précédente on ne pouvait pas vraiment ressortir de caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'une table de contingence : nombre de musiques par sous-genre et par cluster\n",
    "heatmap_data <- song_with_cluster_noNA %>%\n",
    "    group_by(kmeans_pca_cluster, playlist_subgenre) %>%\n",
    "    summarise(count = n(), .groups = \"drop\")\n",
    "\n",
    "# Conversion en matrice pour la heatmap\n",
    "heatmap_matrix <- reshape2::acast(heatmap_data, playlist_subgenre ~ kmeans_pca_cluster, value.var = \"count\", fill = 0)\n",
    "\n",
    "# Création de la heatmap avec ggplot2 (format long)\n",
    "heatmap_long <- as.data.frame(as.table(heatmap_matrix))\n",
    "colnames(heatmap_long) <- c(\"playlist_subgenre\", \"kmeans_pca_cluster\", \"count\")\n",
    "\n",
    "ggplot(heatmap_long, aes(x = kmeans_pca_cluster, y = playlist_subgenre, fill = count)) +\n",
    "    geom_tile(color = \"white\") +\n",
    "    geom_text(aes(label = count), color = \"black\", size = 10) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "    labs(title = \"Nombre de musiques par sous-genre et par cluster\",\n",
    "         x = \"Cluster\",\n",
    "         y = \"Sous-genre\",\n",
    "         fill = \"Nombre\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 20),\n",
    "          axis.text.y = element_text(size = 20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons mis la distribution des sous-genres dans les clusters. Les observations faites précédemment peuvent aussi s'appliquer sur les sous-genres les plus présents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de Mélange Gaussien (GMM)\n",
    "\n",
    "Le modèle de mélange gaussien (GMM) est une méthode de clustering probabiliste qui permet de modéliser les données comme un mélange de plusieurs distributions gaussiennes. Contrairement à K-Means, GMM peut capturer des formes de clusters plus complexes et des variances différentes entre les clusters.\n",
    "\n",
    "Nous allons appliquer le GMM sur les mêmes données que pour K-Means, en utilisant les trois premières composantes principales de l'ACP. Nous allons également utiliser le critère de BIC pour déterminer le nombre optimal de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Critère BIC pour déterminer le nombre optimal de composantes pour une GMM sur onlysongs_pca_data\n",
    "library(mclust)\n",
    "\n",
    "# Appliquer la GMM sur les données PCA (centrées et réduites)\n",
    "gmm_model <- Mclust(onlysongs_pca_data, G = 1:10)  # G = nombre de clusters testés\n",
    "\n",
    "# Afficher le BIC pour chaque nombre de clusters\n",
    "plot(gmm_model, what = \"BIC\")\n",
    "\n",
    "# Nombre optimal de clusters selon le BIC\n",
    "cat(\"Nombre optimal de clusters selon le BIC :\", gmm_model$G, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous affichons pour le GMM le nombre optimal de clusters. Ici, le nombre de clusters optimal d'après le critère BIC est de 9. Ce choix optimise le critère statistique, mais implique des groupes plus petits et une interprétation potentiellement plus complexe.\n",
    "\n",
    "Nous avons donc décidé de retenir ce nombre de clusters pour la suite de l’analyse, sans chercher à simplifier davantage le modèle. Les analyses et visualisations suivantes seront donc réalisées avec 9 clusters, conformément à l’optimum donné par le BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Appliquer la GMM sur les données PCA (centrées et réduites) avec 9 clusters\n",
    "#Applique le modèle VEI (variance égale, covariance identique) sur les données PCA\n",
    "gmm_9 <- Mclust(onlysongs_pca_data, G = 9, modelNames = \"VEI\")  # G = nombre de clusters\n",
    "\n",
    "# Ajouter les labels de cluster GMM au dataset onlysongs\n",
    "onlysongs$gmm_cluster <- as.factor(gmm_9$classification)\n",
    "\n",
    "# Afficher un résumé du modèle GMM\n",
    "summary(gmm_9)\n",
    "\n",
    "# Afficher la répartition des chansons par cluster GMM\n",
    "table(onlysongs$gmm_cluster)\n",
    "\n",
    "# Affichage des clusters GMM sur les dimensions principales 1-2 sans ellipses, juste des points colorés\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             geom = \"point\", \n",
    "             col.ind = onlysongs$gmm_cluster, \n",
    "             palette = \"jco\", \n",
    "             addEllipses = TRUE, # Pas d'ellipses\n",
    "             pointshape = 19, \n",
    "             pointsize = 2, \n",
    "             alpha.ind = 0.7) +\n",
    "  labs(title = \"GMM (k=9) sur ACP onlysongs (projection Dim 1-2) - sans ellipses\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme précédemment, les clusters ne semblent pas très bien se séparer sur le premier plan de l'ACP. On va afficher les boxplots des caractéristiques pour voir si nous trouvons des profils type dans nos clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Affichage des boxplots des variables quantitatives par cluster GMM\n",
    "\n",
    "# Sélection des variables quantitatives à visualiser\n",
    "quant_vars <- c(\"track_popularity\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\")\n",
    "\n",
    "# Fusionner les clusters GMM avec onlysongs pour avoir les variables quantitatives et le cluster\n",
    "onlysongs_gmm_long <- melt(\n",
    "    onlysongs[, c(\"gmm_cluster\", quant_vars)],\n",
    "    id.vars = \"gmm_cluster\"\n",
    ")\n",
    "\n",
    "# Affichage des boxplots pour chaque variable par cluster GMM\n",
    "ggplot(onlysongs_gmm_long, aes(x = gmm_cluster, y = value, fill = gmm_cluster)) +\n",
    "    geom_boxplot(outlier.size = 0.5) +\n",
    "    facet_wrap(~ variable, scales = \"free_y\") +\n",
    "    labs(title = \"Boxplots des variables quantitatives par cluster GMM\",\n",
    "         x = \"Cluster GMM\", y = \"Valeur\") +\n",
    "    theme_minimal() +\n",
    "    theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons essayer de trouver des caractéristiques des différents clusters en utilisant ces boxplots.\n",
    "- Cluster 1 : Basse energy mais haute acousticness (cohérent car corrélation négative)\n",
    "- Cluster 2 : Haute instrumentalness, haute energy\n",
    "- Cluster 3 : Haute valence, haute dancebility\n",
    "- Cluster 4 : Haute speechiness\n",
    "- Cluster 5 : Plus haut tempo que les autres clusters (sauf cluster 1), basse energy\n",
    "- Cluster 6 : Intrumentalness moyenne, haute energy\n",
    "- Cluster 7 : Basse danceability, haute loudness\n",
    "- Cluster 8 : Haute instrumentalness\n",
    "- Cluster 9 : Haute liveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fusionner les clusters GMM avec les données song (sur track_name et track_artist)\n",
    "song_with_gmm_cluster <- song %>%\n",
    "    left_join(onlysongs[, c(\"track_name\", \"track_artist\", \"gmm_cluster\")], \n",
    "              by = c(\"track_name\", \"track_artist\"))\n",
    "\n",
    "# Afficher un aperçu du résultat\n",
    "head(song_with_gmm_cluster[, c(\"track_name\", \"track_artist\", \"gmm_cluster\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#création d'une table de contingence : nombre de musiques par genre et par cluster\n",
    "heatmap_data_gmm <- song_with_gmm_cluster %>%\n",
    "    group_by(gmm_cluster, playlist_genre) %>%\n",
    "    summarise(count = n(), .groups = \"drop\")\n",
    "\n",
    "# Conversion en matrice pour la heatmap\n",
    "heatmap_matrix_gmm <- reshape2::acast(heatmap_data_gmm, playlist_genre ~ gmm_cluster, value.var = \"count\", fill = 0)\n",
    "\n",
    "# Création de la heatmap avec ggplot2 (format long)\n",
    "heatmap_long_gmm <- as.data.frame(as.table(heatmap_matrix_gmm))\n",
    "colnames(heatmap_long_gmm) <- c(\"playlist_genre\", \"gmm_cluster\", \"count\")\n",
    "ggplot(heatmap_long_gmm, aes(x = gmm_cluster, y = playlist_genre, fill = count)) +\n",
    "    geom_tile(color = \"white\") +\n",
    "    geom_text(aes(label = count), color = \"black\", size = 10) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "    labs(title = \"Nombre de musiques par genre et par cluster GMM\",\n",
    "         x = \"Cluster\",\n",
    "         y = \"Sous-genre\",\n",
    "         fill = \"Nombre\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 20),\n",
    "          axis.text.y = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'une table de contingence : nombre de musiques par sous-genre et par cluster GMM\n",
    "heatmap_data_gmm <- song_with_gmm_cluster %>%\n",
    "    filter(!is.na(gmm_cluster)) %>%\n",
    "    group_by(gmm_cluster, playlist_subgenre) %>%\n",
    "    summarise(count = n(), .groups = \"drop\")\n",
    "\n",
    "# Conversion en matrice pour la heatmap\n",
    "heatmap_matrix_gmm <- reshape2::acast(heatmap_data_gmm, playlist_subgenre ~ gmm_cluster, value.var = \"count\", fill = 0)\n",
    "\n",
    "# Format long pour ggplot2\n",
    "heatmap_long_gmm <- as.data.frame(as.table(heatmap_matrix_gmm))\n",
    "colnames(heatmap_long_gmm) <- c(\"playlist_subgenre\", \"gmm_cluster\", \"count\")\n",
    "\n",
    "ggplot(heatmap_long_gmm, aes(x = gmm_cluster, y = playlist_subgenre, fill = count)) +\n",
    "    geom_tile(color = \"white\") +\n",
    "    geom_text(aes(label = count), color = \"black\", size = 10) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "    labs(title = \"Nombre de musiques par sous-genre et par cluster GMM\",\n",
    "         x = \"Cluster GMM\",\n",
    "         y = \"Sous-genre\",\n",
    "         fill = \"Nombre\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 20),\n",
    "          axis.text.y = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons essayer avec ces tables de contingence de lier l'analyse des propriétés des clusters avec les sous-genres de musiques.\n",
    "- Cluster 1 : Neo Soul, urban contemporary et indie poptism, donc haute acousticness cohérente\n",
    "- Cluster 2 : Progressive Electro House, electro house, qui est un style avec beaucoup d'energy\n",
    "- Cluster 3 : Latin hip hop, latin pop, reggaeton, sont bien des musiques très dansantes, très positives\n",
    "- Cluster 4 : Gangster rap, southern hip hop, hip hop, style de musique très parlée\n",
    "- Cluster 5 : New jack swing, neo soul, classic rock, urban contemporary, pas énormément de lien avec une basse energy mais pas incohérent\n",
    "- Cluster 6 : Electro house, progressive electro house, bien caractérisé par des musiques énergiques\n",
    "- Cluster 7 : Hard rock, progresive electro house, pop edm, qui sont bien des musiques bruyantes et peu dansantes\n",
    "- Cluster 8 : Progressive Electro House, electro house, très similaire au cluster 2\n",
    "- Cluster 9 : Album rock, qui peut être des musiques issues de concerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ensuite décidé de faire une méthode de clustering CAH, en traçant un dendrogramme par lien de Ward sur un échantillon de 10000 musiques prises aléatoirement. Avec la totalité de l'effectif, le temps de calcul est très long, nous avons donc pris la décision de ne faire ce clustering que sur un tiers des données, en espérant avoir des résultats tout de même concluants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Échantillonnage aléatoire de 10000 morceaux pour accélérer la CAH\n",
    "set.seed(42)\n",
    "sample_indices <- sample(nrow(onlysongs_pca_data), min(10000, nrow(onlysongs_pca_data)))\n",
    "onlysongs_pca_sample <- onlysongs_pca_data[sample_indices, ]\n",
    "\n",
    "# Calcul de la matrice de distance euclidienne\n",
    "dist_mat <- dist(onlysongs_pca_sample, method = \"euclidean\")\n",
    "\n",
    "# CAH avec la méthode de Ward\n",
    "cah_ward <- hclust(dist_mat, method = \"ward.D2\")\n",
    "\n",
    "# Affichage du dendrogramme\n",
    "plot(cah_ward, labels = FALSE, main = \"Dendrogramme CAH (Ward)\", xlab = \"\", sub = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ne pouvons pas vraiment interpréter à vue d'oeil ce dendrogramme. Pour le couper ici, on devrait choisir l'endroit où nous avons le plus grand saut, en l'occurence à 2 clusters. Malgré tout, nous avons décidé de choisir 3 clusters, ce qui reste un grand saut. Aussi, nous avons fait ce choix pour garder une cohérence avec le notebook Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Appliquer la CAH sur l'échantillon et assigner les clusters uniquement à cet échantillon\n",
    "n_clusters <- 3\n",
    "ward_clusters_sample <- cutree(cah_ward, k = n_clusters)\n",
    "\n",
    "# Créer un vecteur de clusters pour tous les individus (NA par défaut)\n",
    "ward_cluster_full <- rep(NA, nrow(onlysongs))\n",
    "ward_cluster_full[sample_indices] <- ward_clusters_sample\n",
    "onlysongs$ward_cluster <- as.factor(ward_cluster_full)\n",
    "\n",
    "# Visualisation des clusters Ward (sur l'échantillon) sur les deux premières composantes principales de l'ACP\n",
    "fviz_pca_ind(onlysongs_pca, \n",
    "             geom = \"point\", \n",
    "             col.ind = onlysongs$ward_cluster, \n",
    "             palette = \"jco\", \n",
    "             addEllipses = TRUE,\n",
    "             select.ind = list(name = sample_indices)) +\n",
    "  labs(title = \"Classification hiérarchique de Ward (k=3) sur ACP onlysongs (projection Dim 1-2)\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ne pouvons pas non plus avoir une bonne interprétation des clusters dans ce plan, puisque les clusters semblent empilés les uns sur les autres. Par conséquent, comme précédemment, nous allons regarder les caractéritiques de chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fusionner les clusters Ward avec les données song (sur track_name et track_artist)\n",
    "song_with_ward_cluster <- song %>%\n",
    "    left_join(onlysongs[, c(\"track_name\", \"track_artist\", \"ward_cluster\")], \n",
    "              by = c(\"track_name\", \"track_artist\"))\n",
    "# Afficher un aperçu du résultat\n",
    "head(song_with_ward_cluster[, c(\"track_name\", \"track_artist\", \"ward_cluster\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Affichage des boxplots des variables quantitatives par cluster Ward (CAH)\n",
    "\n",
    "# Sélection des variables quantitatives à visualiser\n",
    "quant_vars <- c(\"track_popularity\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\")\n",
    "\n",
    "# Passage au format long pour ggplot, en utilisant les clusters Ward\n",
    "onlysongs_ward_long <- melt(\n",
    "    onlysongs[, c(\"ward_cluster\", quant_vars)],\n",
    "    id.vars = \"ward_cluster\"\n",
    ")\n",
    "\n",
    "# Affichage des boxplots pour chaque variable par cluster Ward, sans les cluster NA\n",
    "onlysongs_ward_long <- onlysongs_ward_long %>%\n",
    "    filter(!is.na(ward_cluster))\n",
    "ggplot(onlysongs_ward_long, aes(x = ward_cluster, y = value, fill = ward_cluster)) +\n",
    "    geom_boxplot(outlier.size = 0.5) +\n",
    "    facet_wrap(~ variable, scales = \"free_y\") +\n",
    "    labs(title = \"Boxplots des variables quantitatives par cluster Ward (CAH)\",\n",
    "         x = \"Cluster Ward\", y = \"Valeur\") +\n",
    "    theme_minimal() +\n",
    "    theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, on ne voit pas de grandes différences entre les clusters avec cette méthode. Elle ne semble pas vraiment concluante par rapport aux deux autres. Malgré tout, la plus grande différence se remarque entre les tempos, ce qui n'est pas très intéressant à analyser pour caractériser des styles de musiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#création d'une table de contingence : nombre de musiques par genre et par cluster\n",
    "heatmap_data_ward <- song_with_ward_cluster %>%\n",
    "    group_by(ward_cluster, playlist_genre) %>%\n",
    "    summarise(count = n(), .groups = \"drop\")\n",
    "\n",
    "# Conversion en matrice pour la heatmap\n",
    "heatmap_matrix_ward <- reshape2::acast(heatmap_data_ward, playlist_genre ~ ward_cluster, value.var = \"count\", fill = 0)\n",
    "\n",
    "# Création de la heatmap avec ggplot2 (format long)\n",
    "heatmap_long_ward <- as.data.frame(as.table(heatmap_matrix_ward))\n",
    "colnames(heatmap_long_ward) <- c(\"playlist_genre\", \"ward_cluster\", \"count\")\n",
    "\n",
    "ggplot(heatmap_long_ward, aes(x = ward_cluster, y = playlist_genre, fill = count)) +\n",
    "    geom_tile(color = \"white\") +\n",
    "    geom_text(aes(label = count), color = \"black\", size = 10) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "    labs(title = \"Nombre de musiques par genre et par cluster Ward\",\n",
    "         x = \"Cluster\",\n",
    "         y = \"Sous-genre\",\n",
    "         fill = \"Nombre\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 20),\n",
    "          axis.text.y = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'une table de contingence : nombre de musiques par sous-genre et par cluster Ward\n",
    "heatmap_data_ward <- song_with_ward_cluster %>%\n",
    "    group_by(ward_cluster, playlist_subgenre) %>%\n",
    "    summarise(count = n(), .groups = \"drop\")\n",
    "\n",
    "# Conversion en matrice pour la heatmap\n",
    "heatmap_matrix_ward <- reshape2::acast(heatmap_data_ward, playlist_subgenre ~ ward_cluster, value.var = \"count\", fill = 0)\n",
    "\n",
    "# Format long pour ggplot2\n",
    "heatmap_long_ward <- as.data.frame(as.table(heatmap_matrix_ward))\n",
    "colnames(heatmap_long_ward) <- c(\"playlist_subgenre\", \"ward_cluster\", \"count\")\n",
    "\n",
    "ggplot(heatmap_long_ward, aes(x = ward_cluster, y = playlist_subgenre, fill = count)) +\n",
    "    geom_tile(color = \"white\") +\n",
    "    geom_text(aes(label = count), color = \"black\", size = 10) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "    labs(title = \"Nombre de musiques par sous-genre et par cluster Ward\",\n",
    "         x = \"Cluster Ward\",\n",
    "         y = \"Sous-genre\",\n",
    "         fill = \"Nombre\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 20),\n",
    "          axis.text.y = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce manque de distinction se retrouve à nouveau dans la répartition des styles de musiques dans les clusters, où on ne voit pas de style qui ressort plus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des méthodes de clustering\n",
    "\n",
    "Dans cette partie, nous appliquons une Analyse des Correspondances Multiples (MCA) pour comparer les résultats des différentes méthodes de clustering (K-Means, GMM, CAH). \n",
    "L’objectif est de visualiser les clusters obtenus par chaque méthode dans un espace factoriel commun, afin d’évaluer leur cohérence et leur séparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Réduction des modalités rares pour 'track_artist'\n",
    "freq_artists <- table(song$track_artist)\n",
    "top_artists <- names(freq_artists[freq_artists > 100])\n",
    "song$track_artist_reduced <- ifelse(song$track_artist %in% top_artists, as.character(song$track_artist), \"Other\")\n",
    "\n",
    "# Réduction des modalités rares pour 'track_album_name'\n",
    "freq_albums <- table(song$track_album_name)\n",
    "top_albums <- names(freq_albums[freq_albums > 100])\n",
    "song$track_album_name_reduced <- ifelse(song$track_album_name %in% top_albums, as.character(song$track_album_name), \"Other\")\n",
    "\n",
    "# Colonnes catégorielles à utiliser pour la MCA\n",
    "cols_cat_reduced <- c(\"track_artist_reduced\", \"track_album_name_reduced\", \"playlist_name\", \n",
    "                      \"playlist_genre\", \"playlist_subgenre\", \"key\", \"mode\")\n",
    "\n",
    "# Prendre un échantillon pour limiter la mémoire\n",
    "set.seed(42)\n",
    "sample_indices <- sample(nrow(song), 5000)\n",
    "data_sample <- song[sample_indices, ]\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "colSums(is.na(data_sample[, cols_cat_reduced]))\n",
    "\n",
    "# Nettoyer et convertir en facteur\n",
    "data_sample_clean <- data_sample[, cols_cat_reduced]\n",
    "data_sample_clean[] <- lapply(data_sample_clean, as.factor)\n",
    "\n",
    "# MCA avec FactoMineR\n",
    "mca <- MCA(data_sample_clean, ncp = 2, graph = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(cluster)\n",
    "library(mclust)\n",
    "library(factoextra)\n",
    "\n",
    "# Récupérer les coordonnées MCA correctement\n",
    "X <- mca$ind$coord[, 1:2]  # Utiliser les coordonnées des individus de la MCA\n",
    "\n",
    "# KMeans avec 5 clusters\n",
    "set.seed(42)\n",
    "kmeans_res <- kmeans(X, centers = 5, nstart = 25)\n",
    "labels_kmeans <- kmeans_res$cluster\n",
    "\n",
    "# GMM avec 10 clusters\n",
    "gmm_res <- Mclust(X, G = 10)\n",
    "labels_gmm <- gmm_res$classification\n",
    "\n",
    "# CAH avec 3 clusters\n",
    "hc <- hclust(dist(X), method = \"ward.D2\")\n",
    "labels_cah <- cutree(hc, k = 3)\n",
    "\n",
    "# Calcul des scores silhouette\n",
    "sil_kmeans <- silhouette(labels_kmeans, dist(X))\n",
    "sil_gmm <- silhouette(labels_gmm, dist(X))\n",
    "sil_cah <- silhouette(labels_cah, dist(X))\n",
    "\n",
    "cat(\"KMeans (5) Silhouette:\", mean(sil_kmeans[, 3]), \"\\n\")\n",
    "cat(\"GMM (10) Silhouette:\", mean(sil_gmm[, 3]), \"\\n\")\n",
    "cat(\"CAH (3) Silhouette:\", mean(sil_cah[, 3]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec analyse des silhouette scores pour les différentes méthodes de clustering que nous avons utilisées, la méthode présentant le meilleur score est K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des indices de validation pour chaque méthode\n",
    "library(clusterCrit)\n",
    "\n",
    "# Silhouette déjà calculé précédemment\n",
    "silhouette_scores <- c(\n",
    "    mean(silhouette(labels_kmeans, dist(X))[, 3]),\n",
    "    mean(silhouette(labels_gmm, dist(X))[, 3]),\n",
    "    mean(silhouette(labels_cah, dist(X))[, 3])\n",
    ")\n",
    "\n",
    "# Calinski-Harabasz et Davies-Bouldin\n",
    "ch_scores <- c(\n",
    "    intCriteria(X, as.integer(labels_kmeans), c(\"Calinski_Harabasz\"))$calinski_harabasz,\n",
    "    intCriteria(X, as.integer(labels_gmm), c(\"Calinski_Harabasz\"))$calinski_harabasz,\n",
    "    intCriteria(X, as.integer(labels_cah), c(\"Calinski_Harabasz\"))$calinski_harabasz\n",
    ")\n",
    "db_scores <- c(\n",
    "    intCriteria(X, as.integer(labels_kmeans), c(\"Davies_Bouldin\"))$davies_bouldin,\n",
    "    intCriteria(X, as.integer(labels_gmm), c(\"Davies_Bouldin\"))$davies_bouldin,\n",
    "    intCriteria(X, as.integer(labels_cah), c(\"Davies_Bouldin\"))$davies_bouldin\n",
    ")\n",
    "\n",
    "# Data frame des scores\n",
    "df_scores <- data.frame(\n",
    "    Méthode = c(\"KMeans (5)\", \"GMM (10)\", \"CAH (3)\"),\n",
    "    Silhouette = round(silhouette_scores, 3),\n",
    "    Calinski_Harabasz = round(ch_scores, 3),\n",
    "    Davies_Bouldin = round(db_scores, 3)\n",
    ")\n",
    "\n",
    "\n",
    "# Préparer les données pour ggplot\n",
    "plot_data <- data.frame(\n",
    "    X1 = X[, 1], X2 = X[, 2],\n",
    "    KMeans = as.factor(labels_kmeans),\n",
    "    GMM = as.factor(labels_gmm),\n",
    "    CAH = as.factor(labels_cah)\n",
    ")\n",
    "\n",
    "p1 <- ggplot(plot_data, aes(x = X1, y = X2, color = KMeans)) +\n",
    "    geom_point(size = 1) +\n",
    "    labs(title = \"KMeans (5 clusters)\", x = \"MCA Dim 1\", y = \"MCA Dim 2\") +\n",
    "    theme_minimal() + theme(legend.position = \"none\")\n",
    "\n",
    "p2 <- ggplot(plot_data, aes(x = X1, y = X2, color = GMM)) +\n",
    "    geom_point(size = 1) +\n",
    "    labs(title = \"GMM (10 clusters)\", x = \"MCA Dim 1\", y = \"MCA Dim 2\") +\n",
    "    theme_minimal() + theme(legend.position = \"none\")\n",
    "\n",
    "p3 <- ggplot(plot_data, aes(x = X1, y = X2, color = CAH)) +\n",
    "    geom_point(size = 1) +\n",
    "    labs(title = \"CAH (3 clusters)\", x = \"MCA Dim 1\", y = \"MCA Dim 2\") +\n",
    "    theme_minimal() + theme(legend.position = \"none\")\n",
    "\n",
    "options(repr.plot.width=40, repr.plot.height=20)\n",
    "p1 <- p1 + coord_fixed()\n",
    "p2 <- p2 + coord_fixed()\n",
    "p3 <- p3 + coord_fixed()\n",
    "\n",
    "grid.arrange(p1, p2, p3, ncol = 3)\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En visualisant la projection de nos clusters dans les dimensions de la MCA, nous pouvons également voir que la méthode K-means semble être la meilleure méthode de clustering.\n",
    "En effet, les points semblent se répartir en 5 groupes de points, et ces groupes sont mieux représentés sur le K-means.\n",
    "\n",
    "Pour la méthode GMM, certains groupements ne semblent pas présenter le même nombre de points, ce qui est un point négatif dans la répartition en clusters.\n",
    "\n",
    "Pour la méthode CAH, il y a trop peu de clusters pour que les groupes soient bien clusterisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Analyse des Correspondances (CA) entre clusters KMeans, sous-genres et genres\n",
    "\n",
    "# Table de contingence : cluster KMeans x sous-genre x genre\n",
    "\n",
    "# Table cluster x sous-genre\n",
    "tab_cluster_subgenre <- table(song_with_cluster_noNA$kmeans_pca_cluster, song_with_cluster_noNA$playlist_subgenre)\n",
    "# Table cluster x genre\n",
    "tab_cluster_genre <- table(song_with_cluster_noNA$kmeans_pca_cluster, song_with_cluster_noNA$playlist_genre)\n",
    "\n",
    "# CA sur cluster x sous-genre\n",
    "ca_subgenre <- CA(tab_cluster_subgenre, graph = FALSE)\n",
    "# CA sur cluster x genre\n",
    "ca_genre <- CA(tab_cluster_genre, graph = FALSE)\n",
    "\n",
    "# Préparation des données pour ggplot (CA cluster x sous-genre)\n",
    "coord_cluster <- as.data.frame(ca_subgenre$row$coord)\n",
    "coord_cluster$Type <- \"Cluster\"\n",
    "coord_cluster$Label <- rownames(coord_cluster)\n",
    "\n",
    "coord_subgenre <- as.data.frame(ca_subgenre$col$coord)\n",
    "coord_subgenre$Type <- \"Sous-genre\"\n",
    "coord_subgenre$Label <- rownames(coord_subgenre)\n",
    "\n",
    "coord_genre <- as.data.frame(ca_genre$col$coord)\n",
    "coord_genre$Type <- \"Genre\"\n",
    "coord_genre$Label <- rownames(coord_genre)\n",
    "\n",
    "plot_data <- rbind(\n",
    "    coord_cluster[, c(\"Dim 1\", \"Dim 2\", \"Type\", \"Label\")],\n",
    "    coord_subgenre[, c(\"Dim 1\", \"Dim 2\", \"Type\", \"Label\")],\n",
    "    coord_genre[, c(\"Dim 1\", \"Dim 2\", \"Type\", \"Label\")]\n",
    ")\n",
    "\n",
    "# Couleurs pour chaque type\n",
    "type_colors <- c(\"Cluster\" = \"#E41A1C\", \"Sous-genre\" = \"#377EB8\", \"Genre\" = \"#4DAF4A\")\n",
    "\n",
    "# Affichage du graphique\n",
    "ggplot(plot_data, aes(x = `Dim 1`, y = `Dim 2`, color = Type, shape = Type)) +\n",
    "    geom_point(size = 8, alpha = 0.8) +\n",
    "    geom_text(aes(label = Label), size = 7, vjust = -1, fontface = \"bold\") +\n",
    "    scale_color_manual(values = type_colors) +\n",
    "    scale_shape_manual(values = c(16, 17, 15)) +\n",
    "    labs(title = \"Analyse des Correspondances : Clusters KMeans, Sous-genres et Genres\",\n",
    "             x = \"Dimension 1\", y = \"Dimension 2\", color = \"Type\", shape = \"Type\") +\n",
    "    theme_minimal(base_size = 22) +\n",
    "    theme(legend.position = \"top\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ici décidé de nous concentrer sur la représentation CA de la méthode de clustering la plus performante, qui est la méthode K-means.\n",
    "\n",
    "On retrouve dans cette représentation les résultats que nous avons obtenu lors de l'analyse des tableaux de contingence de cette méthode.\n",
    "\n",
    "- Cluster 1 : Proche du style EDM, notamment des sous-genres progressive electro house et electro house. Aussi proche du sous-genre big room, que nous ne voyions pas dans le tableau.\n",
    "- Cluster 2 : Proche du R&B, mais aussi un peu du style latin, avec les sous-genres latin pop et new jack swing, qui n'était pas les plus importantes dans la tableau. En revanche, nous retrouvons bien les styles neo soul et urban contemporary.\n",
    "- Cluster 3 : A nouveau, plus proche des styles EDM, rock et pop. Très proche de l'hard rock.\n",
    "- Cluster 4 : Proche du rap, notamment du southern hip hop et du gangster rap.\n",
    "- Cluster 5 : Dans le tableau de contingence, ce cluster contenant beaucoup de style de musiques. Cela se retrouve également dans la CA, mais le cluster est plus proche du style latin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant appliquer une analyse discriminante linéaire (LDA) pour tenter de prédire les genres musicaux à partir des caractéristiques audio des morceaux. LDA est une méthode de classification qui cherche à maximiser la séparation entre les classes en projetant les données dans un espace de dimension inférieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sélection des variables quantitatives et de la variable cible (playlist_genre) pour la LDA\n",
    "library(MASS)\n",
    "library(dplyr)\n",
    "\n",
    "lda_data <- song %>%\n",
    "  dplyr::select(playlist_genre, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_s, track_popularity)\n",
    "\n",
    "#Normalisation des variables quantitatives\n",
    "lda_data[, -1] <- scale(lda_data[, -1])\n",
    "\n",
    "# S'assurer que la variable cible est un facteur\n",
    "lda_data$playlist_genre <- as.factor(lda_data$playlist_genre)\n",
    "\n",
    "# Appliquer la LDA\n",
    "lda_model <- lda(playlist_genre ~ ., data = lda_data)\n",
    "\n",
    "# Prédire les coordonnées des individus sur les axes discriminants\n",
    "lda_pred <- predict(lda_model)\n",
    "\n",
    "# Afficher un résumé du modèle LDA\n",
    "print(lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons dans un premier temps que les genres de musiques sont représentés à peu près dans la même proportion, mais le style EDM suivi du rap restent les styles de musiques les plus présents.\n",
    "\n",
    "Après normalisation des données, nous pouvons voir que certaines caractéritiques semblent caractériser certains style de musiques :\n",
    "- edm : Haute energy,  basse acousticness\n",
    "- latin : Haute danceability, haute valence\n",
    "- pop : Pas vraiment de caractéristiques qui se démarquent du reste\n",
    "- r&b : Basse energy, haute acousticness\n",
    "- rap : Haute danceability, haute speechiness\n",
    "- rock : Basse danceability, basse speechiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lda_df <- data.frame(lda_pred$x, playlist_genre = lda_data$playlist_genre)\n",
    "\n",
    "# Calcul des barycentres pour chaque genre\n",
    "centroids <- lda_df %>%\n",
    "       group_by(playlist_genre) %>%\n",
    "       summarise(LD1 = mean(LD1), LD2 = mean(LD2))\n",
    "\n",
    "# Calcul des coefficients des variables (loadings) pour LD1 et LD2\n",
    "lda_loadings <- as.data.frame(lda_model$scaling[, 1:2])\n",
    "lda_loadings$variable <- rownames(lda_loadings)\n",
    "colnames(lda_loadings)[1:2] <- c(\"LD1\", \"LD2\")\n",
    "\n",
    "# Mise à l'échelle des flèches pour une meilleure visibilité\n",
    "arrow_scale <- 2\n",
    "lda_loadings$LD1 <- lda_loadings$LD1 * arrow_scale\n",
    "lda_loadings$LD2 <- lda_loadings$LD2 * arrow_scale\n",
    "\n",
    "# Affichage du scatterplot avec barycentres et flèches des variables\n",
    "ggplot(lda_df, aes(x = LD1, y = LD2, color = playlist_genre)) +\n",
    "       geom_point(alpha = 0.5) +\n",
    "       geom_point(data = centroids, aes(x = LD1, y = LD2, fill = playlist_genre), \n",
    "                        size = 8, shape = 21, color = \"black\", show.legend = FALSE, inherit.aes = FALSE) +\n",
    "       geom_text(data = centroids, aes(x = LD1, y = LD2, label = playlist_genre), \n",
    "                       color = \"black\", size = 5, vjust = -1, inherit.aes = FALSE) +\n",
    "       geom_segment(data = lda_loadings, aes(x = 0, y = 0, xend = LD1, yend = LD2),\n",
    "                             arrow = arrow(length = unit(0.3, \"cm\")), color = \"black\", inherit.aes = FALSE) +\n",
    "       geom_text(data = lda_loadings, aes(x = LD1, y = LD2, label = variable),\n",
    "                       color = \"black\", size = 5, vjust = 1.2, inherit.aes = FALSE) +\n",
    "       labs(title = \"Projection LDA : individus, barycentres et vecteurs des variables\",\n",
    "               x = \"LD1\", y = \"LD2\", color = \"Genre\") +\n",
    "       theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons projeté les individus sur les premiers axes discriminants de LDA, en ajoutant les barycentres des classes de genre et les variables explicatives. Nous pouvons voir que certains genres se démarquent un peu des autres dans le nuage de points. Nous avons l'EDM qui se distingue plus vers le haut du graphe, le rap en bas à droite et le rock en bas à gauche. Nous pouvons aussi dire que le rap se distingue un peu en bas du nuage. Pour ce qui est de la pop et du latin, comme nous avons vu précédemment, ils ne se distinguent pas vraiment avec des caractéristiques très particulières. Par conséquent, ils sont très au centre et mélangés avec des individus d'autres genres.\n",
    "\n",
    "Nous pouvons aussi lier à certaines caractéristiques nos styles de musique à nouveau. Nos analyses seront très similaires aux précédentes. Le rock se situe à l'opposé de la flèche de danceability et de speechiness, ce n'est donc pas un style ni dansant ni parlé, contrairement au rap. Nous retrouvons l'EDM qui est très instrumental et très énergétique. Le R&B semble être un style plutôt acoustique, et parlé. Finalement pour la pop et le latin, qui se trouvent au centre ddu graphe, ils ne semblent pas faire ressortir de caractéristiques particulières."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ensuite essayé de faire une LDA pour voir si la popularité d'un titre est liée à ses caractéristiques intrinsèques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# LDA pour estimer la popularité à partir des variables quantitatives\n",
    "library(MASS)\n",
    "library(dplyr)\n",
    "\n",
    "# Création d'une variable catégorielle de popularité (par exemple, 5 classes : 0;20 , 20;40, 40;60, 60;80, 80;100)\n",
    "song$popularity_class <- cut(\n",
    "    song$track_popularity,\n",
    "    breaks = quantile(song$track_popularity, probs = seq(0, 1, by = 0.2)),\n",
    "    labels = c(\"Très faible\", \"Faible\", \"Moyenne\", \"Forte\", \"Très forte\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Sélection des variables quantitatives et de la variable cible\n",
    "lda_pop_data <- song %>%\n",
    "    dplyr::select(popularity_class, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_s)\n",
    "\n",
    "# Normalisation des variables quantitatives\n",
    "lda_pop_data[, -1] <- scale(lda_pop_data[, -1])\n",
    "\n",
    "# S'assurer que la variable cible est un facteur\n",
    "lda_pop_data$popularity_class <- as.factor(lda_pop_data$popularity_class)\n",
    "\n",
    "# Appliquer la LDA\n",
    "lda_pop_model <- lda(popularity_class ~ ., data = lda_pop_data)\n",
    "\n",
    "# Afficher un résumé du modèle LDA\n",
    "print(lda_pop_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A première vue, il n'y pas de caractéristiques quantitatives qui permettent à des musiques plus ou moins populaires de se distinguer des autres. Nous allons malgré tout regarder si la projection des individus sur le premier plan de la LDA permet d'avoir des résultats plus concluants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Scatterplot des axes LDA (premiers axes discriminants)\n",
    "lda_pop_pred <- predict(lda_pop_model)\n",
    "lda_pop_df <- as.data.frame(lda_pop_pred$x)\n",
    "lda_pop_df$popularity_class <- lda_pop_data$popularity_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des barycentres pour chaque classe de popularité\n",
    "centroids_pop <- lda_pop_df %>%\n",
    "    group_by(popularity_class) %>%\n",
    "    summarise(LD1 = mean(LD1), LD2 = mean(LD2))\n",
    "\n",
    "# Calcul des coefficients des variables (loadings) pour LD1 et LD2\n",
    "lda_pop_loadings <- as.data.frame(lda_pop_model$scaling[, 1:2])\n",
    "lda_pop_loadings$variable <- rownames(lda_pop_loadings)\n",
    "colnames(lda_pop_loadings)[1:2] <- c(\"LD1\", \"LD2\")\n",
    "\n",
    "# Mise à l'échelle des flèches pour une meilleure visibilité\n",
    "arrow_scale <- 2\n",
    "lda_pop_loadings$LD1 <- lda_pop_loadings$LD1 * arrow_scale\n",
    "lda_pop_loadings$LD2 <- lda_pop_loadings$LD2 * arrow_scale\n",
    "\n",
    "# Affichage du scatterplot avec barycentres et flèches des variables\n",
    "ggplot(lda_pop_df, aes(x = LD1, y = LD2, color = popularity_class)) +\n",
    "    geom_point(alpha = 0.5) +\n",
    "    geom_point(data = centroids_pop, aes(x = LD1, y = LD2, fill = popularity_class), \n",
    "               size = 8, shape = 21, color = \"black\", show.legend = FALSE, inherit.aes = FALSE) +\n",
    "    geom_text(data = centroids_pop, aes(x = LD1, y = LD2, label = popularity_class), \n",
    "              color = \"black\", size = 5, vjust = -1, inherit.aes = FALSE) +\n",
    "    geom_segment(data = lda_pop_loadings, aes(x = 0, y = 0, xend = LD1, yend = LD2),\n",
    "                 arrow = arrow(length = unit(0.3, \"cm\")), color = \"black\", inherit.aes = FALSE) +\n",
    "    geom_text(data = lda_pop_loadings, aes(x = LD1, y = LD2, label = variable),\n",
    "              color = \"black\", size = 5, vjust = 1.2, inherit.aes = FALSE) +\n",
    "    labs(title = \"Projection LDA (popularité) : individus, barycentres et vecteurs des variables\",\n",
    "         x = \"LD1\", y = \"LD2\", color = \"Popularité\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, après projection sur les dimensions de la LDA, et en plaçant les barycentres des classes de popularité, les individus restent très proches les uns des autres. A première vue, on pourrait penser que les musiques plus populaires sont bruyantes et peu énergétiques, mais le graphe ne permet pas une distinction assez précises pour arriver à cette conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Système de recommandation\n",
    "\n",
    "### Objectif\n",
    "L'objectif de cette section est de développer un système de recommandation basé sur les profils musicaux latents identifiés par la NMF. Ce système permettra de :\n",
    "\n",
    "1. Recommander des **morceaux à ajouter à une playlist existante** en analysant son profil musical global\n",
    "2. Suggérer des **chansons similaires à un morceau spécifique choisi** par l'utilisateur\n",
    "\n",
    "### Méthodologie\n",
    "En se basant sur les 6 profils latents extraits (instrumental, énergique-intense, live, émotionnel-valence, acoustique-chant, rap-rythmé), le système calcule des mesures de similarité pour proposer des recommandations personnalisées et pertinentes.\n",
    "\n",
    "1. **Extraction des profils latents** : Utilisation des 6 profils musicaux latents identifiés par la NMF.\n",
    "2. **Calcul de similarité** : Mesures de similarité entre les morceaux ou le profil moyen d'une playlist et les profils latents pour déterminer les recommandations.\n",
    "3. **Recommandation personnalisée** : Proposer des morceaux en fonction des similarités calculées.\n",
    "\n",
    "Nous commençons par effectuer une recommandation à partir d'une playlist spécfique. Pour cela, nous allons utiliser une fonction qui prend en entrée une playlist et renvoie les morceaux similaires en fonction de leur profil musical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Système de recommandation basé sur les profils NMF\n",
    "\n",
    "# 1. Ajouter les profils NMF comme colonnes au dataframe original\n",
    "song_with_profiles <- song\n",
    "song_with_profiles[, paste0(\"profile_\", 1:6)] <- W_6\n",
    "\n",
    "# 2. Fonction pour recommander des chansons basées sur une playlist\n",
    "recommend_songs <- function(playlist_name, num_recommendations = 3) {\n",
    "    # Vérifier si la playlist existe\n",
    "    if(!(playlist_name %in% song_with_profiles$playlist_name)) {\n",
    "        stop(\"Playlist non trouvée dans le dataset\")\n",
    "    }\n",
    "    \n",
    "    # Récupérer les morceaux de la playlist\n",
    "    playlist_songs <- song_with_profiles[song_with_profiles$playlist_name == playlist_name, ]\n",
    "    \n",
    "    # Calculer le profil moyen de la playlist\n",
    "    playlist_profile <- colMeans(playlist_songs[, paste0(\"profile_\", 1:6)])\n",
    "    \n",
    "    # Exclure les morceaux déjà dans la playlist\n",
    "    other_songs <- song_with_profiles[song_with_profiles$playlist_name != playlist_name, ]\n",
    "    \n",
    "    # Calculer la similarité (distance euclidienne) entre le profil de la playlist et chaque morceau\n",
    "    similarities <- apply(other_songs[, paste0(\"profile_\", 1:6)], 1, function(song_profile) {\n",
    "        -sqrt(sum((song_profile - playlist_profile)^2))  # Négative car nous voulons maximiser\n",
    "    })\n",
    "    \n",
    "    # Trier les morceaux par similarité décroissante\n",
    "    other_songs$similarity <- similarities\n",
    "    recommendations <- other_songs[order(other_songs$similarity, decreasing = TRUE), ]\n",
    "    \n",
    "    # Retourner les top N recommandations\n",
    "    return(head(recommendations[, c(\"track_name\", \"track_artist\", \"playlist_genre\", \"playlist_subgenre\", \"similarity\")], num_recommendations))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous allons faire une recommandation de morceaux à ajouter à une playlist existante avec la fonction `recommend_song` qui prend en entrée une playlist et renvoie les morceaux similaires en fonction du profil musical moyen de la playlist.\n",
    "\n",
    "A partir de la playlist EDM House & Dance, nous allons extraire le profil musical moyen de cette playlist et recommander des morceaux similaires en fonction des profils musicaux latents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Exemple d'utilisation\n",
    "# Obtenir les noms de playlists uniques\n",
    "unique_playlists <- unique(song_with_profiles$playlist_name)\n",
    "\n",
    "# Sélectionner une playlist aléatoire pour démonstration\n",
    "set.seed(123)\n",
    "example_playlist <- sample(unique_playlists, 1)\n",
    "\n",
    "# Afficher le nom de la playlist sélectionnée\n",
    "cat(\"Playlist sélectionnée:\", as.character(example_playlist), \"\\n\\n\")\n",
    "\n",
    "# Afficher quelques chansons de la playlist sélectionnée\n",
    "playlist_sample <- song_with_profiles[song_with_profiles$playlist_name == example_playlist, \n",
    "                                                                     c(\"track_name\", \"track_artist\", \"playlist_genre\")]\n",
    "cat(\"Exemple de chansons dans cette playlist:\\n\")\n",
    "print(head(playlist_sample, 3))\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Obtenir les recommandations sous la forme d'un tableau sans les playlist_subgenre\n",
    "recommendations <- recommend_songs(example_playlist, num_recommendations = 3)\n",
    "cat(\"Recommandations de chansons basées sur la playlist sélectionnée:\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme nous propose les morceaux suivants :\n",
    "* Think Before You Talk - Chad Cooper\n",
    "* Make It To Heaven (with Raye) - Rework David Guetta\n",
    "* 2 Hearts (feat. Gia Koka)    Sam Feldt\n",
    "\n",
    "Après écoute, ces morceaux correspondent bien à l'esprit de la playlist EDM House & Dance. Ils sont électroniques, dansants et ont une ambiance similaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Fonction pour recommander à partir d'une chanson spécifique\n",
    "recommend_from_song <- function(track_name, track_artist, num_recommendations = 3) {\n",
    "    # Trouver la chanson dans le dataset\n",
    "    song_idx <- which(song_with_profiles$track_name == track_name & \n",
    "                                        song_with_profiles$track_artist == track_artist)\n",
    "    \n",
    "    if(length(song_idx) == 0) {\n",
    "        stop(\"Chanson non trouvée dans le dataset\")\n",
    "    }\n",
    "    \n",
    "    # Récupérer le profil de la chanson\n",
    "    song_profile <- as.numeric(song_with_profiles[song_idx[1], paste0(\"profile_\", 1:6)])\n",
    "    \n",
    "    # Exclure la chanson elle-même\n",
    "    other_songs <- song_with_profiles[-song_idx, ]\n",
    "    \n",
    "    # Calculer la similarité\n",
    "    similarities <- apply(other_songs[, paste0(\"profile_\", 1:6)], 1, function(profile) {\n",
    "        -sqrt(sum((profile - song_profile)^2))\n",
    "    })\n",
    "    \n",
    "    # Trier par similarité\n",
    "    other_songs$similarity <- similarities\n",
    "    recommendations <- other_songs[order(other_songs$similarity, decreasing = TRUE), ]\n",
    "    \n",
    "    # Retourner les top N recommandations\n",
    "    return(head(recommendations[, c(\"track_name\", \"track_artist\", \"playlist_genre\", \"playlist_subgenre\", \"similarity\")], num_recommendations))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Recommandation pour la chanson \"Thunderstruck\" de \"AC/DC\"\n",
    "track_name <- \"Thunderstruck\"\n",
    "track_artist <- \"AC/DC\"\n",
    "num_recommendations <- 5\n",
    "recommendations <- recommend_from_song(track_name, track_artist, num_recommendations)\n",
    "cat(\"Recommandations pour la chanson 'Thunderstruck' de 'AC/DC':\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme nous propose les morceaux suivants :\n",
    "* Ita - Dyne Side\n",
    "* Summer - Marshmello\n",
    "* Bella Ciao - Hardwell\n",
    "\n",
    "L'algorithme nous renvoie les morceaux les plus similaires au morceau choisi, en se basant sur les profils musicaux latents. Ce sont des morceaux qui partagent des caractéristiques audio avec `Thunderstruck`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet d'analyse de données musicales a permis d'explorer en profondeur un dataset riche de plus de 30 000 morceaux issus de playlists Spotify, en appliquant diverses techniques d'analyse multivariée et d'apprentissage non supervisé.\n",
    "\n",
    "### Apports méthodologiques\n",
    "\n",
    "**Maîtrise d'un pipeline complet d'analyse**  \n",
    "Ce projet nous a permis de développer une expertise transversale en :\n",
    "- **Préparation et nettoyage** de données complexes\n",
    "- **Analyse exploratoire** approfondie avec visualisations avancées\n",
    "- **Application coordonnée** de multiples techniques d'analyse multivariée\n",
    "- **Validation et comparaison** rigoureuse des méthodes de clustering\n",
    "\n",
    "**Expertise en techniques d'analyse multivariée**  \n",
    "Nous avons acquis une maîtrise pratique de :\n",
    "- L'**Analyse en Composantes Principales (ACP)** pour la réduction de dimensionnalité\n",
    "- L'**Analyse des Correspondances Multiples (ACM)** pour les variables qualitatives\n",
    "- La **Factorisation Matricielle Non-Négative (NMF)** pour l'extraction de profils latents\n",
    "- Les **méthodes de clustering** (K-Means, GMM, CAH) avec optimisation des hyperparamètres\n",
    "\n",
    "### Découvertes scientifiques\n",
    "\n",
    "**Structures cachées dans les données musicales**  \n",
    "L'analyse a révélé des **patterns significatifs** :\n",
    "- **6 profils musicaux latents** distincts identifiés par NMF\n",
    "- **Correspondances fortes** entre caractéristiques audio et genres musicaux\n",
    "- **Segmentation naturelle** des morceaux en groupes homogènes\n",
    "\n",
    "**Validation de la cohérence des résultats**  \n",
    "La convergence des différentes méthodes confirme la **robustesse** de nos analyses :\n",
    "- Les clusters correspondent aux genres attendus\n",
    "- Les profils NMF sont musicalement interprétables\n",
    "- La MCA révèle des associations logiques entre variables\n",
    "\n",
    "### Compétences techniques développées\n",
    "\n",
    "**Programmation avancée en Python**  \n",
    "- Manipulation de **pandas** pour les données structurées\n",
    "- Visualisation sophistiquée avec **matplotlib/seaborn**\n",
    "- Implémentation d'algorithmes **scikit-learn** \n",
    "\n",
    "### Applications concrètes\n",
    "\n",
    "Ce projet démontre notre capacité à :\n",
    "- **Transformer** des données brutes en insights exploitables\n",
    "- **Développer** des systèmes de recommandation fonctionnels\n",
    "\n",
    "### Perspectives professionnelles\n",
    "\n",
    "Cette expérience nous prépare à :\n",
    "- **Analyser** tout type de données multidimensionnelles\n",
    "- **Conseiller** sur le choix de méthodes analytiques appropriées\n",
    "- **Communiquer** des résultats techniques\n",
    "\n",
    "Ce projet illustre parfaitement comment l'analyse de données peut révéler des structures cachées dans des domaines complexes, tout en développant une expertise technique solide et une approche méthodologique rigoureuse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
