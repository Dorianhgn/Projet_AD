{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Contexte et objectifs\n",
    "\n",
    "Ce projet analyse un dataset Spotify contenant des caractéristiques audio de milliers de chansons provenant de différents genres musicaux. L'objectif principal est d'explorer la structure des données musicales à travers diverses techniques d'analyse multivariée et de réduction de dimension.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Le dataset comprend des variables quantitatives (danceability, energy, valence, tempo, etc.) et qualitatives (genre, artiste, tonalité, mode) permettant une analyse complète des profils musicaux. Après prétraitement, nous disposons de données sur les caractéristiques audio objectives et les métadonnées descriptives des morceaux.\n",
    "\n",
    "## Approche méthodologique\n",
    "\n",
    "Cette analyse combine plusieurs techniques complémentaires :\n",
    "- **Analyse en Composantes Principales (ACP)** pour explorer les relations entre variables quantitatives et réduire la dimensionnalité\n",
    "- **Analyse des Correspondances Multiples (MCA)** pour étudier les associations entre variables qualitatives (genres, tonalités, modes)\n",
    "- **Analyse Factorielle Multiple (MFA)** pour intégrer simultanément données quantitatives et qualitatives dans une analyse unifiée\n",
    "- **Techniques de réduction non-linéaire** (MDS, t-SNE) pour visualiser la structure complexe des données musicales\n",
    "- **Factorisation Matricielle Non-négative (NMF)** pour identifier des profils musicaux latents et développer un système de recommandation\n",
    "- **Algorithmes de clustering** pour segmenter les morceaux en groupes homogènes selon leurs caractéristiques audio\n",
    "\n",
    "L'objectif est de comprendre comment les caractéristiques musicales s'organisent, identifier des patterns et profils musicaux distincts, et développer des applications pratiques comme un système de recommandation personnalisé basé sur les profils latents découverts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "## Préparation et nettoyage des données\n",
    "\n",
    "Le préprocessing est une étape cruciale qui conditionne la qualité des analyses statistiques ultérieures. Pour ce dataset Spotify, plusieurs transformations sont nécessaires :\n",
    "\n",
    "### Objectifs du préprocessing\n",
    "\n",
    "- **Élimination des variables non pertinentes** : Suppression des identifiants techniques (`track_id`, `album_id`, `playlist_id`) qui n'apportent pas d'information analytique\n",
    "- **Gestion des valeurs manquantes** : Identification et traitement des données incomplètes pour éviter les biais dans les analyses\n",
    "- **Standardisation des types de données** : Conversion des variables catégorielles et temporelles dans les formats appropriés\n",
    "- **Déduplication intelligente** : Conservation des versions les plus populaires des morceaux dupliqués\n",
    "- **Harmonisation des unités** : Conversion de la durée en secondes pour une meilleure interprétabilité\n",
    "\n",
    "### Impact sur les analyses multivariées\n",
    "\n",
    "Un preprocessing rigoureux garantit :\n",
    "- Des résultats d'ACP non biaisés par des échelles de variables hétérogènes\n",
    "- Une MCA cohérente avec des modalités catégorielles bien définies\n",
    "- Des algorithmes de clustering et de réduction de dimension plus performants\n",
    "- Une meilleure généralisation des modèles de recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(gridExtra)\n",
    "library(GGally)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(reshape2)\n",
    "library(FactoMineR) \n",
    "library(factoextra)\n",
    "library(glmnet) \n",
    "library(ggfortify)\n",
    "library(pROC)\n",
    "library(ROCR)\n",
    "library(ggpubr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture des données\n",
    "path <- \"data/\"\n",
    "song <- read.csv(paste0(path, \"spotify_songs.csv\"), header = TRUE, sep = \",\")\n",
    "\n",
    "# Premières lignes du jeu de données\n",
    "head(song)\n",
    "\n",
    "# Vérification du contenu\n",
    "summary(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check the data types\n",
    "str(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the track_id, track_album_id, playlist_id columns\n",
    "song <- song[, -c(1, 5, 9)]\n",
    "\n",
    "# As factor the categorical variables track_artist, playlist_genre, playlist_subgenre, key, mode, playlist_name, track_album_name\n",
    "song$playlist_name <- as.factor(song$playlist_name)\n",
    "song$track_album_name <- as.factor(song$track_album_name)\n",
    "song$track_artist <- as.factor(song$track_artist)\n",
    "song$playlist_genre <- as.factor(song$playlist_genre)\n",
    "song$playlist_subgenre <- as.factor(song$playlist_subgenre)\n",
    "song$key <- factor(song$key, levels = c(-1, 0:11), labels = c(\"No key detected\", \"C\", \"C♯/D♭\", \"D\", \"D♯/E♭\", \"E\", \"F\", \"F♯/G♭\", \"G\", \"G♯/A♭\", \"A\", \"A♯/B♭\", \"B\"))\n",
    "song$mode <- factor(song$mode, levels = c(0, 1), labels = c(\"minor\", \"major\"))\n",
    "\n",
    "# track_album_release_date to date (if the full date is not available, we will use the first day of the year)\n",
    "song$track_album_release_date <- as.Date(ifelse(nchar(song$track_album_release_date) != 10, \n",
    "                                                paste0(substr(song$track_album_release_date, 1, 4), \"-01-01\"), \n",
    "                                                song$track_album_release_date), \n",
    "                                         format = \"%Y-%m-%d\")\n",
    "\n",
    "# Convert the duration_ms to seconds and rename the column to duration_s\n",
    "song$duration_s <- song$duration_ms / 1000\n",
    "song$duration_ms <- NULL\n",
    "\n",
    "# Check the modified dataset\n",
    "summary(song)\n",
    "head(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "colSums(is.na(song))\n",
    "\n",
    "# Drop the missing values\n",
    "song <- na.omit(song)\n",
    "\n",
    "# Check the modified dataset\n",
    "colSums(is.na(song))\n",
    "\n",
    "str(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réduction de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons effectuer une analyse en composantes principales (ACP) sur les données prétraitées. L'ACP est une technique de réduction de dimension qui permet de projeter les données d'origine dans un espace de dimension inférieure. Nous avons gardé 20 variables et nous allons étudier s'il est possible de réduire la dimensionnalité de ces données tout en préservant un maximum d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en Composantes Principales (ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on ne sélectionne que les variables quantitatives, en y ajoutant une variable qualitative (playlist_genre) pour voir si elle a un impact sur la projection des données. On garde au final 11 variables quantitatives et 1 variable qualitative.\n",
    "\n",
    "On décide de normaliser les données avant de faire l'ACP car l'ACP est sensible à l'échelle des variables. On va donc centrer et réduire les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# PCA analysis using FactoMineR\n",
    "song_pca <- song[, c(3, 7, 9:10, 12, 14:20)]\n",
    "\n",
    "# Perform PCA\n",
    "pca <- PCA(song_pca,scale.unit = TRUE, graph = FALSE,ncp = 7,quali.sup = 2)\n",
    "\n",
    "# Afficher le pourcentage de variance expliquée par chaque composante principale\n",
    "fviz_eig(pca, addlabels = TRUE, ylim = c(0, 40))\n",
    "\n",
    "# Calculer la variance cumulée\n",
    "explained_variance <- pca$eig[, 2]  # La deuxième colonne contient le pourcentage de variance expliquée\n",
    "cumulative_variance <- cumsum(explained_variance) \n",
    "\n",
    "# Tracer la variance cumulée\n",
    "plot(cumulative_variance, xlab = \"Nombre de composantes principales\", ylab = \"Variance cumulée\", type = \"b\")\n",
    "abline(h = 80, col = \"red\", lty = 2)  # Ligne horizontale à 80% de variance expliquée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :** \n",
    "\n",
    "L’analyse de la variance expliquée montre que les 7 premières composantes principales permettent de représenter 80,1 % de la variance totale du jeu de données. Cela signifie que l’essentiel de l’information contenue dans les 11 variables numériques initiales (comme danceability, energy, speechiness, tempo, etc.) peut être résumé avec seulement 7 dimensions, ce qui représente une réduction significative de la complexité du dataset tout en conservant une bonne qualité descriptive.\n",
    "\n",
    "Dans cette optique de réduction de dimension, il serait pertinent de conserver ces 7 composantes principales pour la suite des analyses (clustering, visualisation, classification), car elles capturent la structure principale des données tout en éliminant le \"bruit\".\n",
    "\n",
    "Dans l’analyse factorielle, nous avons choisi d’interpréter les trois premières composantes principales, qui à elles seules expliquent 45 % de la variance totale. Elles offrent un bon compromis entre lisibilité et pertinence pour une visualisation ou une première analyse des relations entre les variables et les genres musicaux (playlist_genre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Corrélation des variables\n",
    "corrplot(pca$var$cor, is.corr = FALSE, method = \"ellipse\")\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 1-2\n",
    "fviz_pca_var(pca, axes=c(1,2),col.var = \"contrib\", gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), repel = TRUE) +\n",
    "  labs(title = \"Variables sur le plan factoriel\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 1-3\n",
    "  fviz_pca_var(pca, axes = c(1, 3), col.var = \"contrib\", \n",
    "         gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n",
    "         repel = TRUE) +\n",
    "    labs(title = \"Variables sur le plan factoriel (Dim 1-3)\") +\n",
    "    theme_minimal()\n",
    "\n",
    "# Tracer les variables sur le plan factoriel dim 2-3\n",
    "  fviz_pca_var(pca, axes = c(2, 3), col.var = \"contrib\", \n",
    "         gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n",
    "         repel = TRUE) +\n",
    "    labs(title = \"Variables sur le plan factoriel (Dim 2-3)\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table des correlations et les trois graphiques ci-dessus représentent les projections des features sur les trois premières composantes principales nous donne des informations sur la structure des données réduites.\n",
    "\n",
    "**Composante principale 1 :**\n",
    "    \n",
    "Les variables energy (-0.91), loudness (-0.80) et acousticness (+0.72) sont linéairement corrélées avec la première composante principale, en soulignant que energy et loudness sont inversément corrélées avec acousticness. Cela indique que la CP1 oppose les morceaux énergiques, forts en volume et peu acoustiques (ex : rock, électro) aux morceaux calmes, acoustiques et peu énergétiques (ex : folk, classique).\n",
    "\n",
    "**Composante principale 2 :**\n",
    "\n",
    "Sur le graphique de gauche, on remarque une opposition des variables instrumentalness (+0.45), duration_s (+0.38) contre danceability (-0.68), valence (-0.62), track_popularity (-0.37), speechiness (-0.39).\n",
    "\n",
    "Cette composante principale oppose deux profils de morceaux :\n",
    "    D’un côté, les morceaux instrumentaux, longs et peu populaires (forte contribution de instrumentalness et duration_s), souvent associés à des genres comme le classique ou le jazz.\n",
    "    De l’autre, les chansons courtes, dansantes, joyeuses et populaires (forte contribution de danceability, valence et track_popularity), typiques de la pop ou de la musique de club.\n",
    "    Enfin, cette opposition suggère que les morceaux avec des paroles marquées (speechiness) et une structure rythmique engageante (danceability) sont plus susceptibles de générer de la popularité.\n",
    "\n",
    "**Composantes principales 2 et 3 :**\n",
    "\n",
    "Sur le graphique au centre, on peut extraire plusieurs informations :\n",
    "    Les morceaux dansants et joyeux (haute valence) s'opposent dans une moindre mesure aux morceaux de faible tempo. De plus, ces morceaux semblent avoir peu de versions live.\n",
    "    On observe aussi que les morceaux instrumentaux et longs ont généralement une faible popularité, tandis que les morceaux courts et peu instrumentaux sont souvent plus populaires, ce qui est typique de la musique pop, qui est souvent plus accessible et commerciale.\n",
    "\n",
    "**Composante principale 3 :**\n",
    "\n",
    "La troisième composante (CP3) révèle un paradoxe : elle regroupe des morceaux à fort potentiel dansant (danceability) et mood positif (valence), mais qui restent peu populaires (track_popularity). Ces morceaux sont souvent instrumentaux (instrumentalness), longs (duration_s) et à tempo faible (tempo), ce qui les éloigne des standards des charts. Cette composante pourrait représenter des créations artistiques équilibrant danse et complexité, mais peinant à atteindre un large public.\n",
    "\n",
    "\n",
    "La troisième composante principale met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "Du côté des contributions négatives, on retrouve des titres de pop et R&B calmes et acoustiques comme raindrops (an angel cried) (Ariana Grande) ou You Are The Reason (Calum Scott). Ces chansons ont :\n",
    "\n",
    "    une acousticness élevée (acapela, guitare acoustique, piano),\n",
    "    un tempo légèrement plus rapide que la médiane des morceaux,\n",
    "    une faible énergie, mais un potentiel émotionnel fort (valence variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "Les contributions positives, quant à elles, sont largement dominées par des morceaux EDM ou latino instrumentaux, comme I Feel Love ou Chase. Ces morceaux sont :\n",
    "\n",
    "    longs,\n",
    "    très instrumentaux,\n",
    "    énergiques mais souvent moins \"accessibles\" émotionnellement (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la PC3 oppose des créations acoustiques à forte charge émotionnelle à des morceaux instrumentaux, électroniques, longs, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque le signe des contributions est inversé par rapport à l'analyse en composantes principales (ACP) réalisée sous Python.\n",
    "\n",
    "**Remarque:** on peut noter que les valeurs ne sont pas exactement les mêmes que sur le notebook Python. L'ACP sous R ne prend pas forcément la même base que sur Python, ce qui explique les valeurs parfois négatives ou positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux comprendre à quoi correspond les type morceaux extraits par ces composantes principales, nous allons regarder les morceaux (individus) contribuant le plus à chacune des composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 1\n",
    "dim1_coords <- pca$ind$coord[, 1]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices <- order(dim1_coords)[1:5]\n",
    "max_indices <- order(dim1_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals <- song[c(min_indices, max_indices), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals$Dim1_Value <- dim1_coords[c(min_indices, max_indices)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim1_Value au début\n",
    "col_order <- c(\"Category\", \"Dim1_Value\", colnames(extreme_individuals)[1:(ncol(extreme_individuals)-2)])\n",
    "extreme_individuals <- extreme_individuals[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n",
    "\n",
    "Pour mieux cerner les types de morceaux représentés aux extrémités de la première composante principale (PC1), nous avons identifié les individus (chansons) ayant les contributions les plus élevées, positives comme négatives.\n",
    "\n",
    "    Du côté des contributions positives, on retrouve majoritairement des morceaux rock, hard rock ou pop rock très énergiques et puissants tels que American Idiot (Green Day), Beauty Queen (BLVK SWVN) ou ATTENTION ATTENTION (Shinedown). Ces morceaux sont caractérisés par une énergie élevée, une forte intensité sonore (loudness) et une faible acoustique, ce qui confirme bien la structure mise en évidence par la CP1. Notons aussi This Is How We Do It (Montell Jordan), un morceau R&B énergique, qui se distingue des autres par son genre mais partage les mêmes caractéristiques acoustiques.\n",
    "\n",
    "    À l’opposé, les morceaux à contribution très négative sur PC1 sont des titres à forte acoustique, peu énergiques et très faibles en loudness. Il s'agit notamment de sons ambiants, relaxants ou naturels, comme Peaceful Forest ou Tropical Rainforest at Dawn, mais aussi de titres R&B ou indie très doux (Small de chloe moriondo). Ces morceaux incarnent l'autre extrémité de la CP1 : des chansons calmes, acoustiques et à faible énergie, souvent issues de sous-genres comme tropical, indie poptimism ou new jack swing.\n",
    "\n",
    "Cette opposition renforce l’interprétation de la CP1 comme un axe énergie / intensité sonore vs. calme / acoustique, pertinent pour distinguer deux grandes familles de styles musicaux dans le dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 2\n",
    "dim2_coords <- pca$ind$coord[, 2]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices_dim2 <- order(dim2_coords)[1:5]\n",
    "max_indices_dim2 <- order(dim2_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals_dim2 <- song[c(min_indices_dim2, max_indices_dim2), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals_dim2$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals_dim2$Dim2_Value <- dim2_coords[c(min_indices_dim2, max_indices_dim2)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim2_Value au début\n",
    "col_order <- c(\"Category\", \"Dim2_Value\", colnames(extreme_individuals_dim2)[1:(ncol(extreme_individuals_dim2)-2)])\n",
    "extreme_individuals_dim2 <- extreme_individuals_dim2[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals_dim2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n",
    "\n",
    "Côté contributions positives, on retrouve des titres principalement rap et latino, tels que Suge de DaBaby ou LAX de B0nds. Ces morceaux sont :\n",
    "\n",
    "    courts,\n",
    "    dansants (haute danceability),\n",
    "    avec une valence élevée (émotion positive),\n",
    "    mais également avec un certain niveau de speechiness, notamment pour les titres rap.\n",
    "\n",
    "Ces morceaux partagent donc des caractéristiques propres aux chansons énergétiques, rythmées et populaires, souvent taillées pour le streaming, avec des formats courts, accrocheurs et directs.\n",
    "\n",
    "À l’opposé, les morceaux ayant une forte contribution négative à PC2 sont très différents : on retrouve des paysages sonores naturels, ambiants ou instrumentaux comme Rain Forest and Tropical Beach Sound, Caribbean Thunderstorm, ou encore Battlement. Ces titres sont :\n",
    "\n",
    "    longs,\n",
    "    instrumentaux (forte instrumentalness),\n",
    "    avec une faible valence et peu de parole,\n",
    "    et souvent issus de sous-genres comme tropical, album rock, ou ambient.\n",
    "\n",
    "Cela confirme l’interprétation initiale de la PC2 comme un axe opposant la musique instrumentale, longue et contemplative à une musique populaire, dansante et rythmée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des individus sur la dimension 3\n",
    "dim3_coords <- pca$ind$coord[, 3]\n",
    "\n",
    "# Récupération des indices des 5 valeurs minimales et maximales\n",
    "min_indices_dim3 <- order(dim3_coords)[1:5]\n",
    "max_indices_dim3 <- order(dim3_coords, decreasing = TRUE)[1:5]\n",
    "\n",
    "# Sélection complète des individus extrêmes avec toutes leurs caractéristiques\n",
    "extreme_individuals_dim3 <- song[c(min_indices_dim3, max_indices_dim3), ]\n",
    "\n",
    "# Ajout d'une colonne pour identifier la catégorie (minimum ou maximum)\n",
    "extreme_individuals_dim3$Category <- c(rep(\"Minimum\", 5), rep(\"Maximum\", 5))\n",
    "extreme_individuals_dim3$Dim3_Value <- dim3_coords[c(min_indices_dim3, max_indices_dim3)]\n",
    "\n",
    "# Réorganiser les colonnes pour mettre Category et Dim3_Value au début\n",
    "col_order <- c(\"Category\", \"Dim3_Value\", colnames(extreme_individuals_dim3)[1:(ncol(extreme_individuals_dim3)-2)])\n",
    "extreme_individuals_dim3 <- extreme_individuals_dim3[, col_order]\n",
    "\n",
    "# Pour une meilleure visualisation en format tableau\n",
    "if (requireNamespace(\"knitr\", quietly = TRUE)) {\n",
    "  knitr::kable(extreme_individuals_dim3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "La troisième composante principale met en lumière une tension plus subtile entre deux types de morceaux aux caractéristiques inattendues.\n",
    "\n",
    "Du côté des contributions négatives, on retrouve des titres de pop et R&B calmes et acoustiques comme raindrops (an angel cried) (Ariana Grande) ou You Are The Reason (Calum Scott). Ces chansons ont :\n",
    "\n",
    "    une acousticness élevée (acapela, guitare acoustique, piano),\n",
    "    un tempo légèrement plus rapide que la médiane des morceaux,\n",
    "    une faible énergie, mais un potentiel émotionnel fort (valence variable).\n",
    "\n",
    "Comme suggéré par la PC3, ces morceaux rencontrent un certain succès, illustrant un profil de chansons émotionnelles, accessibles et bien produites, souvent interprétées par des artistes grand public au style sobre et expressif.\n",
    "\n",
    "Les contributions positives, quant à elles, sont largement dominées par des morceaux EDM ou latino instrumentaux, comme I Feel Love ou Chase. Ces morceaux sont :\n",
    "\n",
    "    longs,\n",
    "    très instrumentaux,\n",
    "    énergiques mais souvent moins \"accessibles\" émotionnellement (valence très élevée mais peu de paroles, structure répétitive).\n",
    "\n",
    "Ils présentent également une popularité extrêmement faible, allant de 0 à 8. Ces productions s’adressent probablement à un public averti ou sont conçues pour des usages spécifiques (DJ sets, ambiances electro), ce qui les éloigne des standards de la musique grand public.\n",
    "\n",
    "Ces observations confirment que la PC3 oppose des créations acoustiques à forte charge émotionnelle à des morceaux instrumentaux, électroniques, longs, aux dynamiques parfois complexes ou répétitives.\n",
    "\n",
    "On remarque le signe des contributions est inversé par rapport à l'analyse en composantes principales (ACP) réalisée sous Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Sélectionner les variables numériques pertinentes (similaire à l'ACP)\n",
    "numerical_features <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                               \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                               \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "\n",
    "# S'assurer qu'il n'y a pas de NA\n",
    "numerical_features <- na.omit(numerical_features)\n",
    "\n",
    "# Limiter à 2000 chansons pour éviter crash mémoire\n",
    "set.seed(42)\n",
    "if (nrow(numerical_features) > 2000) {\n",
    "  sample_idx <- sample(seq_len(nrow(numerical_features)), 2000)\n",
    "  numerical_features <- numerical_features[sample_idx, ]\n",
    "}\n",
    "\n",
    "# Standardiser\n",
    "scaled_numerical_features <- scale(numerical_features)\n",
    "dist_matrix <- dist(scaled_numerical_features)\n",
    "\n",
    "# MDS sans add=TRUE\n",
    "mds_result <- cmdscale(dist_matrix, k = 2, eig = TRUE)\n",
    "\n",
    "mds_points <- as.data.frame(mds_result$points)\n",
    "colnames(mds_points) <- c(\"Dim1\", \"Dim2\")\n",
    "\n",
    "# Récupérer le genre correspondant\n",
    "if (exists(\"sample_idx\")) {\n",
    "  temp_df_for_mds <- song[, c(\"playlist_genre\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                              \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                              \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "  temp_df_for_mds_clean <- na.omit(temp_df_for_mds)\n",
    "  temp_df_for_mds_clean <- temp_df_for_mds_clean[sample_idx, ]\n",
    "} else {\n",
    "  temp_df_for_mds <- song[, c(\"playlist_genre\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "                              \"acousticness\", \"instrumentalness\", \"liveness\", \n",
    "                              \"valence\", \"tempo\", \"track_popularity\", \"duration_s\")]\n",
    "  temp_df_for_mds_clean <- na.omit(temp_df_for_mds)\n",
    "}\n",
    "\n",
    "mds_points$playlist_genre <- temp_df_for_mds_clean$playlist_genre\n",
    "\n",
    "# Visualisation\n",
    "ggplot(mds_points, aes(x = Dim1, y = Dim2, color = playlist_genre)) +\n",
    "  geom_point(alpha = 0.7) +\n",
    "  labs(title = \"MDS des chansons (basé sur les caractéristiques audio)\",\n",
    "       x = \"Dimension MDS 1\",\n",
    "       y = \"Dimension MDS 2\",\n",
    "       color = \"Genre de Playlist\") +\n",
    "  theme_minimal() +\n",
    "  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))\n",
    "\n",
    "# Goodness-of-fit\n",
    "cat(\"\\nGoodness-of-fit (GOF):\\n\")\n",
    "print(mds_result$GOF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"Rtsne\")\n",
    "library(Rtsne)\n",
    "library(ggplot2)\n",
    "\n",
    "# Supprimer les doublons\n",
    "scaled_numerical_features_unique <- unique(scaled_numerical_features)\n",
    "\n",
    "# Identifier les lignes uniques\n",
    "unique_rows <- !duplicated(scaled_numerical_features)\n",
    "\n",
    "# Conserver uniquement les genres correspondant aux lignes uniques\n",
    "playlist_genre_unique <- temp_df_for_mds_clean$playlist_genre[unique_rows]\n",
    "\n",
    "# Exécuter t-SNE\n",
    "set.seed(42)\n",
    "tsne_result <- Rtsne(scaled_numerical_features_unique, dims = 2, perplexity = 30, verbose = TRUE)\n",
    "\n",
    "# Préparer le dataframe pour ggplot\n",
    "tsne_df <- as.data.frame(tsne_result$Y)\n",
    "colnames(tsne_df) <- c(\"Dim1\", \"Dim2\")\n",
    "tsne_df$playlist_genre <- playlist_genre_unique\n",
    "\n",
    "# Visualisation\n",
    "ggplot(tsne_df, aes(x = Dim1, y = Dim2, color = playlist_genre)) +\n",
    "  geom_point(alpha = 0.6) +\n",
    "  labs(title = \"t-SNE des chansons (caractéristiques audio)\",\n",
    "       x = \"Dimension 1\", y = \"Dimension 2\",\n",
    "       color = \"Genre de Playlist\") +\n",
    "  theme_minimal() +\n",
    "  guides(color = guide_legend(override.aes = list(size = 4, alpha = 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Interprétation des méthodes de MDS et t-SNE\n",
    "\n",
    "### Interprétation du MDS\n",
    "\n",
    "Le graphique issu de la MDS montre une concentration importante des points au centre, avec un fort chevauchement entre les différents genres musicaux (`pop`, `rap`, `r&b`, `rock`, etc.). Il n'y a pas de séparation nette ou de regroupement clair visible sur les deux dimensions principales.\n",
    "\n",
    "Le **Goodness-of-Fit (GOF)** est d’environ **0.34**, ce qui signifie que seulement **34 %** de la structure initiale des distances est préservée dans cette projection bidimensionnelle. Ce score relativement faible traduit une **perte d'information importante**, ce qui rend la visualisation difficile à interpréter de manière fiable.\n",
    "\n",
    "Cela suggère que :\n",
    "\n",
    "- Les genres musicaux ne se distinguent pas clairement sur la base des distances euclidiennes entre leurs caractéristiques audio normalisées.\n",
    "- La MDS, étant une méthode **linéaire**, ne capture pas bien les relations **non linéaires** qui pourraient exister entre les chansons.\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation du t-SNE\n",
    "\n",
    "Le graphique t-SNE montre une plus grande dispersion des points, avec des zones où certains genres comme `edm` ou `rap` semblent former des **sous-groupes partiellement distincts**. Cependant, on observe encore un chevauchement significatif entre les genres.\n",
    "\n",
    "Contrairement à la MDS, le t-SNE est une méthode **non linéaire** qui vise à préserver les **voisinages locaux** plutôt que les distances globales. Cela lui permet de mieux mettre en évidence les structures locales, comme des groupes compacts, même si les distances globales ne sont pas interprétables.\n",
    "\n",
    "L’interprétation du t-SNE suggère que :\n",
    "\n",
    "- Il existe quelques **régions homogènes** selon certains genres, mais aucune **séparation franche** entre clusters de genres.\n",
    "- Les caractéristiques audio seules ne suffisent probablement pas à **discriminer clairement** les genres musicaux.\n",
    "- Le t-SNE offre une visualisation plus riche que la MDS, mais reste difficile à interpréter en l’absence de clusters bien définis.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion commune\n",
    "\n",
    "Les deux méthodes révèlent que les genres musicaux dans ce jeu de données **ne sont pas linéairement séparables** sur la base des caractéristiques audio fournies. Le chevauchement visuel suggère soit :\n",
    "\n",
    "- une **proximité réelle** entre les genres sur le plan acoustique,\n",
    "- soit un **manque de variabilité** ou de pertinence dans les variables utilisées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Analyse en Correspondances Multiples (MCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif\n",
    "L'Analyse en Correspondances Multiples (MCA) a été réalisée pour explorer les relations entre les variables qualitatives du dataset Spotify. Cette méthode permet de visualiser les associations entre les modalités des variables qualitatives et d'identifier des clusters ou des oppositions significatives.\n",
    "\n",
    "**1. Variables catégorielles à utiliser dans la MCA**\n",
    "Voici les variables qualitatives que l'on pourrait envisager d'utiliser pour la MCA sur le dataset Spotify :  \n",
    "- `track_artist`  \n",
    "- `track_album_name` (attention à trop de modalités rares, peut-être garder que les plus fréquentes ou ne pas inclure à cause du grand nombre d’artistes)  \n",
    "- `playlist_name`  \n",
    "- `playlist_genre`  \n",
    "- `playlist_subgenre`  \n",
    "- `key`  \n",
    "- `mode`  \n",
    "\n",
    "---\n",
    "\n",
    "**2. Questions que la MCA peut aider à explorer**\n",
    "\n",
    "**a) Quels sont les groupes/cluster de modalités similaires ?**\n",
    "- Est-ce que certains genres et sous-genres de playlists s’associent fréquemment ?  \n",
    "- Certains \"modes\" (majeur/minor) sont-ils plus fréquents dans certains genres ?  \n",
    "- Y a-t-il des clés (`key`) musicales qui sont typiques de certains genres ou playlists ?  \n",
    "\n",
    "La MCA permettra de représenter graphiquement (biplot) ces modalités et d’identifier des associations fortes.\n",
    "\n",
    "**b) Est-ce que certains artistes ou playlists ont un profil qualitatif particulier ?**\n",
    "- Par exemple, certains artistes seraient-ils associés à un genre et sous-genre spécifiques, ou à un mode particulier ?  \n",
    "- Y a-t-il des clusters d’artistes / playlists qui partagent des caractéristiques particulières (clé, mode, genre) ?\n",
    "\n",
    "**3. Comment interpréter la MCA ici**\n",
    "\n",
    "- **Axes factoriels** : Chaque axe correspond à une dimension qui résume des associations fortes entre modalités. Par exemple, un axe peut opposer les genres \"Rock\" à \"Pop\", ou des clés majeures à mineures.\n",
    "- **Modalités proches dans l’espace** : Modalités proches signifient qu’elles co-apparaissent souvent dans les observations (ex. certains genres + mode majeur).\n",
    "- **Observation** : Si tu represents les observations (chansons) dans l’espace MCA, celles proches partagent des profils catégoriels similaires.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Utilisations concrètes/academic use cases**\n",
    "\n",
    "- **Profil des genres musicaux** : Comprendre quels modes/clés/sous-genres caractérisent les genres populaires sur Spotify.  \n",
    "- **Segmentation qualitative des playlists** : Y a-t-il des types de playlists/musiques qui partagent des caractéristiques qualitatives communes ?  \n",
    "- **Analyse de diversité** : Mesurer dans quelle mesure certains artistes/genres sont hétérogènes ou homogènes quant à leurs caractéristiques catégorielles.  \n",
    "- **Préparation à une classification** : Par exemple, combiner le résultat de la PCA (variables numériques) avec la MCA (variables qualitatives) dans une analyse factorielle mixte ou pour enrichir un modèle prédictif.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Exemple de questions précises à poser**\n",
    "\n",
    "- Les genres musicaux sont-ils liés à certaines tonalités ou modes ?  \n",
    "- Les sous-genres présents dans la même playlist sont-ils proches ou éloignés dans l’espace MCA ?  \n",
    "- Y a-t-il des clés rares ou des modes minoritaires associés à certains genres uniquement ?  \n",
    "- Peut-on détecter des groupes de playlists ou artistes avec des profils qualitatifs similaires ?  \n",
    "\n",
    "---\n",
    "\n",
    "**En conclusion**\n",
    "La MCA t’aide surtout à **explorer et visualiser les relations entre variables qualitatives** et leurs modalités sur ton dataset Spotify, ce qui complète bien la PCA sur les variables numériques. C’est une étape utile pour comprendre la structure qualitative de tes données avant d’envisager une modélisation supervisée ou une analyse plus approfondie.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'un data.frame catégorique selon les règles demandées\n",
    "\n",
    "df_cat_custom <- data.frame(row.names = rownames(song))\n",
    "\n",
    "# Popularity\n",
    "df_cat_custom$popularity_cat <- cut(\n",
    "    song$track_popularity,\n",
    "    breaks = c(-1, 20, 75, 100),\n",
    "    labels = c(\"Peu populaire\", \"Popularité moyenne\", \"Très populaire\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Speechiness\n",
    "df_cat_custom$speechiness_cat <- cut(\n",
    "    song$speechiness,\n",
    "    breaks = c(-0.01, 0.3, 1.0),  # Ajuster les seuils\n",
    "    labels = c(\"Peu de paroles\", \"Paroles dominantes\"),  # Deux classes seulement\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Danceability\n",
    "df_cat_custom$danceability_cat <- cut(\n",
    "    song$danceability,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Peu dansant\", \"Dansant\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Energy\n",
    "df_cat_custom$energy_cat <- cut(\n",
    "    song$energy,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Peu énergique\", \"Energique\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Instrumentalness\n",
    "df_cat_custom$instrumentalness_cat <- cut(\n",
    "    song$instrumentalness,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Peu instrumental\", \"Instrumentale\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Liveness\n",
    "df_cat_custom$liveness_cat <- cut(\n",
    "    song$liveness,\n",
    "    breaks = c(-0.01, 0.8, 1.0),\n",
    "    labels = c(\"Pas live\", \"Live\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Valence\n",
    "df_cat_custom$valence_cat <- cut(\n",
    "    song$valence,\n",
    "    breaks = c(-0.01, 0.5, 1.0),\n",
    "    labels = c(\"Triste\", \"Joyeux\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Tempo\n",
    "df_cat_custom$tempo_cat <- cut(\n",
    "    song$tempo,\n",
    "    breaks = c(-Inf,100, 150, Inf),\n",
    "    labels = c(\"Tempo lent\", \"Tempo modéré\", \"Tempo rapide\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Duration (en secondes)\n",
    "df_cat_custom$duration_cat <- cut(\n",
    "    song$duration_s,\n",
    "    breaks = c(-0.01, 120, 240, Inf),\n",
    "    labels = c(\"Morceaux courts\", \"Morceaux moyennement longs\", \"Morceaux longs\"),\n",
    "    include.lowest = TRUE\n",
    ")\n",
    "\n",
    "# Décennie de sortie de l'album\n",
    "years <- as.numeric(format(song$track_album_release_date, \"%Y\"))\n",
    "df_cat_custom$decade <- ifelse(\n",
    "    !is.na(years),\n",
    "    paste0(floor(years / 10) * 10, \"s\"),\n",
    "    \"unknown\"\n",
    ")\n",
    "\n",
    "#Fusionner 50s et 60s\n",
    "df_cat_custom$decade <- recode(df_cat_custom$decade, \n",
    "                               \"1950s\" = \"1950s-1960s\", \n",
    "                               \"1960s\" = \"1950s-1960s\")\n",
    "\n",
    "head(df_cat_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sélection de toutes les variables qualitatives pertinentes pour la MCA\n",
    "qual_vars <- c( 'playlist_genre', 'key', 'mode')\n",
    "song_mca_all <- song[, qual_vars]\n",
    "\n",
    "# Réalisation de la MCA avec FactoMineR\n",
    "mca_all <- MCA(song_mca_all, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_all, col.var = \"cos2\", \n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Toutes les variables qualitatives\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables utilisées\n",
    "Les variables qualitatives sélectionnées pour cette analyse sont :\n",
    "- `playlist_genre` : Genre de la playlist (ex. rock, pop, rap, etc.).\n",
    "- `key` : Tonalité musicale (ex. C, D, E♭, etc.).\n",
    "- `mode` : Mode musical (majeur ou mineur).\n",
    "\n",
    "### Résultats\n",
    "\n",
    "#### 1. Axes factoriels\n",
    "- **Dim1 (8%)** : Cet axe semble opposer des genres musicaux et des tonalités spécifiques :\n",
    "  - À droite, des genres comme `rap` et des tonalités comme `A♯/B♭` sont associés à des morceaux modernes ou spécifiques.\n",
    "  - À gauche, des tonalités comme `C` et `G` sont associées à des genres comme `rock`, suggérant une relation avec des styles plus classiques.\n",
    "- **Dim2 (6.6%)** : Cet axe reflète une distinction entre les modes (`major` et `minor`) et leur association avec certains genres :\n",
    "  - En haut, le mode `major` est associé à des genres comme `rock`.\n",
    "  - En bas, le mode `minor` est plus proche de genres comme `rap` et `edm`.\n",
    "\n",
    "#### 2. Proximité des modalités\n",
    "- Les modalités proches sur le graphique sont souvent associées dans les données :\n",
    "  - `pop`, `latin`, `r&b` et `edm` sont centrés par rapport aux modes `minor`et `major`, indiquant qu'ils n'appartiennent pas clairement à un mode spécifique, mais partagent des caractéristiques communes.\n",
    "  - `rap` est également centré par rapport à ces modes, ce qui suggère que l'utilisation des modes majeurs et mineurs est assez équilibrée dans la composition des morceaux de rap. Toutefois, il reste distinct des groupes `pop`, `latin`, `r&b` et `edm`.\n",
    "  - `rock` est plus proche de `major`, ce qui suggère que les musiques de ce genre sont souvent associées à des tonalités majeures.\n",
    "  - Les tonalités comme `B`,`D♯/E♭`,`A♯/B♭`,`F♯/G♭`et `F` sont proches de `minor`, indiquant qu'elles sont souvent utilisées dans des morceaux en mode mineur.\n",
    "  - Les tonalités comme `C`, `G`,`D` sont proches de `major`, ce qui suggère qu'elles sont souvent utilisées dans des morceaux en mode majeur.\n",
    "\n",
    "#### 3. Cos2 (Qualité de représentation)\n",
    "- Les couleurs des points indiquent la qualité de représentation des modalités sur les deux premières dimensions :\n",
    "  - Les modalités avec des couleurs chaudes (orange/rouge) comme `major` ou `minor` sont bien représentées sur ces axes.\n",
    "  - Les modalités avec des couleurs froides (bleu/vert) comme certaines tonalités (`C`, `G`) sont moins bien représentées, ce qui signifie qu'elles pourraient être mieux expliquées par d'autres dimensions.\n",
    "\n",
    "### Conclusion\n",
    "Cette MCA met en évidence des associations claires entre les genres musicaux, les tonalités (`key`), et les modes (`major`/`minor`). Elle permet de visualiser les relations qualitatives dans les données et d'identifier des clusters ou des oppositions significatives. Par exemple :\n",
    "- `rock` est distinct des autres genres, avec des tonalités et un mode spécifiques.\n",
    "- `pop`, `latin`, `r&b` et `edm` partagent des caractéristiques similaires, mais ne sont pas clairement associés à un mode particulier.\n",
    "- `rap` est centré par rapport aux modes, mais reste distinct des autres genres.\n",
    "\n",
    "Ces résultats offrent une meilleure compréhension des structures qualitatives des données et peuvent être utilisés pour des analyses complémentaires, comme la segmentation ou la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Identifier les top artists\n",
    "top_artists <- c(\"Eminem\", \"Green Day\", \"David Guetta\", \"Ed Sheeran\")\n",
    "\n",
    "# Créer une nouvelle variable track_artist_grouped avec \"other\" pour les artistes non sélectionnés\n",
    "song$track_artist_grouped <- as.character(song$track_artist)\n",
    "song$track_artist_grouped[!(song$track_artist %in% top_artists)] <- \"other\"\n",
    "song$track_artist_grouped <- as.factor(song$track_artist_grouped)\n",
    "\n",
    "# Filtrer le dataset pour ne garder que les morceaux des top artists ou \"other\"\n",
    "song_top_other <- song[song$track_artist_grouped %in% c(top_artists, \"other\"), ]\n",
    "\n",
    "# Sélection des variables qualitatives pour la MCA\n",
    "qual_vars_top_other <- c('track_artist_grouped', 'playlist_genre', 'key', 'mode')\n",
    "song_mca_top_other <- song_top_other[, qual_vars_top_other]\n",
    "\n",
    "# Réalisation de la MCA\n",
    "mca_top_other <- MCA(song_mca_top_other, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_top_other, col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             repel = TRUE) +\n",
    "  labs(title = \"MCA - Top 4 artistes vs autres + genre, key, mode\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Proximité des modalités\n",
    "- Les artistes proches sur le graphique partagent des caractéristiques similaires :\n",
    "  - `Ed Sheeran` est proche des tonalités `A` et `D`, ainsi que du mode `major`, ce qui reflète son style musical souvent associé à des tonalités classiques.\n",
    "  - `Green Day` est également associé au mode `major` et à des tonalités comme `C` et `D`, typiques de leur style rock.\n",
    "  - `David Guetta` est lié à des tonalités comme `F` et `D♯/E♭`, souvent utilisées dans la musique électronique.\n",
    "  - `Eminem` est associé au mode `minor` et à des tonalités comme `A♯/B♭`, caractéristiques de son style rap.\n",
    "\n",
    "#### 2. Clusters identifiés\n",
    "  - `rock` est fortement associé à `Green Day` et au mode `major`.\n",
    "  - `rap` est lié à `Eminem` et au mode `minor`.\n",
    "  - `Ed Sheeran` est proche du centre, indiquant un style musical équilibré entre tonalités et modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# D'abord, ajouter les variables catégorielles créées précédemment à song\n",
    "song$popularity_cat <- df_cat_custom$popularity_cat\n",
    "song$speechiness_cat <- df_cat_custom$speechiness_cat\n",
    "song$danceability_cat <- df_cat_custom$danceability_cat\n",
    "song$energy_cat <- df_cat_custom$energy_cat\n",
    "song$instrumentalness_cat <- df_cat_custom$instrumentalness_cat\n",
    "song$liveness_cat <- df_cat_custom$liveness_cat\n",
    "song$valence_cat <- df_cat_custom$valence_cat\n",
    "song$tempo_cat <- df_cat_custom$tempo_cat\n",
    "song$duration_cat <- df_cat_custom$duration_cat\n",
    "song$decade <- df_cat_custom$decade\n",
    "\n",
    "# MCA avec toutes les variables qualitatives + les variables catégorielles créées\n",
    "qual_vars_cat <- c('playlist_genre', \n",
    "                   'popularity_cat', 'speechiness_cat', \n",
    "                   'danceability_cat', 'energy_cat', \n",
    "                   'instrumentalness_cat', 'liveness_cat', \n",
    "                   'valence_cat', 'tempo_cat', \n",
    "                   'duration_cat', 'decade')\n",
    "song_mca_cat <- song[, qual_vars_cat]\n",
    "\n",
    "# Réalisation de la MCA\n",
    "mca_cat <- MCA(song_mca_cat, graph = FALSE)\n",
    "\n",
    "# Visualisation des modalités sur le plan factoriel\n",
    "fviz_mca_var(mca_cat, col.var = \"cos2\",\n",
    "                   gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "                   repel = TRUE) +\n",
    "  labs(title = \"MCA - Variables catégorielles\",\n",
    "         subtitle = \"Variables incluses: playlist_genre, popularity_cat, speechiness_cat, danceability_cat,\\nenergy_cat, instrumentalness_cat, liveness_cat, valence_cat, tempo_cat,\\nduration_cat, decade\",\n",
    "         caption = \"Les couleurs indiquent la qualité de représentation (cos2) des modalités\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"bottom\",\n",
    "            plot.title = element_text(size = 16),\n",
    "            plot.subtitle = element_text(size = 12, color = \"gray40\"),\n",
    "            plot.caption = element_text(size = 10, color = \"gray50\"),\n",
    "            axis.text = element_text(size = 12),\n",
    "            axis.title = element_text(size = 14)) +\n",
    "  guides(color = guide_colorbar(title = \"Cos2\", \n",
    "                                                title.position = \"top\",\n",
    "                                                barwidth = 15,\n",
    "                                                barheight = 1))\n",
    "\n",
    "# Afficher avec une taille plus grande\n",
    "options(repr.plot.width = 18, repr.plot.height = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Interprétation de l'Analyse des Correspondances Multiples (MCA)\n",
    "\n",
    "#### Variables utilisées\n",
    "\n",
    "Les variables qualitatives sélectionnées pour cette analyse sont :\n",
    "- `playlist_genre` : Genre de la playlist (ex. rock, pop, rap, edm, r&b, latin).\n",
    "- `popularity_cat` : Catégorie de popularité (Peu populaire, Popularité moyenne, Très populaire).\n",
    "- `speechiness_cat` : Présence de paroles (Peu de paroles, Paroles dominantes).\n",
    "- `danceability_cat` : Potentiel dansant (Peu dansant, Dansant).\n",
    "- `energy_cat` : Niveau d'énergie (Peu énergique, Énergique).\n",
    "- `instrumentalness_cat` : Caractère instrumental (Peu instrumental, Instrumentale).\n",
    "- `liveness_cat` : Caractère live (Pas live, Live).\n",
    "- `valence_cat` : Valence émotionnelle (Triste, Joyeux).\n",
    "- `tempo_cat` : Catégorie de tempo (Tempo lent, Tempo modéré, Tempo rapide).\n",
    "- `duration_cat` : Durée des morceaux (Morceaux courts, Morceaux moyennement longs, Morceaux longs).\n",
    "- `decade` : Décennie de sortie (1950s-1960s, 1970s, 1980s, 1990s, 2000s, 2010s, 2020s).\n",
    "---\n",
    "\n",
    "### Résultats\n",
    "\n",
    "#### 1. **Axes factoriels**\n",
    "\n",
    "##### **Dimension 1 (8.15%)** :\n",
    "\n",
    "Cet axe semble opposer :\n",
    "\n",
    "* **À droite** : des genres et époques associés à une musique plus **live**, **peu dansante**, **rock** et **années 1970–1980**, avec une tendance à la **longueur**.\n",
    "* **À gauche** : des genres comme **EDM**, **rap**, ou **pop des années 2010–2020**, associés à des morceaux plus **courts**, **instrumentaux**, **très populaires**, avec **paroles dominantes**, souvent **joyeux**.\n",
    "\n",
    "##### **Dimension 2 (7.14%)** :\n",
    "\n",
    "Cet axe reflète plutôt une opposition d’ambiance :\n",
    "\n",
    "* **En bas** : Musiques plus **live**, **peu dansantes**, parfois **instrumentales**, associées à des décennies anciennes (1950s–1980s).\n",
    "* **En haut** : Musiques plus **rapides**, **énergétiques**, **avec paroles dominantes**, parfois **r\\&b** ou **pop**.\n",
    "\n",
    "> La projection est inversée selon la dim 1 par rapport aux résultats sous R. Cela n'affecte pas l'interprétation, seule l’orientation spatiale est différente.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Proximité des modalités**\n",
    "\n",
    "* Les genres **rap**, **latin**, **court**, **très populaire** et **paroles dominantes** sont regroupés → musique courte, populaire, axée sur le texte.\n",
    "* Le **rock** est fortement associé à la **décennie 1980**, à un **caractère live** et **peu dansant**.\n",
    "* **EDM** est très proche de **instrumentale**, indiquant des morceaux sans paroles.\n",
    "* Les catégories **\"paroles dominantes\"**, **\"peu instrumental\"**, et **\"énergique\"** sont toutes proches, suggérant que beaucoup de morceaux énergiques contiennent beaucoup de texte.\n",
    "* **Pop des années 2010s et 2020s**, **dansants**, morceaux **moyennement long** se positionne plutôt au centre, ce qui reflète une certaine **polyvalence**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Cos² (qualité de représentation)**\n",
    "\n",
    "* Les modalités bien représentées par les deux axes incluent :\n",
    "\n",
    "  * `rock`, `live`, `très populaire`, `joyeux`, `paroles dominantes`, `peu dansant`\n",
    "* Les modalités avec des bulles plus petites comme `minor`, `pop`, `latin`, `r&b` sont moins bien représentées → elles nécessiteraient plus de dimensions pour être bien décrites.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Cette MCA met en évidence des **clusters sémantiques clairs** entre les genres, l’époque, les caractéristiques émotionnelles et musicales :\n",
    "\n",
    "* **Le rock des années 70–80** est clairement identifiable : live, peu dansant, majeur, long.\n",
    "* **Le EDM et l’instrumental** vont de pair, souvent peu dansants, modernes, peu de texte.\n",
    "* **Le rap** est court, populaire, avec des paroles dominantes, souvent dans un registre énergique mais pas exclusivement mineur ou majeur.\n",
    "* **La pop des années 2010s–2020s** est très mixte : ni clairement joyeuse ni triste, ni très rapide ni lente → un profil \"standard\" qui touche un large public.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Analyse Factorielle Multiple (MFA)\n",
    "\n",
    "L’Analyse Factorielle Multiple (MFA) est une méthode d’analyse exploratoire multivariée qui permet d’étudier simultanément plusieurs groupes de variables de nature différente, notamment des variables quantitatives (caractéristiques audio) et qualitatives (genre, tonalité, mode, etc.). \n",
    "\n",
    "Dans le contexte de ce projet Spotify, la MFA est particulièrement pertinente car elle va permettre de :\n",
    "- **Combiner** dans une même analyse les profils audio des morceaux et leurs attributs qualitatifs (genre, mode, key, etc.), en tenant compte de la structure de chaque groupe de variables.\n",
    "- **Explorer les liens** entre les caractéristiques musicales objectives et les catégories musicales, pour voir par exemple si certains genres ou modes sont associés à des profils audio spécifiques.\n",
    "- **Visualiser la structure globale** du jeu de données en intégrant toutes les dimensions importantes, ce qui offre une vision plus complète que l’ACP (centrée sur le quantitatif) ou la MCA (centrée sur le qualitatif) seules.\n",
    "\n",
    "La MFA est donc un outil idéal pour comprendre comment les différentes facettes des chansons (audio et catégorielles) s’articulent et pour identifier des profils ou des clusters mixtes dans le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Analyse Factorielle Multiple (MFA) : audio + genre\n",
    "\n",
    "# 1. Préparer les données pour MFA avec playlist_genre\n",
    "mfa_data_genre <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\",\n",
    "              \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\", \"playlist_genre\")]\n",
    "\n",
    "# S'assurer que playlist_genre est un facteur\n",
    "mfa_data_genre$playlist_genre <- as.factor(mfa_data_genre$playlist_genre)\n",
    "\n",
    "# 2. Définir les groupes : 10 variables audio (quantitatives), 1 qualitative (playlist_genre)\n",
    "group_genre <- c(10, 1)\n",
    "type_genre <- c(\"s\", \"n\")  # 1 groupe quanti, 1 groupe quali\n",
    "\n",
    "# 3. Réaliser la MFA\n",
    "mfa_genre <- MFA(mfa_data_genre, group = group_genre, type = type_genre, \n",
    "         name.group = c(\"Audio\", \"Genre\"), graph = FALSE)\n",
    "\n",
    "# 4. Visualisation des individus colorés par genre\n",
    "fviz_mfa_ind(mfa_genre, habillage = mfa_data_genre$playlist_genre, palette = \"Set2\", \n",
    "       addEllipses = TRUE, ellipse.type = \"confidence\", label = \"none\") +\n",
    "  labs(title = \"MFA : projection des chansons selon audio et genre\") +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation de l'Analyse Factorielle Multiple (MFA)\n",
    "\n",
    "#### **Analyse audio + genre**\n",
    "\n",
    "La MFA intégrant les caractéristiques audio et les genres musicaux révèle une **structuration claire** des genres selon leurs profils acoustiques :\n",
    "\n",
    "**Séparation des genres :**\n",
    "- Les genres forment des **clusters relativement distincts** dans l'espace factoriel, confirmant que les caractéristiques audio permettent une différenciation entre styles musicaux\n",
    "- Certains genres comme **rock** et **edm** montrent une **séparation nette**, reflétant leurs profils acoustiques contrastés (rock : acoustique, live vs. edm : électronique, synthétique)\n",
    "- D'autres genres comme **pop** et **latin** présentent une **plus grande diversité interne** et un chevauchement partiel, suggérant une variabilité stylistique au sein de ces catégories\n",
    "\n",
    "**Axes factoriels :**\n",
    "- Les axes révèlent des **oppositions claires** entre profils musicaux :\n",
    "    - **Rock** : associé à des caractéristiques plus classiques (acousticness, liveness)\n",
    "    - **EDM** : orienté vers des profils modernes et électroniques (energy, danceability)\n",
    "    - **Rap** : caractérisé par des aspects rythmiques et vocaux (speechiness, tempo)\n",
    "\n",
    "\n",
    "Ce graphique met en évidence la structuration des genres musicaux en fonction des caractéristiques audio. Il montre que certains genres (comme le rock et l'edm) sont bien séparés, tandis que d'autres (comme le pop et le latin) partagent des caractéristiques communes avec plusieurs genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Analyse Factorielle Multiple (MFA) : audio + decade\n",
    "\n",
    "# 1. Préparer les données pour MFA avec decade\n",
    "mfa_data_decade <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\",\n",
    "                           \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\", \"decade\")]\n",
    "\n",
    "# S'assurer que decade est un facteur\n",
    "mfa_data_decade$decade <- as.factor(mfa_data_decade$decade)\n",
    "\n",
    "# 2. Définir les groupes : 10 variables audio (quantitatives), 1 qualitative (decade)\n",
    "group_decade <- c(10, 1)\n",
    "type_decade <- c(\"s\", \"n\")  # 1 groupe quanti, 1 groupe quali\n",
    "\n",
    "# 3. Réaliser la MFA\n",
    "mfa_decade <- MFA(mfa_data_decade, group = group_decade, type = type_decade, \n",
    "                  name.group = c(\"Audio\", \"Decade\"), graph = FALSE)\n",
    "\n",
    "# 4. Visualisation des individus colorés par décennie\n",
    "fviz_mfa_ind(mfa_decade, habillage = mfa_data_decade$decade, palette = \"Set1\", \n",
    "             addEllipses = TRUE, ellipse.type = \"confidence\", label = \"none\") +\n",
    "  labs(title = \"MFA : projection des chansons selon audio et décennie\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Analyse audio + décennie**\n",
    "\n",
    "La MFA intégrant les caractéristiques audio et les décennies de sortie des morceaux révèle une **structuration temporelle claire** des chansons selon leurs profils acoustiques.\n",
    "\n",
    "**Séparation des décennies :**\n",
    "- Les décennies forment des **clusters relativement distincts** dans l'espace factoriel, confirmant que les caractéristiques audio évoluent au fil du temps\n",
    "- Les morceaux des **années 1950s-1960s et 1970s** montrent une séparation nette\n",
    "- Les morceaux des **années 2000s, 2010s et 2020s** présentent une plus grande diversité interne et un chevauchement partiel, suggérant une variabilité stylistique accrue dans les productions modernes\n",
    "\n",
    "Ce graphique met en évidence l'**évolution des caractéristiques musicales au fil des décennies**. Il montre que les morceaux anciens (1950s-1970s) sont bien séparés des morceaux modernes (2000s-2020s), tandis que les décennies intermédiaires (1980s-1990s) servent de transition entre ces deux périodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Analyse Factorielle Multiple (MFA) : audio + popularity\n",
    "\n",
    "# 1. Préparer les données pour MFA avec popularity_cat\n",
    "mfa_data_popularity <- song[, c(\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\",\n",
    "                               \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_s\", \"popularity_cat\")]\n",
    "\n",
    "# S'assurer que popularity_cat est un facteur\n",
    "mfa_data_popularity$popularity_cat <- as.factor(mfa_data_popularity$popularity_cat)\n",
    "\n",
    "# 2. Définir les groupes : 10 variables audio (quantitatives), 1 qualitative (popularity_cat)\n",
    "group_popularity <- c(10, 1)\n",
    "type_popularity <- c(\"s\", \"n\")  # 1 groupe quanti, 1 groupe quali\n",
    "\n",
    "# 3. Réaliser la MFA\n",
    "mfa_popularity <- MFA(mfa_data_popularity, group = group_popularity, type = type_popularity, \n",
    "                     name.group = c(\"Audio\", \"Popularity\"), graph = FALSE)\n",
    "\n",
    "# 4. Visualisation des individus colorés par popularité\n",
    "fviz_mfa_ind(mfa_popularity, habillage = mfa_data_popularity$popularity_cat, palette = \"viridis\", \n",
    "             addEllipses = TRUE, ellipse.type = \"confidence\", label = \"none\") +\n",
    "  labs(title = \"MFA : projection des chansons selon audio et popularité\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "#### **Analyse audio + popularité**\n",
    "\n",
    "La MFA intégrant les caractéristiques audio et les niveaux de popularité des morceaux révèle une structuration claire des chansons selon leur popularité.\n",
    "\n",
    "**Séparation des niveaux de popularité :**\n",
    "\n",
    "Les morceaux forment des clusters relativement distincts dans l'espace factoriel, confirmant que les caractéristiques audio influencent leur popularité.\n",
    "\n",
    "Les morceaux **très populaires** montrent une concentration nette.\n",
    "\n",
    "Les morceaux **peu populaires** présentent une plus grande diversité interne et un chevauchement partiel, suggérant une variabilité stylistique accrue ou des caractéristiques acoustiques et instrumentales.\n",
    "\n",
    "Ce graphique met en évidence les relations entre les caractéristiques musicales et la popularité. Il montre que les morceaux très populaires se distinguent par des profils spécifiques, tandis que les morceaux peu populaires sont plus variés. Les morceaux de popularité moyenne occupent une position intermédiaire, suggérant que la popularité est influencée par une combinaison de caractéristiques audio et de facteurs contextuels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## NMF\n",
    "\n",
    "La Factorisation Matricielle Non-Négative (NMF) est une technique de réduction de dimension qui permet de décomposer une matrice en deux matrices de facteurs non négatifs. Dans le contexte de l'analyse des données musicales, NMF est particulièrement utile pour identifier des motifs latents ou des profils musicaux à partir des caractéristiques audio.\n",
    "\n",
    "### Objectif de la NMF\n",
    "L'objectif de la NMF dans ce projet est de découvrir des profils musicaux latents qui peuvent représenter des styles ou des genres musicaux spécifiques. En factorisant les données audio, nous espérons extraire des caractéristiques communes qui peuvent être utilisées pour la recommandation de musique ou pour mieux comprendre la structure des genres musicaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(NMF)\n",
    "# 2. Sélection des colonnes audio uniquement depuis song\n",
    "audio_features <- song %>%\n",
    "  select(danceability, energy, loudness, speechiness, acousticness,\n",
    "         instrumentalness, liveness, valence, tempo, duration_s) %>%\n",
    "  na.omit()\n",
    "\n",
    "# 3. Min-max scaling sur chaque colonne\n",
    "audio_features <- as.data.frame(lapply(audio_features, function(x) (x - min(x)) / (max(x) - min(x))))\n",
    "\n",
    "# 4. Conversion en matrice\n",
    "audio_matrix <- as.matrix(audio_features)\n",
    "\n",
    "# 5. Choix du nombre de composantes (ex. : 4 profils)\n",
    "nmf_result <- nmf(audio_matrix, rank = 4, method = \"brunet\", nrun = 10, seed = 123)\n",
    "\n",
    "# 6. Résumé\n",
    "print(nmf_result)\n",
    "\n",
    "# 7. Matrice W (coefficients pour chaque chanson)\n",
    "W <- basis(nmf_result)\n",
    "\n",
    "# 8. Matrice H (contributions de chaque feature à chaque profil)\n",
    "H <- coef(nmf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Sélection des features audio\n",
    "audio_features <- c('danceability', 'energy', 'loudness', 'speechiness',\n",
    "                   'acousticness', 'instrumentalness', 'liveness',\n",
    "                   'valence', 'tempo', 'duration_s')\n",
    "\n",
    "X <- song[, audio_features]\n",
    "\n",
    "# 2. Normalisation min-max (important pour la NMF)\n",
    "X_scaled <- as.data.frame(lapply(X, function(x) (x - min(x)) / (max(x) - min(x))))\n",
    "X_matrix <- as.matrix(X_scaled)\n",
    "\n",
    "# 3. Tester plusieurs valeurs de r (nombre de composants)\n",
    "errors <- c()\n",
    "r_values <- seq(2, 10, by = 2)\n",
    "\n",
    "for (r in r_values) {\n",
    "  nmf_model <- nmf(X_matrix, rank = r, method = \"brunet\", nrun = 5, seed = 42)\n",
    "  W <- basis(nmf_model)\n",
    "  H <- coef(nmf_model)\n",
    "  reconstruction <- W %*% H\n",
    "  error <- norm(X_matrix - reconstruction, type = \"F\") # norme de Frobenius\n",
    "  errors <- c(errors, error)\n",
    "}\n",
    "\n",
    "# 4. Tracer la courbe de l’erreur de reconstruction\n",
    "plot(r_values, errors, type = \"b\", pch = 19,\n",
    "     main = \"Erreur de reconstruction vs nombre de composants (r)\",\n",
    "     xlab = \"Nombre de composants (r)\",\n",
    "     ylab = \"Erreur de reconstruction (norme de Frobenius)\")\n",
    "grid()\n",
    "\n",
    "#On garde r=6 pour la suite soit 6 profils musicaux\n",
    "\n",
    "# 5. Application de la NMF avec 6 composantes\n",
    "nmf_model_6 <- nmf(X_matrix, rank = 6, method = \"brunet\", nrun = 10, seed = 42)\n",
    "W_6 <- basis(nmf_model_6)\n",
    "H_6 <- coef(nmf_model_6)\n",
    "\n",
    "# 6. Créer un data.frame pour la matrice H\n",
    "H_df <- as.data.frame(H_6)\n",
    "colnames(H_df) <- audio_features\n",
    "rownames(H_df) <- paste0(\"Profil \", 1:6)\n",
    "\n",
    "# 7. Affichage de la matrice H\n",
    "print(\"Matrice H (profils latents définis par les variables audio) :\")\n",
    "\n",
    "# 8. Visualisation : contribution des variables à chaque profil (heatmap)\n",
    "library(reshape2)\n",
    "library(ggplot2)\n",
    "H_df_long <- melt(as.matrix(H_df))\n",
    "colnames(H_df_long) <- c(\"Profil\", \"Variable\", \"Valeur\")\n",
    "\n",
    "ggplot(H_df_long, aes(x = Variable, y = Profil, fill = Valeur)) +\n",
    "    geom_tile() +\n",
    "    geom_text(aes(label = sprintf(\"%.2f\", Valeur)), size = 3) +\n",
    "    scale_fill_gradient(low = \"#E7F6D5\", high = \"#2171B5\") +\n",
    "    labs(title = \"Profils latents musicaux détectés par NMF (matrice H)\",\n",
    "             x = \"Caractéristiques audio\", y = \"Profils NMF\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'erreur de reconstruction décroit jusqu'à notre nombre variables totales, on choisit arbitrairement de prendre 6 facteurs pour la suite de l'analyse, ce qui va nous donner 6 profils musicaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Résultats\n",
    "\n",
    "#### 1. Profils latents détectés\n",
    "\n",
    "L’analyse a révélé **6 profils musicaux latents** à partir des données. Chaque profil est défini par une combinaison unique de caractéristiques audio. Voici leur interprétation :\n",
    "\n",
    "* **Profil 1 : Profil Instrumental**\n",
    "\n",
    "  * Très forte **`instrumentalness`** avec très peu d'autres caractéristiques.\n",
    "  * Correspond clairement à des morceaux **purement instrumentaux**, probablement **ambient**, **classique** ou **bande-son**.\n",
    "\n",
    "* **Profil 2 : Profil Énergique-Intense**\n",
    "\n",
    "  * Caractérisé par de **très fortes valeurs en `energy`, `loudness`, `tempo`, `duration` et `danceability`**.\n",
    "  * Faible en composantes émotionnelles (`valence`), vocales et instrumentales.\n",
    "  * Ce profil pourrait correspondre à des morceaux **très dynamiques et bruyants**, typiques de l’**EDM** (house, electro, techno) ou du **hard-rock**/**metal**.\n",
    "\n",
    "* **Profil 3 : Profil Live**\n",
    "\n",
    "  * Faibles valeurs générales sauf une **forte `liveness`**.\n",
    "  * Peut représenter des morceaux **live**.\n",
    "\n",
    "* **Profil 4 : Profil Émotionnel-Valence**\n",
    "\n",
    "  * Faible en toutes dimensions sauf une très forte **`valence`**.\n",
    "  * Ce profil regroupe des morceaux **émotionnellement très positifs**, avec une ambiance **joyeuse ou euphorique**, indépendamment du tempo ou de l’énergie.\n",
    "\n",
    "* **Profil 5 : Profil Acoustique-Chant**\n",
    "\n",
    "  * Dominé par une forte **`acousticness`**.\n",
    "  * Ce profil, présente **`instrumentalness`=0**, et un faible **`speechiness`** mais différent de zéro.\n",
    "  * Ce profil regroupe possiblement des morceaux **acoustiques et chantés**.\n",
    "\n",
    "* **Profil 6 : Profil Rap-Rythmé**\n",
    "\n",
    "  * Forte `danceability` et `speechiness`.\n",
    "  * Ce profil semble capturer des morceaux **rythmés et très vocaux**, typiques du **rap**, **hip-hop**, voire certains morceaux **R\\&B urbains**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Système de recommandation\n",
    "\n",
    "### Objectif\n",
    "L'objectif de cette section est de développer un système de recommandation basé sur les profils musicaux latents identifiés par la NMF. Ce système permettra de :\n",
    "\n",
    "1. Recommander des **morceaux à ajouter à une playlist existante** en analysant son profil musical global\n",
    "2. Suggérer des **chansons similaires à un morceau spécifique choisi** par l'utilisateur\n",
    "\n",
    "### Méthodologie\n",
    "En se basant sur les 6 profils latents extraits (instrumental, énergique-intense, live, émotionnel-valence, acoustique-chant, rap-rythmé), le système calcule des mesures de similarité pour proposer des recommandations personnalisées et pertinentes.\n",
    "\n",
    "1. **Extraction des profils latents** : Utilisation des 6 profils musicaux latents identifiés par la NMF.\n",
    "2. **Calcul de similarité** : Mesures de similarité entre les morceaux ou le profil moyen d'une playlist et les profils latents pour déterminer les recommandations.\n",
    "3. **Recommandation personnalisée** : Proposer des morceaux en fonction des similarités calculées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Système de recommandation basé sur les profils NMF\n",
    "\n",
    "# 1. Ajouter les profils NMF comme colonnes au dataframe original\n",
    "song_with_profiles <- song\n",
    "song_with_profiles[, paste0(\"profile_\", 1:6)] <- W_6\n",
    "\n",
    "# 2. Fonction pour recommander des chansons basées sur une playlist\n",
    "recommend_songs <- function(playlist_name, num_recommendations = 3) {\n",
    "    # Vérifier si la playlist existe\n",
    "    if(!(playlist_name %in% song_with_profiles$playlist_name)) {\n",
    "        stop(\"Playlist non trouvée dans le dataset\")\n",
    "    }\n",
    "    \n",
    "    # Récupérer les morceaux de la playlist\n",
    "    playlist_songs <- song_with_profiles[song_with_profiles$playlist_name == playlist_name, ]\n",
    "    \n",
    "    # Calculer le profil moyen de la playlist\n",
    "    playlist_profile <- colMeans(playlist_songs[, paste0(\"profile_\", 1:6)])\n",
    "    \n",
    "    # Exclure les morceaux déjà dans la playlist\n",
    "    other_songs <- song_with_profiles[song_with_profiles$playlist_name != playlist_name, ]\n",
    "    \n",
    "    # Calculer la similarité (distance euclidienne) entre le profil de la playlist et chaque morceau\n",
    "    similarities <- apply(other_songs[, paste0(\"profile_\", 1:6)], 1, function(song_profile) {\n",
    "        -sqrt(sum((song_profile - playlist_profile)^2))  # Négative car nous voulons maximiser\n",
    "    })\n",
    "    \n",
    "    # Trier les morceaux par similarité décroissante\n",
    "    other_songs$similarity <- similarities\n",
    "    recommendations <- other_songs[order(other_songs$similarity, decreasing = TRUE), ]\n",
    "    \n",
    "    # Retourner les top N recommandations\n",
    "    return(head(recommendations[, c(\"track_name\", \"track_artist\", \"playlist_genre\", \"playlist_subgenre\", \"similarity\")], num_recommendations))\n",
    "}\n",
    "\n",
    "# 3. Exemple d'utilisation\n",
    "# Obtenir les noms de playlists uniques\n",
    "unique_playlists <- unique(song_with_profiles$playlist_name)\n",
    "\n",
    "# Sélectionner une playlist aléatoire pour démonstration\n",
    "set.seed(123)\n",
    "example_playlist <- sample(unique_playlists, 1)\n",
    "\n",
    "# Afficher le nom de la playlist sélectionnée\n",
    "cat(\"Playlist sélectionnée:\", as.character(example_playlist), \"\\n\\n\")\n",
    "\n",
    "# Afficher quelques chansons de la playlist sélectionnée\n",
    "playlist_sample <- song_with_profiles[song_with_profiles$playlist_name == example_playlist, \n",
    "                                                                     c(\"track_name\", \"track_artist\", \"playlist_genre\")]\n",
    "cat(\"Exemple de chansons dans cette playlist:\\n\")\n",
    "print(head(playlist_sample, 3))\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Obtenir les recommandations sous la forme d'un tableau sans les playlist_subgenre\n",
    "recommendations <- recommend_songs(example_playlist, num_recommendations = 3)\n",
    "cat(\"Recommandations de chansons basées sur la playlist sélectionnée:\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Fonction pour recommander à partir d'une chanson spécifique\n",
    "recommend_from_song <- function(track_name, track_artist, num_recommendations = 3) {\n",
    "    # Trouver la chanson dans le dataset\n",
    "    song_idx <- which(song_with_profiles$track_name == track_name & \n",
    "                                        song_with_profiles$track_artist == track_artist)\n",
    "    \n",
    "    if(length(song_idx) == 0) {\n",
    "        stop(\"Chanson non trouvée dans le dataset\")\n",
    "    }\n",
    "    \n",
    "    # Récupérer le profil de la chanson\n",
    "    song_profile <- as.numeric(song_with_profiles[song_idx[1], paste0(\"profile_\", 1:6)])\n",
    "    \n",
    "    # Exclure la chanson elle-même\n",
    "    other_songs <- song_with_profiles[-song_idx, ]\n",
    "    \n",
    "    # Calculer la similarité\n",
    "    similarities <- apply(other_songs[, paste0(\"profile_\", 1:6)], 1, function(profile) {\n",
    "        -sqrt(sum((profile - song_profile)^2))\n",
    "    })\n",
    "    \n",
    "    # Trier par similarité\n",
    "    other_songs$similarity <- similarities\n",
    "    recommendations <- other_songs[order(other_songs$similarity, decreasing = TRUE), ]\n",
    "    \n",
    "    # Retourner les top N recommandations\n",
    "    return(head(recommendations[, c(\"track_name\", \"track_artist\", \"playlist_genre\", \"playlist_subgenre\", \"similarity\")], num_recommendations))\n",
    "}\n",
    "\n",
    "# Exemple d'utilisation de la recommandation par chanson\n",
    "# Sélectionner une chanson aléatoire\n",
    "set.seed(24)\n",
    "random_song_idx <- sample(1:nrow(song_with_profiles), 1)\n",
    "example_song <- song_with_profiles[random_song_idx, ]\n",
    "\n",
    "cat(\"\\n\\nRecommandation basée sur une chanson spécifique\\n\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"Chanson sélectionnée :\\n\")\n",
    "cat(\"Nom de la chanson:\", example_song$track_name, \"\\n\")\n",
    "cat(\"Artiste:\", as.character(example_song$track_artist), \"\\n\")\n",
    "\n",
    "# Obtenir les recommandations\n",
    "song_recommendations <- recommend_from_song(example_song$track_name, example_song$track_artist, 5)\n",
    "cat(\"Chansons similaires recommandées:\\n\")\n",
    "print(song_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Recommandation pour la playlist \"Tropical Beats\"\n",
    "playlist_name <- \"Tropical Beats\"\n",
    "num_recommendations <- 5\n",
    "recommendations <- recommend_songs(playlist_name, num_recommendations)\n",
    "cat(\"Recommandations pour la playlist 'Tropical Beats':\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Recommandation pour la chanson \"Thunderstruck\" de \"AC/DC\"\n",
    "track_name <- \"Thunderstruck\"\n",
    "track_artist <- \"AC/DC\"\n",
    "num_recommendations <- 5\n",
    "recommendations <- recommend_from_song(track_name, track_artist, num_recommendations)\n",
    "cat(\"Recommandations pour la chanson 'Thunderstruck' de 'AC/DC':\\n\")\n",
    "print(recommendations[, -4])  # Exclure la colonne playlist_subgenre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette analyse approfondie du dataset Spotify a permis d'explorer les relations complexes entre les caractéristiques musicales à travers plusieurs techniques complémentaires d'analyse multivariée et de réduction de dimension.\n",
    "\n",
    "### Principaux résultats\n",
    "\n",
    "**Analyse en Composantes Principales (ACP)**\n",
    "\n",
    "L'ACP a révélé que 80% de la variance des données peut être expliquée par seulement 7 composantes principales, démontrant une structure sous-jacente claire dans les caractéristiques audio. Les trois premières composantes principales ont mis en évidence des oppositions significatives :\n",
    "- **CP1** : Opposition entre morceaux énergiques/électriques et morceaux acoustiques/calmes\n",
    "- **CP2** : Distinction entre musique instrumentale/longue et musique populaire/dansante  \n",
    "- **CP3** : Paradoxe entre potentiel dansant et popularité réelle\n",
    "\n",
    "**Techniques de réduction non-linéaire**\n",
    "Les méthodes MDS et t-SNE ont montré que les genres musicaux ne sont pas linéairement séparables sur la base des seules caractéristiques audio, suggérant une proximité acoustique entre certains genres ou la nécessité de variables supplémentaires pour une discrimination efficace.\n",
    "\n",
    "**Analyse des Correspondances Multiples (ACM)**\n",
    "L'ACM a révélé des associations claires entre genres musicaux, tonalités et modes, notamment l'association du rock avec le mode majeur et certaines tonalités spécifiques, contrastant avec d'autres genres plus équilibrés entre modes majeur et mineur.\n",
    "\n",
    "**Analyse Factorielle Multiple (AFM)**\n",
    "L'intégration simultanée des variables quantitatives et qualitatives a permis une vision globale des profils musicaux, confirmant les relations entre caractéristiques audio et attributs catégoriels.\n",
    "\n",
    "**Factorisation Matricielle Non-négative (NMF)**\n",
    "La NMF a identifié 6 profils musicaux latents distincts : instrumental, énergique-intense, live, émotionnel-valence, acoustique-chant, et rap-rythmé. Ces profils ont servi de base à un système de recommandation efficace.\n",
    "\n",
    "### Applications pratiques\n",
    "\n",
    "Le système de recommandation développé à partir des profils NMF démontre l'applicabilité concrète de cette analyse. Il permet de recommander des morceaux similaires basés soit sur une playlist entière, soit sur une chanson spécifique, en utilisant les profils latents comme mesure de similarité.\n",
    "\n",
    "### Perspectives\n",
    "\n",
    "Cette analyse ouvre plusieurs pistes pour des développements futurs :\n",
    "- Intégration de variables temporelles (évolution des goûts musicaux)\n",
    "- Application à des tâches de classification supervisée des genres\n",
    "- Enrichissement du système de recommandation avec des données d'écoute utilisateur\n",
    "- Extension à d'autres plateformes musicales pour validation croisée\n",
    "\n",
    "L'approche multi-méthodes adoptée a permis une compréhension riche et nuancée de la structure des données musicales, démontrant la complémentarité des différentes techniques d'analyse factorielle pour explorer des datasets complexes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
